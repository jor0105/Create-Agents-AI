# ğŸ¤– AI Agent Creator

Um sistema modular e profissional para criar agentes de IA com suporte a mÃºltiplos provedores (OpenAI, Ollama).

## âš¡ Quick Start

### InstalaÃ§Ã£o

```bash
# Clone o repositÃ³rio
git clone https://github.com/jor0105/AI_Agent.git
cd AI_Agent

# InstalaÃ§Ã£o bÃ¡sica (sem ferramentas pesadas)
poetry install

# OU InstalaÃ§Ã£o completa (inclui ferramentas de leitura de arquivos)
poetry install -E file-tools

# OU InstalaÃ§Ã£o com todas as funcionalidades
poetry install -E all

# Configure suas credenciais
cp .env.example .env
# Edite .env e adicione sua chave OpenAI
```

### ğŸ“¦ InstalaÃ§Ã£o de Extras Opcionais

Este projeto oferece instalaÃ§Ã£o modular para manter a biblioteca leve:

**InstalaÃ§Ã£o BÃ¡sica** (apenas funcionalidades essenciais):
```bash
pip install ai-agent
# ou
poetry install
```

**Com ferramentas de leitura de arquivos** (PDF, Excel, CSV, Parquet):
```bash
pip install ai-agent[file-tools]
# ou
poetry install -E file-tools
```

**InstalaÃ§Ã£o completa** (todas as funcionalidades):
```bash
pip install ai-agent[all]
# ou
poetry install -E all
```

#### ğŸ“‹ Extras DisponÃ­veis

| Extra | DependÃªncias | Funcionalidades |
|-------|--------------|-----------------|
| `file-tools` | tiktoken, pymupdf, pandas, openpyxl, pyarrow, chardet | Ferramenta ReadLocalFileTool para ler arquivos locais (TXT, CSV, Excel, PDF, Parquet) |
| `all` | Todas acima | Todas as funcionalidades opcionais |

### Uso bÃ¡sico em 3 linhas

```python
from src.presentation import AIAgent

agent = AIAgent(model="gpt-4", name="Meu Assistente", instructions="VocÃª Ã© um assistente Ãºtil")

response = agent.chat("OlÃ¡! Como vocÃª estÃ¡?")

print(response)
```

## ğŸ¯ Funcionalidades

### âœ… Suporte a mÃºltiplos provedores

- **OpenAI**: Todos os modelos de Chat
- **Ollama**: Modelos locais que vocÃª instalou

### âœ… Interface intuitiva

```python
# Criar agente
agent = AIAgent(
    provider="openai",      # ou "ollama"
    model="gpt-4",
    name="Assistente Smart",
    instructions="VocÃª Ã© um especialista em Python"
)

# Conversar
response = agent.chat("Qual Ã© a diferenÃ§a entre lista e tupla?")

# Obter histÃ³rico
configs = agent.get_configs()

# Limpar histÃ³rico
agent.clear_history()
```

### âœ… Gerenciamento de histÃ³rico

```python
# HistÃ³rico automÃ¡tico (Ãºltimas 10 mensagens por padrÃ£o)
agent.chat("Primeira mensagem")
agent.chat("Segunda mensagem")

# Personalizar tamanho do histÃ³rico
agent = AIAgent(..., history_max_size=20)

# Limpar quando necessÃ¡rio
agent.clear_history()
```

### âœ… ConfiguraÃ§Ã£o customizada

```python
config = {
    "temperature": 0.7,     # Criatividade (0-1)
    "max_tokens": 1000,     # Limite de resposta
}

agent = AIAgent(
    model="gpt-4",
    name="Assistente",
    instructions="Seja conciso"
    config=config,
)
```

### âœ… MÃ©tricas e performance

```python
# Ver mÃ©tricas de chamadas
metrics = agent.get_metrics()

# Exportar como JSON
json_data = agent.export_metrics_json()

# Exportar formato Prometheus
prom_data = agent.export_metrics_prometheus()

# Salvar em arquivo
agent.export_metrics_json("metrics.json")
agent.export_metrics_prometheus("metrics.prom")
```

## ğŸ“‹ Exemplos de Uso

### Exemplo 1: Assistente de ProgramaÃ§Ã£o

```python
from src.presentation import AIAgent

assistant = AIAgent(
    provider="openai",
    model="gpt-4",
    name="Code Assistant",
    instructions="VocÃª Ã© um especialista em programaÃ§Ã£o Python. Sempre forneÃ§a exemplos de cÃ³digo.",
    config={"temperature": 0.3}  # Menos criatividade para cÃ³digo
)

# Conversar
response = assistant.chat("Como ordenar uma lista de dicionÃ¡rios por chave?")
print(response)

# Ver histÃ³rico
config = assistant.get_configs()
print(f"HistÃ³rico: {len(config['history'])} mensagens")

# Limpar e comeÃ§ar novo diÃ¡logo
assistant.clear_history()
```

### Exemplo 2: Agente Local com Ollama

```python
# Certifique-se que Ollama estÃ¡ rodando
# ollama serve

agent = AIAgent(
    provider="ollama",
    model="llama2",
    name="Local Assistant"
)

# Usar localmente (sem custos de API)
response = agent.chat("Resuma Clean Architecture em 3 pontos")
print(response)
```

### Exemplo 3: MÃºltiplos Agentes

```python
# Um para anÃ¡lise
analyzer = AIAgent(
    model="gpt-4",
    instructions="VocÃª analisa cÃ³digo e fornece feedback crÃ­tico",
    config={"temperature": 0.5}
)

# Outro para documentaÃ§Ã£o
documentor = AIAgent(
    model="gpt-4",
    instructions="VocÃª escreve documentaÃ§Ã£o clara e profissional",
    config={"temperature": 0.3}
)

# Usar ambos
code = "def sum(a,b): return a+b"
feedback = analyzer.chat(f"Revise este cÃ³digo:\n{code}")
docs = documentor.chat(f"Documente este cÃ³digo:\n{code}")

print("Feedback:", feedback)
print("DocumentaÃ§Ã£o:", docs)
```

## ğŸ”§ ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente

Crie um arquivo `.env`:

```bash
# OpenAI
OPENAI_API_KEY=sk-xxx...

# Ollama (opcional)
OLLAMA_API_URL=http://localhost:11434
```

### Modelos disponÃ­veis

**OpenAI:**

- `gpt-4` (mais poderoso)
- `gpt-4-turbo` (mais rÃ¡pido)
- `gpt-4o` (visÃ£o incluÃ­da)
- `gpt-3.5-turbo` (mais econÃ´mico)

**Ollama (local):**

- `llama2`
- `mistral`
- `neural-chat`
- `starling-lm`
- E muitos mais...

## ğŸ“Š API ReferÃªncia

### AIAgent

```python
AIAgent(
    provider: str,              # "openai" ou "ollama"
    model: str,                 # Nome do modelo
    name: str = None,           # Nome do agente (opcional)
    instructions: str = None,   # InstruÃ§Ãµes do sistema (opcional)
    config: dict = None,        # ConfiguraÃ§Ã£o do modelo
    history_max_size: int = 10  # Tamanho mÃ¡ximo do histÃ³rico
)
```

#### MÃ©todos

| MÃ©todo                                 | Retorno | DescriÃ§Ã£o                          |
| -------------------------------------- | ------- | ---------------------------------- |
| `chat(message)`                        | `str`   | Enviar mensagem e receber resposta |
| `get_configs()`                        | `dict`  | Obter configuraÃ§Ãµes e histÃ³rico    |
| `clear_history()`                      | `None`  | Limpar histÃ³rico de mensagens      |
| `get_metrics()`                        | `list`  | Obter mÃ©tricas de performance      |
| `export_metrics_json(path=None)`       | `str`   | Exportar mÃ©tricas em JSON          |
| `export_metrics_prometheus(path=None)` | `str`   | Exportar mÃ©tricas em Prometheus    |

## ğŸš€ Performance

### Tempos de resposta

- OpenAI: 1-5 segundos (depende da rede)
- Ollama: 2-30 segundos (depende do modelo e hardware)

### Limite de tokens

- GPT-4: atÃ© 8.000 tokens por mensagem
- GPT-3.5: atÃ© 4.000 tokens por mensagem
- Modelos locais: variam por modelo

## ğŸ“š Arquitetura (Para Desenvolvedores)

Este projeto segue **Clean Architecture** e **SOLID Principles**:

```
src/
â”œâ”€â”€ domain/           # Regras de negÃ³cio (independente de tecnologia)
â”œâ”€â”€ application/      # Casos de uso (lÃ³gica da aplicaÃ§Ã£o)
â”œâ”€â”€ infra/           # Detalhes tÃ©cnicos (APIs, adapters)
â”œâ”€â”€ main/            # ComposiÃ§Ã£o e injeÃ§Ã£o de dependÃªncias
â””â”€â”€ presentation/    # Interface pÃºblica (AIAgent)
```

## ğŸ¤ Contribuindo

Quer adicionar um novo provedor de IA?

1. **Crie um novo adapter** em `src/infra/adapters/NomeProvedor/`
2. **Implemente** a interface `ChatRepository`
3. **Registre** em `ChatAdapterFactory`
4. **Adicione testes** em `tests/infra/adapters/`

Exemplo:

```python
class MeuAdapter(ChatRepository):
    async def chat(self, message: str) -> str:
        # Sua implementaÃ§Ã£o
        pass
```

## ğŸ§ª Para Desenvolvedores: CI/CD & Workflows

Este projeto tem automaÃ§Ã£o profissional com GitHub Actions:

- **Quality Checks (CI)**: Lint, formataÃ§Ã£o, type checking, security, testes com cobertura mÃ­nima de 70%

  - Executa em: Push/PR para `develop` ou `main`
  - Matrix: Python 3.12, 3.13, 3.14

- **Documentation Build**: Build e validaÃ§Ã£o da documentaÃ§Ã£o com MkDocs

  - Executa: Manualmente via workflow_dispatch

- **Pre-commit Hooks**: 15+ verificadores automÃ¡ticos antes de cada commit
  - Black, Ruff, isort, mypy, pydocstyle, yamllint e mais

**ğŸ“– DocumentaÃ§Ã£o Completa:** [`docs/ci-cd.md`](./docs/ci-cd.md)

**Quick start para contribuir:**

```bash
# Instalar pre-commit hooks
poetry run pre-commit install

# Executar todos os checks localmente
poetry run pre-commit run --all-files

# Executar testes com cobertura
poetry run pytest --cov=src --cov-fail-under=70
```

## ğŸ“„ LicenÃ§a

MIT - Use livremente em seus projetos!

## ğŸ“ Suporte

- ğŸ“– [DocumentaÃ§Ã£o Completa](./docs/)
- ğŸ› [Reportar Bugs](https://github.com/jor0105/AI_Agent/issues)
- ğŸ’¬ [DiscussÃµes](https://github.com/jor0105/AI_Agent/discussions)

## ğŸ‘¨â€ğŸ’» Autor

**Jordan Estralioto**

- Email: estraliotojordan@gmail.com
- GitHub: [@jor0105](https://github.com/jor0105)

---

## ğŸ“š ReferÃªncias

- [Clean Architecture - Robert C. Martin](https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html)
- [OpenAI API Documentation](https://platform.openai.com/docs)
- [Ollama Documentation](https://github.com/ollama/ollama)
- [SOLID Principles](https://en.wikipedia.org/wiki/SOLID)

---

**VersÃ£o:** 0.1.0
**Ãšltima atualizaÃ§Ã£o:** Outubro 2025
