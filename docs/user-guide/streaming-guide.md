# Guia de Streaming

Este guia explica como receber respostas do agente em tempo real.

---

## ğŸ’¡ O que Ã© Streaming?

Streaming permite que vocÃª veja a resposta aparecendo **palavra por palavra** em tempo real, como se o agente estivesse digitando. Isso deixa a experiÃªncia mais natural e interativa.

**Sem streaming**: VocÃª espera 5 segundos e recebe a resposta completa de uma vez.
**Com streaming**: As palavras aparecem imediatamente, conforme o agente gera a resposta.

---

## ğŸš€ Como Usar

Existem duas formas de receber respostas do agente:

### 1ï¸âƒ£ Receber a Resposta Completa (Mais Simples)

Use `await` para esperar a resposta completa:

```python
import asyncio
from createagents import CreateAgent

async def main():
    agent = CreateAgent(provider="openai", model="gpt-4")

    # Espera a resposta completa
    resposta = await agent.chat("Escreva um poema")
    print(resposta)

asyncio.run(main())
```

### 2ï¸âƒ£ Ver Palavra por Palavra (Streaming em Tempo Real)

Use `async for` para ver cada palavra aparecer:

```python
import asyncio
from createagents import CreateAgent

async def main():
    agent = CreateAgent(provider="openai", model="gpt-4")

    resposta = await agent.chat("Conte uma histÃ³ria")

    # Mostra palavra por palavra
    async for palavra in resposta:
        print(palavra, end='', flush=True)
    print()  # Nova linha no final

asyncio.run(main())
```

> ğŸ’¡ **Dica**: Use a opÃ§Ã£o 2 para chatbots ou interfaces onde vocÃª quer mostrar o agente "pensando".

---

## ğŸ“š Exemplos PrÃ¡ticos

### Exemplo 1: Chatbot Interativo

Crie um chatbot que mostra as palavras aparecendo:

```python
import asyncio
from createagents import CreateAgent

async def chat_interface():
    agent = CreateAgent(provider="openai", model="gpt-4")

    while True:
        user_input = input("VocÃª: ")
        if user_input.lower() in ['sair', 'exit']:
            break

        print("Agente: ", end='', flush=True)
        resposta = await agent.chat(user_input)

        # Mostra palavra por palavra
        async for palavra in resposta:
            print(palavra, end='', flush=True)
        print("\n")

asyncio.run(chat_interface())
```

### Exemplo 2: Perguntas Simples

Para perguntas diretas, use `await` (mais simples):

```python
import asyncio
from createagents import CreateAgent

async def perguntas_simples():
    agent = CreateAgent(provider="openai", model="gpt-4")

    # Pergunta direta
    resposta = await agent.chat("Qual a capital do Brasil?")
    print(f"Resposta: {resposta}")

asyncio.run(perguntas_simples())
```

---

## âš™ï¸ Ativando e Desativando Streaming

### Ativar Streaming (PadrÃ£o)

Por padrÃ£o, o streaming jÃ¡ vem ativado. VocÃª nÃ£o precisa fazer nada!

```python
import asyncio
from createagents import CreateAgent

async def main():
    # Streaming jÃ¡ estÃ¡ ativo
    agent = CreateAgent(provider="openai", model="gpt-4")

    resposta = await agent.chat("Conte uma histÃ³ria")
    async for palavra in resposta:
        print(palavra, end='', flush=True)

asyncio.run(main())
```

### Desativar Streaming

Se preferir esperar a resposta completa, desative o streaming:

```python
import asyncio

async def main():
    # Desabilita streaming
    agent = CreateAgent(
        provider="openai",
        model="gpt-4",
        config={"stream": False}
    )

    # Recebe tudo de uma vez
    resposta = await agent.chat("OlÃ¡")
    print(resposta)

asyncio.run(main())
```

---

### Usar com Ollama (Modelos Locais)

```python
import asyncio

async def ollama_streaming():
    agent = CreateAgent(provider="ollama", model="llama3.2")

    resposta = await agent.chat("Explique machine learning")
    async for palavra in resposta:
        print(palavra, end='', flush=True)
    print()

asyncio.run(ollama_streaming())
```

**Funciona igual!** NÃ£o importa se usa OpenAI ou Ollama, o streaming funciona da mesma forma.

---

## ğŸ› ï¸ Usando Ferramentas

O streaming funciona normalmente mesmo quando o agente usa ferramentas:

```python
import asyncio

async def exemplo_com_ferramentas():
    agent = CreateAgent(
        provider="openai",
        model="gpt-4",
        tools=["currentdate"]
    )

    print("Perguntando sobre datas...\n")
    resposta = await agent.chat("Que dia Ã© hoje?")

    # O agente usa a ferramenta e responde em streaming
    async for palavra in resposta:
        print(palavra, end='', flush=True)
    print()

asyncio.run(exemplo_com_ferramentas())
```

---

## ğŸ“Š Streaming e MÃ©tricas

MÃ©tricas sÃ£o coletadas automaticamente, independentemente do modo de consumo:

```python
import asyncio

async def streaming_with_metrics():
    from createagents import CreateAgent

    agent = CreateAgent(provider="openai", model="gpt-4")

    # Streaming
    response = await agent.chat("Conte uma piada")
    async for token in response:
        print(token, end='')
    print("\n")

    # MÃ©tricas ainda sÃ£o gravadas
    metrics = agent.get_metrics()
    print(f"\nLatÃªncia: {metrics[-1].latency_ms}ms")
    print(f"Tokens: {metrics[-1].tokens_used}")

asyncio.run(streaming_with_metrics())
```

---

## ï¿½ Dicas

### 1. Para Perguntas RÃ¡pidas

Use `await` para receber a resposta completa:

```python
resposta = await agent.chat("Qual a capital da FranÃ§a?")
print(resposta)
```

### 2. Para Chatbots e Interfaces

Use `async for` para mostrar palavra por palavra:

```python
resposta = await agent.chat("Escreva um artigo")
async for palavra in resposta:
    print(palavra, end='', flush=True)
```

### 3. Lembre-se do `await`

Sempre use `await` ao chamar `agent.chat()`:

```python
# âŒ Errado
resposta = agent.chat("mensagem")  # NÃ£o funciona!

# âœ… Correto
resposta = await agent.chat("mensagem")  # Funciona!
```

### 4. Use `asyncio.run()`

Sempre envolva seu cÃ³digo em uma funÃ§Ã£o `async` e execute com `asyncio.run()`:

```python
import asyncio

async def main():
    resposta = await agent.chat("mensagem")
    print(resposta)

asyncio.run(main())
```

---

## ğŸ“š PrÃ³ximos Passos

- [Uso da CLI](cli-usage.md) - Interface interativa
- [Exemplos PrÃ¡ticos](examples-user.md) - Mais exemplos de uso
- [FAQ](faq-user.md) - Perguntas frequentes

---

**VersÃ£o:** 0.1.3 | **AtualizaÃ§Ã£o:** 01/12/2025
