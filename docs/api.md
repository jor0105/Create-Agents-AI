# üìö API Reference

Documenta√ß√£o completa da API p√∫blica do **AI Agent Creator**.

---

## ü§ñ AIAgent

O controller principal para intera√ß√£o com agentes de IA.

### Construtor

```python
AIAgent(
    provider: str,
    model: str,
    name: Optional[str] = None,
    instructions: Optional[str] = None,
    config: Optional[Dict[str, Any]] = None,
    tools: Optional[Sequence[Union[str, BaseTool]]] = None,
    history_max_size: int = 10
)
```

**Par√¢metros:**

| Par√¢metro          | Tipo   | Descri√ß√£o                                                 | Obrigat√≥rio |
| ------------------ | ------ | --------------------------------------------------------- | ----------- |
| `provider`         | `str`  | Provider de IA: `"openai"` ou `"ollama"`                  | ‚úÖ Sim      |
| `model`            | `str`  | Nome do modelo (ex: `"gpt-4"`, `"llama2"`)                | ‚úÖ Sim      |
| `name`             | `str`  | Nome do agente                                            | ‚ùå N√£o      |
| `instructions`     | `str`  | Instru√ß√µes/personalidade do agente                        | ‚ùå N√£o      |
| `config`           | `dict` | Configura√ß√µes do modelo (temperature, max_tokens, etc)    | ‚ùå N√£o      |
| `tools`            | `list` | Lista de ferramentas: `["current_date", "readlocalfile"]` | ‚ùå N√£o      |
| `history_max_size` | `int`  | Tamanho m√°ximo do hist√≥rico (padr√£o: 10)                  | ‚ùå N√£o      |

**Exemplo:**

```python
from src.presentation import AIAgent

agent = AIAgent(
    provider="openai",
    model="gpt-4",
    instructions="Voc√™ √© um assistente t√©cnico",
    config={"temperature": 0.7, "max_tokens": 2000},
    tools=["current_date"],
    history_max_size=20
)
```

---

### M√©todos

#### chat()

Envia mensagem ao agente e retorna resposta.

```python
def chat(message: str) -> str
```

**Par√¢metros:**

- `message` (str): Mensagem do usu√°rio

**Retorna:** `str` - Resposta do agente

**Exemplo:**

```python
response = agent.chat("Como criar uma fun√ß√£o em Python?")
print(response)
```

---

#### get_configs()

Retorna configura√ß√µes e hist√≥rico do agente.

```python
def get_configs() -> Dict[str, Any]
```

**Retorna:** `dict` com:

- `name`: Nome do agente
- `model`: Modelo usado
- `provider`: Provider (openai/ollama)
- `instructions`: Instru√ß√µes
- `history`: Lista de mensagens
- `tools`: Ferramentas dispon√≠veis
- `config`: Configura√ß√µes do modelo

**Exemplo:**

```python
config = agent.get_configs()
print(f"Modelo: {config['model']}")
print(f"Hist√≥rico: {len(config['history'])} mensagens")
```

---

#### clear_history()

Limpa o hist√≥rico de mensagens.

```python
def clear_history() -> None
```

**Exemplo:**

```python
agent.clear_history()
print("Hist√≥rico limpo!")
```

---

#### get_metrics()

Retorna m√©tricas de performance.

```python
def get_metrics() -> List[ChatMetrics]
```

**Retorna:** `List[ChatMetrics]` com:

- `response_time` (float): Tempo de resposta em segundos
- `tokens_used` (int): Tokens consumidos
- `status` (str): Status da requisi√ß√£o
- `timestamp` (datetime): Momento da execu√ß√£o

**Exemplo:**

```python
metrics = agent.get_metrics()
for m in metrics:
    print(f"Tempo: {m.response_time:.2f}s, Tokens: {m.tokens_used}")
```

---

#### export_metrics_json()

Exporta m√©tricas em formato JSON.

```python
def export_metrics_json(filepath: Optional[str] = None) -> str
```

**Par√¢metros:**

- `filepath` (str, opcional): Caminho para salvar

**Retorna:** JSON string

**Exemplo:**

```python
# Salvar em arquivo
agent.export_metrics_json("metrics.json")

# Obter como string
json_data = agent.export_metrics_json()
```

---

#### export_metrics_prometheus()

Exporta m√©tricas em formato Prometheus.

```python
def export_metrics_prometheus(filepath: Optional[str] = None) -> str
```

**Par√¢metros:**

- `filepath` (str, opcional): Caminho para salvar

**Retorna:** String formato Prometheus

**Exemplo:**

```python
agent.export_metrics_prometheus("metrics.prom")
```

---

## üõ†Ô∏è Ferramentas (Tools)

### Ferramentas Dispon√≠veis

#### CurrentDateTool

Obt√©m data/hora em qualquer timezone.

**Nome:** `"current_date"`

**Uso:**

```python
agent = AIAgent(
    provider="openai",
    model="gpt-4",
    tools=["current_date"]
)

response = agent.chat("Que dia √© hoje?")
```

**A√ß√µes:**

- `date`: Data (YYYY-MM-DD)
- `time`: Hora (HH:MM:SS)
- `datetime`: Data e hora
- `timestamp`: Unix timestamp
- `date_with_weekday`: Data com dia da semana

---

#### ReadLocalFileTool

L√™ arquivos locais em m√∫ltiplos formatos.

**Nome:** `"readlocalfile"`

**Requer:** `poetry install -E file-tools`

**Formatos:**

- Texto: TXT, MD, CSV, JSON, YAML
- Documentos: PDF
- Planilhas: Excel (XLS, XLSX), Parquet

**Uso:**

```python
agent = AIAgent(
    provider="openai",
    model="gpt-4",
    tools=["readlocalfile"]
)

response = agent.chat("Leia o arquivo report.pdf")
```

**Limites:**

- Tamanho m√°ximo: 100MB
- Tokens m√°ximos: 30.000

---

## üìä Configura√ß√µes do Modelo

Par√¢metros para controlar o comportamento do modelo (OpenAI):

```python
config = {
    "temperature": 0.7,        # 0-1: Criatividade
    "max_tokens": 2000,        # Limite de tokens
    "top_p": 0.9,              # 0-1: Nucleus sampling
    "frequency_penalty": 0,    # 0-2: Reduz repeti√ß√£o
    "presence_penalty": 0,     # 0-2: Encoraja novos t√≥picos
}

agent = AIAgent(provider="openai", model="gpt-4", config=config)
```

**Par√¢metros:**

| Nome                | Faixa | Descri√ß√£o                                            |
| ------------------- | ----- | ---------------------------------------------------- |
| `temperature`       | 0-1   | Controla aleatoriedade. 0=determin√≠stico, 1=criativo |
| `max_tokens`        | 1-‚àû   | Limite de tokens na resposta                         |
| `top_p`             | 0-1   | Nucleus sampling                                     |
| `frequency_penalty` | 0-2   | Penalidade por repeti√ß√£o                             |
| `presence_penalty`  | 0-2   | Encoraja novos t√≥picos                               |

---

## üí° Exemplos de Uso

```python
from src.presentation import AIAgent

# B√°sico
agent = AIAgent(provider="openai", model="gpt-4")
response = agent.chat("Ol√°!")

# Com ferramentas
agent = AIAgent(
    provider="openai",
    model="gpt-4",
    tools=["current_date", "readlocalfile"]
)

# Local (Ollama)
agent = AIAgent(provider="ollama", model="llama2")

# Personalizado
agent = AIAgent(
    provider="openai",
    model="gpt-4",
    instructions="Seja t√©cnico",
    config={"temperature": 0.3},
    history_max_size=50
)
```

---

**Vers√£o:** 0.1.0 | **Atualiza√ß√£o:** Novembro 2025
