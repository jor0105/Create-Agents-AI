{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b73494c",
   "metadata": {},
   "source": [
    "# Pipeline Modular de Embeddings com Ollama - Vers√£o Profissional\n",
    "\n",
    "Este notebook demonstra como usar a fun√ß√£o `create_embeddings()` do m√≥dulo `indexar.py` para processar documentos e criar embeddings de forma simples e modular.\n",
    "\n",
    "## Caracter√≠sticas:\n",
    "- ‚úÖ **Extremamente simples de usar** - apenas uma chamada de fun√ß√£o\n",
    "- ‚úÖ **Totalmente modular** - customize todos os par√¢metros\n",
    "- ‚úÖ **Suporta m√∫ltiplos formatos** - PDF, CSV, Parquet, Excel, TXT, MD\n",
    "- ‚úÖ **Processamento paralelo** - aproveita m√∫ltiplos workers\n",
    "- ‚úÖ **Seguro para notebooks** - logs detalhados e tratamento de erros\n",
    "- üÜï **Detec√ß√£o autom√°tica de √≠ndice** - escolhe Flat ou IVF baseado no volume\n",
    "- üÜï **Normaliza√ß√£o de embeddings** - para similaridade coseno eficiente\n",
    "- üÜï **Deduplica√ß√£o autom√°tica** - economiza 20-40% de espa√ßo\n",
    "- üÜï **Metadados ricos** - rastreamento completo de documentos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d242ddd",
   "metadata": {},
   "source": [
    "## 1. Importar a Fun√ß√£o Principal\n",
    "\n",
    "Basta importar a fun√ß√£o `create_embeddings` do m√≥dulo `indexar_novo.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bffa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from indexar import create_embeddings\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e86733d",
   "metadata": {},
   "source": [
    "## 2. Exemplo B√°sico - Uso Mais Simples\n",
    "\n",
    "Este √© o jeito mais simples de usar. Apenas especifique:\n",
    "- Lista de documentos (arquivos ou diret√≥rios)\n",
    "- Modelo do Ollama\n",
    "- Configura√ß√µes de chunk (tamanho e overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e18354a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo b√°sico - processar um diret√≥rio\n",
    "result = create_embeddings(\n",
    "    documents=[\"./documentos\"],           # Diret√≥rio ou lista de arquivos\n",
    "    model_name=\"qwen3-embedding:4b\",      # Modelo do Ollama\n",
    "    chunk_size=1000,                      # Tamanho de cada chunk\n",
    "    chunk_overlap=150,                    # Sobreposi√ß√£o entre chunks\n",
    "    output_prefix=\"meu_indice\"            # Nome dos arquivos de sa√≠da\n",
    ")\n",
    "\n",
    "# Resultado cont√©m informa√ß√µes sobre o processamento\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"‚úì Processamento conclu√≠do!\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total de chunks: {result['total_chunks']}\")\n",
    "print(f\"Tempo: {result['time_seconds']}s\")\n",
    "print(f\"√çndice FAISS: {result['faiss_path']}\")\n",
    "print(f\"Metadados: {result['metadata_path']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8909d7bd",
   "metadata": {},
   "source": [
    "## 3. Exemplo com Arquivos Espec√≠ficos\n",
    "\n",
    "Voc√™ pode especificar arquivos individuais em vez de diret√≥rios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec60e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processar arquivos espec√≠ficos\n",
    "result = create_embeddings(\n",
    "    documents=[\n",
    "        \"artigo1.pdf\",\n",
    "        \"dados.csv\",\n",
    "        \"relatorio.parquet\",\n",
    "        \"planilha.xlsx\"\n",
    "    ],\n",
    "    model_name=\"qwen3-embedding:4b\",\n",
    "    chunk_size=800,           # Chunks menores\n",
    "    chunk_overlap=100,        # Menos overlap\n",
    "    output_prefix=\"arquivos_especificos\"\n",
    ")\n",
    "\n",
    "print(f\"‚úì {result['total_chunks']} chunks processados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cfa4e0",
   "metadata": {},
   "source": [
    "## 4. Customizando Todos os Par√¢metros\n",
    "\n",
    "Voc√™ tem controle total sobre todos os aspectos do processamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963a8af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = create_embeddings(\n",
    "    # Documentos a processar\n",
    "    documents=[\"./docs_tecnicos\", \"./relatorios\"],\n",
    "    \n",
    "    # Modelo de embedding do Ollama\n",
    "    model_name=\"llama2\",  # ou \"qwen3-embedding:4b\", \"nomic-embed-text\", etc.\n",
    "    \n",
    "    # Configura√ß√£o de chunking\n",
    "    chunk_size=1200,       # Tamanho m√°ximo de cada chunk (caracteres)\n",
    "    chunk_overlap=200,     # Sobreposi√ß√£o entre chunks (caracteres)\n",
    "    \n",
    "    # Performance\n",
    "    batch_size=256,        # Quantos chunks processar por vez (menor = menos RAM)\n",
    "    num_workers=8,         # Threads paralelas (mais = mais r√°pido, mas usa mais CPU)\n",
    "    \n",
    "    # Sa√≠da\n",
    "    output_prefix=\"indice_completo\"  # Gera indice_completo.faiss e indice_completo.jsonl\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Estat√≠sticas:\")\n",
    "print(f\"   Chunks: {result['total_chunks']}\")\n",
    "print(f\"   Tempo: {result['time_seconds']}s\")\n",
    "print(f\"   Velocidade: {result['total_chunks'] / result['time_seconds']:.1f} chunks/s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1230f2",
   "metadata": {},
   "source": [
    "## 5. Usando Diferentes Modelos de IA\n",
    "\n",
    "Voc√™ pode trocar o modelo facilmente. Exemplos de modelos Ollama para embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c95f9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando modelo Qwen (recomendado para portugu√™s)\n",
    "result_qwen = create_embeddings(\n",
    "    documents=[\"./docs\"],\n",
    "    model_name=\"qwen3-embedding:4b\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150,\n",
    "    output_prefix=\"embeddings_qwen\"\n",
    ")\n",
    "\n",
    "# Usando modelo Llama2\n",
    "result_llama = create_embeddings(\n",
    "    documents=[\"./docs\"],\n",
    "    model_name=\"llama2\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150,\n",
    "    output_prefix=\"embeddings_llama\"\n",
    ")\n",
    "\n",
    "# Usando Nomic Embed (√≥timo para embeddings)\n",
    "result_nomic = create_embeddings(\n",
    "    documents=[\"./docs\"],\n",
    "    model_name=\"nomic-embed-text\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150,\n",
    "    output_prefix=\"embeddings_nomic\"\n",
    ")\n",
    "\n",
    "print(f\"Qwen: {result_qwen['total_chunks']} chunks\")\n",
    "print(f\"Llama: {result_llama['total_chunks']} chunks\")\n",
    "print(f\"Nomic: {result_nomic['total_chunks']} chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce927459",
   "metadata": {},
   "source": [
    "## 6. Ajustando Chunks para Diferentes Tipos de Documento\n",
    "\n",
    "Diferentes tipos de documentos podem precisar de configura√ß√µes diferentes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7034b0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para artigos t√©cnicos/cient√≠ficos - chunks maiores para preservar contexto\n",
    "tech_docs = create_embeddings(\n",
    "    documents=[\"./artigos_cientificos\"],\n",
    "    model_name=\"qwen3-embedding:4b\",\n",
    "    chunk_size=1500,      # Chunks grandes\n",
    "    chunk_overlap=250,    # Overlap maior para n√£o perder contexto\n",
    "    output_prefix=\"indice_tecnico\"\n",
    ")\n",
    "\n",
    "# Para dados tabulares (CSV/Excel) - chunks menores\n",
    "tabular_data = create_embeddings(\n",
    "    documents=[\"./planilhas\"],\n",
    "    model_name=\"qwen3-embedding:4b\",\n",
    "    chunk_size=500,       # Chunks pequenos\n",
    "    chunk_overlap=50,     # Overlap m√≠nimo\n",
    "    output_prefix=\"indice_dados\"\n",
    ")\n",
    "\n",
    "# Para documentos mistos - configura√ß√£o balanceada\n",
    "mixed_docs = create_embeddings(\n",
    "    documents=[\"./documentos_variados\"],\n",
    "    model_name=\"qwen3-embedding:4b\",\n",
    "    chunk_size=1000,      # Tamanho m√©dio\n",
    "    chunk_overlap=150,    # Overlap m√©dio\n",
    "    output_prefix=\"indice_geral\"\n",
    ")\n",
    "\n",
    "print(f\"T√©cnicos: {tech_docs['total_chunks']} chunks\")\n",
    "print(f\"Tabulares: {tabular_data['total_chunks']} chunks\")\n",
    "print(f\"Mistos: {mixed_docs['total_chunks']} chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953ff708",
   "metadata": {},
   "source": [
    "## 7. Otimizando Performance\n",
    "\n",
    "Ajuste `batch_size` e `num_workers` conforme seus recursos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dffdfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configura√ß√£o para M√ÅXIMA VELOCIDADE (usa mais recursos)\n",
    "fast_config = create_embeddings(\n",
    "    documents=[\"./docs\"],\n",
    "    model_name=\"qwen3-embedding:4b\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150,\n",
    "    batch_size=1024,      # Lotes grandes (usa mais RAM)\n",
    "    num_workers=16,       # Muitas threads (usa mais CPU)\n",
    "    output_prefix=\"fast_index\"\n",
    ")\n",
    "\n",
    "# Configura√ß√£o para M√çNIMO USO DE RECURSOS (mais lento, mas seguro)\n",
    "safe_config = create_embeddings(\n",
    "    documents=[\"./docs\"],\n",
    "    model_name=\"qwen3-embedding:4b\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150,\n",
    "    batch_size=128,       # Lotes pequenos (menos RAM)\n",
    "    num_workers=2,        # Poucas threads (menos CPU)\n",
    "    output_prefix=\"safe_index\"\n",
    ")\n",
    "\n",
    "# Configura√ß√£o BALANCEADA (recomendado)\n",
    "balanced_config = create_embeddings(\n",
    "    documents=[\"./docs\"],\n",
    "    model_name=\"qwen3-embedding:4b\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150,\n",
    "    batch_size=512,       # Lotes m√©dios\n",
    "    num_workers=4,        # Threads moderadas\n",
    "    output_prefix=\"balanced_index\"\n",
    ")\n",
    "\n",
    "print(\"Configura√ß√µes testadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049a5dec",
   "metadata": {},
   "source": [
    "## 8. Resumo dos Par√¢metros\n",
    "\n",
    "Refer√™ncia r√°pida de todos os par√¢metros dispon√≠veis:\n",
    "\n",
    "| Par√¢metro | Tipo | Padr√£o | Descri√ß√£o |\n",
    "|-----------|------|--------|-----------|\n",
    "| `documents` | Lista[str] | **Obrigat√≥rio** | Arquivos ou diret√≥rios para processar |\n",
    "| `model_name` | str | \"qwen3-embedding:4b\" | Modelo Ollama para embeddings |\n",
    "| `chunk_size` | int | 1000 | Tamanho m√°ximo de cada chunk (caracteres) |\n",
    "| `chunk_overlap` | int | 150 | Sobreposi√ß√£o entre chunks (caracteres) |\n",
    "| `batch_size` | int | 512 | Chunks a processar por vez |\n",
    "| `num_workers` | int | 4 | N√∫mero de threads paralelas |\n",
    "| `output_prefix` | str | \"vector_index\" | Prefixo dos arquivos de sa√≠da |\n",
    "\n",
    "### Formatos Suportados:\n",
    "- üìÑ **PDF** - Documentos de texto\n",
    "- üìä **CSV** - Planilhas de dados\n",
    "- üì¶ **Parquet** - Dados colunares\n",
    "- üìà **Excel** (.xlsx, .xls) - Planilhas do Microsoft Excel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56ff73f",
   "metadata": {},
   "source": [
    "## 9. Exemplo Pr√°tico Completo\n",
    "\n",
    "Use este exemplo como template para seus projetos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3a8d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "EXEMPLO PR√ÅTICO: Criar embeddings de uma base de conhecimento\n",
    "\"\"\"\n",
    "\n",
    "# Passo 1: Definir configura√ß√µes\n",
    "MODELO = \"qwen3-embedding:4b\"  # Escolha seu modelo\n",
    "DOCUMENTOS = [\n",
    "    \"./base_conhecimento/pdfs\",\n",
    "    \"./base_conhecimento/dados.csv\",\n",
    "    \"./base_conhecimento/relatorio.xlsx\"\n",
    "]\n",
    "TAMANHO_CHUNK = 1000\n",
    "OVERLAP_CHUNK = 150\n",
    "NOME_INDICE = \"base_conhecimento_index\"\n",
    "\n",
    "# Passo 2: Criar embeddings\n",
    "print(\"üöÄ Iniciando processamento...\")\n",
    "print(f\"üìÅ Documentos: {DOCUMENTOS}\")\n",
    "print(f\"ü§ñ Modelo: {MODELO}\")\n",
    "print(f\"üìè Chunk size: {TAMANHO_CHUNK} | Overlap: {OVERLAP_CHUNK}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "resultado = create_embeddings(\n",
    "    documents=DOCUMENTOS,\n",
    "    model_name=MODELO,\n",
    "    chunk_size=TAMANHO_CHUNK,\n",
    "    chunk_overlap=OVERLAP_CHUNK,\n",
    "    batch_size=512,\n",
    "    num_workers=4,\n",
    "    output_prefix=NOME_INDICE\n",
    ")\n",
    "\n",
    "# Passo 3: Exibir resultados\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ PROCESSAMENTO CONCLU√çDO!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"üìä Total de chunks criados: {resultado['total_chunks']}\")\n",
    "print(f\"‚è±Ô∏è  Tempo de processamento: {resultado['time_seconds']}s\")\n",
    "print(f\"‚ö° Velocidade m√©dia: {resultado['total_chunks']/resultado['time_seconds']:.1f} chunks/s\")\n",
    "print(f\"\\nüìÇ Arquivos gerados:\")\n",
    "print(f\"   ‚Ä¢ √çndice FAISS: {resultado['faiss_path']}\")\n",
    "print(f\"   ‚Ä¢ Metadados: {resultado['metadata_path']}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Passo 4: Os arquivos est√£o prontos para uso em um sistema RAG!\n",
    "print(\"\\nüí° Pr√≥ximos passos:\")\n",
    "print(\"   1. Use o arquivo .faiss para busca vetorial\")\n",
    "print(\"   2. Use o arquivo .jsonl para recuperar metadados\")\n",
    "print(\"   3. Integre com seu sistema de chat/RAG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb276b9",
   "metadata": {},
   "source": [
    "## 10. Recursos Profissionais de Alta Qualidade\n",
    "\n",
    "O sistema agora inclui **melhores pr√°ticas da ind√∫stria** para RAG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efedab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ CONFIGURA√á√ÉO PROFISSIONAL COMPLETA COM DETEC√á√ÉO AUTOM√ÅTICA\n",
    "result = create_embeddings(\n",
    "    documents=[\"./docs\"],\n",
    "    model_name=\"qwen3-embedding:4b\",\n",
    "    \n",
    "    # Chunking\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150,\n",
    "    min_chunk_size=50,  # ‚úÖ Ignora chunks muito pequenos\n",
    "    \n",
    "    # Qualidade RAG\n",
    "    normalize_embeddings=True,  # ‚úÖ CR√çTICO para similaridade coseno\n",
    "    deduplicate=True,  # ‚úÖ Remove chunks duplicados\n",
    "    add_document_context=True,  # ‚úÖ Adiciona contexto do documento pai\n",
    "    \n",
    "    # üÜï DETEC√á√ÉO AUTOM√ÅTICA DE √çNDICE (RECOMENDADO)\n",
    "    # use_ivf_index=None (padr√£o)  - Sistema decide automaticamente\n",
    "    # use_ivf_index=True           - For√ßa IVF (grande escala)\n",
    "    # use_ivf_index=False          - For√ßa Flat (pequena escala)\n",
    "    \n",
    "    # Se omitir use_ivf_index, o sistema decide automaticamente:\n",
    "    # - < 10.000 chunks ‚Üí IndexFlatL2 (busca exata, r√°pida)\n",
    "    # - ‚â• 10.000 chunks ‚Üí IndexIVFFlat (busca aproximada, escal√°vel)\n",
    "    \n",
    "    ivf_threshold=10000,  # Threshold para ativar IVF (padr√£o: 10k)\n",
    "    ivf_nlist=100,  # Clusters IVF (s√≥ usado se IVF for ativado)\n",
    "    \n",
    "    # Metadados customizados\n",
    "    custom_metadata={\n",
    "        \"project\": \"Sistema RAG\",\n",
    "        \"version\": \"2.0\",\n",
    "        \"team\": \"IA\",\n",
    "        \"environment\": \"production\"\n",
    "    },\n",
    "    \n",
    "    # Performance\n",
    "    batch_size=512,\n",
    "    num_workers=4,\n",
    "    output_prefix=\"rag_profissional\"\n",
    ")\n",
    "\n",
    "# ‚úÖ Estat√≠sticas detalhadas dispon√≠veis\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"ESTAT√çSTICAS PROFISSIONAIS\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"‚úÖ Chunks √∫nicos indexados: {result['total_chunks']}\")\n",
    "print(f\"üóëÔ∏è  Duplicados removidos: {result['duplicates_removed']}\")\n",
    "print(f\"üìÅ Arquivos processados: {result['files_processed']}\")\n",
    "print(f\"‚è±Ô∏è  Tempo total: {result['time_seconds']}s\")\n",
    "print(f\"‚ö° Velocidade: {result['chunks_per_second']} chunks/s\")\n",
    "print(f\"üìä Dimens√£o embedding: {result['embedding_dimension']}\")\n",
    "print(f\"üîß Tipo de √≠ndice: {result['index_type']}\")\n",
    "print(f\"ü§ñ Sele√ß√£o autom√°tica: {'Sim' if result['index_auto_selected'] else 'N√£o (for√ßado pelo usu√°rio)'}\")\n",
    "print(f\"\\nüìÇ Arquivos gerados:\")\n",
    "print(f\"   ‚Ä¢ FAISS: {result['faiss_path']}\")\n",
    "print(f\"   ‚Ä¢ Metadados: {result['metadata_path']}\")\n",
    "print(f\"   ‚Ä¢ Estat√≠sticas: {result['stats_path']}\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# üí° EXPLICA√á√ÉO DA SELE√á√ÉO AUTOM√ÅTICA\n",
    "if result['index_auto_selected']:\n",
    "    if result['index_type'] == 'IVF':\n",
    "        print(\"\\nüí° Sistema detectou GRANDE VOLUME (‚â•10k chunks)\")\n",
    "        print(\"   ‚Üí IndexIVFFlat selecionado automaticamente\")\n",
    "        print(\"   ‚Üí Busca aproximada, mas 10-100x mais r√°pida\")\n",
    "    else:\n",
    "        print(\"\\nüí° Sistema detectou VOLUME MODERADO (<10k chunks)\")\n",
    "        print(\"   ‚Üí IndexFlatL2 selecionado automaticamente\")\n",
    "        print(\"   ‚Üí Busca exata e r√°pida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4129330",
   "metadata": {},
   "source": [
    "## 11. üÜï Detec√ß√£o Autom√°tica de √çndice FAISS\n",
    "\n",
    "**NOVIDADE PROFISSIONAL:** O sistema agora escolhe automaticamente o melhor tipo de √≠ndice baseado no volume de documentos!\n",
    "\n",
    "### Como Funciona:\n",
    "\n",
    "| Volume de Chunks | √çndice Selecionado | Caracter√≠sticas |\n",
    "|------------------|-------------------|-----------------|\n",
    "| **< 10.000** | IndexFlatL2 | Busca exata, muito r√°pida |\n",
    "| **‚â• 10.000** | IndexIVFFlat | Busca aproximada, escal√°vel |\n",
    "\n",
    "### Por que isso √© importante?\n",
    "\n",
    "- ‚úÖ **Voc√™ n√£o precisa decidir** - o sistema otimiza automaticamente\n",
    "- ‚úÖ **Performance ideal** - sempre usa o √≠ndice mais apropriado\n",
    "- ‚úÖ **Escalabilidade** - funciona bem de 100 a 1 milh√£o de chunks\n",
    "- ‚úÖ **Padr√£o da ind√∫stria** - mesmo comportamento do LlamaIndex/LangChain\n",
    "\n",
    "### Voc√™ ainda tem controle (se quiser):\n",
    "\n",
    "```python\n",
    "# Detec√ß√£o autom√°tica (RECOMENDADO - deixe vazio ou omita)\n",
    "result = create_embeddings(documents=[\"./docs\"])\n",
    "\n",
    "# For√ßar Flat (busca exata)\n",
    "result = create_embeddings(documents=[\"./docs\"], use_ivf_index=False)\n",
    "\n",
    "# For√ßar IVF (grande escala)\n",
    "result = create_embeddings(documents=[\"./docs\"], use_ivf_index=True)\n",
    "\n",
    "# Ajustar threshold (padr√£o: 10.000)\n",
    "result = create_embeddings(documents=[\"./docs\"], ivf_threshold=15000)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8970d135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo 1: Detec√ß√£o autom√°tica com documentos pequenos\n",
    "pequeno = create_embeddings(\n",
    "    documents=[\"./pequeno_dataset\"],  # < 10k chunks\n",
    "    model_name=\"qwen3-embedding:4b\",\n",
    "    output_prefix=\"indice_pequeno\"\n",
    ")\n",
    "print(f\"Dataset pequeno ‚Üí √çndice: {pequeno['index_type']}\")\n",
    "print(f\"Sele√ß√£o autom√°tica: {pequeno['index_auto_selected']}\")\n",
    "\n",
    "# Exemplo 2: Detec√ß√£o autom√°tica com documentos grandes\n",
    "grande = create_embeddings(\n",
    "    documents=[\"./grande_dataset\"],  # ‚â• 10k chunks\n",
    "    model_name=\"qwen3-embedding:4b\",\n",
    "    output_prefix=\"indice_grande\"\n",
    ")\n",
    "print(f\"\\nDataset grande ‚Üí √çndice: {grande['index_type']}\")\n",
    "print(f\"Sele√ß√£o autom√°tica: {grande['index_auto_selected']}\")\n",
    "\n",
    "# Exemplo 3: Ajustando o threshold\n",
    "custom = create_embeddings(\n",
    "    documents=[\"./meus_docs\"],\n",
    "    model_name=\"qwen3-embedding:4b\",\n",
    "    ivf_threshold=15000,  # S√≥ usa IVF se tiver 15k+ chunks\n",
    "    output_prefix=\"indice_custom\"\n",
    ")\n",
    "print(f\"\\nThreshold customizado (15k) ‚Üí √çndice: {custom['index_type']}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
