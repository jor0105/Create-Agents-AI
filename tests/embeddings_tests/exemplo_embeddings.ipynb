{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b73494c",
   "metadata": {},
   "source": [
    "# üöÄ Pipeline RAG Profissional - Vers√£o 2.0 Refatorada\n",
    "\n",
    "Este notebook demonstra como usar a fun√ß√£o `create_embeddings()` do m√≥dulo **`indexar.py`** (vers√£o 2.0 refatorada) para processar documentos e criar embeddings de alta qualidade.\n",
    "\n",
    "## üéØ Principais Melhorias da v2.0:\n",
    "\n",
    "### ‚úÖ Corre√ß√µes Cr√≠ticas\n",
    "- ‚úÖ **Overlap inteligente** - N√£o corta mais palavras no meio\n",
    "- ‚úÖ **Normaliza√ß√£o otimizada** - Elimina redund√¢ncia (~30% mais r√°pido)\n",
    "- ‚úÖ **Gest√£o de recursos** - Context managers garantem limpeza\n",
    "- ‚úÖ **Valida√ß√£o robusta** - Verifica par√¢metros e modelo\n",
    "- ‚úÖ **Interrup√ß√£o graciosa** - Ctrl+C salva progresso\n",
    "\n",
    "### üÜï Novas Funcionalidades\n",
    "- üÜï **Detec√ß√£o autom√°tica de √≠ndice** - Escolhe Flat ou IVF baseado no volume\n",
    "- üÜï **Chunk com slots** - 40% menos mem√≥ria\n",
    "- üÜï **Logging estruturado** - M√©tricas em JSON\n",
    "- üÜï **Type hints completos** - C√≥digo 100% correto\n",
    "- üÜï **Suite de testes** - Valida√ß√£o automatizada\n",
    "\n",
    "## üìö Documenta√ß√£o Completa:\n",
    "- `ANALISE_CODIGO_RAG.md` - An√°lise profissional detalhada\n",
    "- `MELHORIAS_APLICADAS.md` - Log de todas as corre√ß√µes\n",
    "- `GUIA_RAPIDO.md` - Refer√™ncia r√°pida\n",
    "- `SUMARIO_REFATORACAO.md` - Resumo executivo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d242ddd",
   "metadata": {},
   "source": [
    "## 1. Importar a Fun√ß√£o Principal\n",
    "\n",
    "Basta importar a fun√ß√£o `create_embeddings` do m√≥dulo `indexar_novo.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bffa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from indexar import create_embeddings\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e86733d",
   "metadata": {},
   "source": [
    "## 2. Exemplo B√°sico - Uso Mais Simples\n",
    "\n",
    "Este √© o jeito mais simples de usar. Apenas especifique:\n",
    "- Lista de documentos (arquivos ou diret√≥rios)\n",
    "- Modelo do Ollama\n",
    "- Configura√ß√µes de chunk (tamanho e overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e18354a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ö° EXEMPLO B√ÅSICO - Uso Mais Simples\n",
    "# Sistema escolhe automaticamente o melhor √≠ndice (Flat ou IVF)\n",
    "\n",
    "result = create_embeddings(\n",
    "    documents=[\"./docs\"],\n",
    "    model_name=\"qwen3-embedding:4b\"\n",
    ")\n",
    "\n",
    "# Resultado cont√©m estat√≠sticas detalhadas\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"‚úÖ PROCESSAMENTO CONCLU√çDO\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"üìä Chunks √∫nicos indexados: {result['total_chunks']}\")\n",
    "print(f\"üóëÔ∏è  Duplicados removidos: {result['duplicates_removed']}\")\n",
    "print(f\"‚è±Ô∏è  Tempo: {result['time_seconds']}s ({result['chunks_per_second']} chunks/s)\")\n",
    "print(f\"üìÅ Arquivos: {result['files_processed']} processados | {result['files_failed']} falharam\")\n",
    "print(f\"üîß √çndice: {result['index_type']} {'(autom√°tico)' if result['index_auto_selected'] else '(manual)'}\")\n",
    "print(f\"üìê Dimens√£o: {result['embedding_dimension']}\")\n",
    "print(f\"\\nüìÇ Arquivos gerados:\")\n",
    "print(f\"   ‚Ä¢ {result['faiss_path']}\")\n",
    "print(f\"   ‚Ä¢ {result['metadata_path']}\")\n",
    "print(f\"   ‚Ä¢ {result['stats_path']}\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8909d7bd",
   "metadata": {},
   "source": [
    "## 3. Exemplo com Arquivos Espec√≠ficos\n",
    "\n",
    "Voc√™ pode especificar arquivos individuais em vez de diret√≥rios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec60e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processar arquivos espec√≠ficos\n",
    "result = create_embeddings(\n",
    "    documents=[\n",
    "        \"artigo1.pdf\",\n",
    "        \"dados.csv\",\n",
    "        \"relatorio.parquet\",\n",
    "        \"planilha.xlsx\"\n",
    "    ],\n",
    "    model_name=\"qwen3-embedding:4b\",\n",
    "    chunk_size=800,           # Chunks menores\n",
    "    chunk_overlap=100,        # Menos overlap\n",
    "    output_prefix=\"arquivos_especificos\"\n",
    ")\n",
    "\n",
    "print(f\"‚úì {result['total_chunks']} chunks processados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cfa4e0",
   "metadata": {},
   "source": [
    "## 4. Customizando Todos os Par√¢metros\n",
    "\n",
    "Voc√™ tem controle total sobre todos os aspectos do processamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963a8af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéõÔ∏è CONFIGURA√á√ÉO AVAN√áADA - Controle Total\n",
    "result = create_embeddings(\n",
    "    documents=[\"./docs\", \"./reports\"],\n",
    "    model_name=\"qwen3-embedding:4b\",\n",
    "    \n",
    "    # Chunking\n",
    "    chunk_size=800,              # Tamanho de cada chunk\n",
    "    chunk_overlap=100,           # Overlap entre chunks\n",
    "    min_chunk_size=50,           # Ignora chunks muito pequenos\n",
    "    \n",
    "    # Otimiza√ß√µes\n",
    "    normalize_embeddings=True,   # Normaliza vetores (recomendado)\n",
    "    deduplicate=True,            # Remove duplicados (recomendado)\n",
    "    add_document_context=True,   # Adiciona metadados do documento\n",
    "    \n",
    "    # Performance\n",
    "    batch_size=256,              # Chunks por lote\n",
    "    num_workers=8,               # Threads paralelas\n",
    "    \n",
    "    # √çndice FAISS (None = autom√°tico - RECOMENDADO)\n",
    "    use_ivf_index=None,          # Sistema decide automaticamente\n",
    "    ivf_threshold=10000,         # Ativa IVF com 10k+ chunks\n",
    "    ivf_nlist=100,               # Clusters para IVF\n",
    "    \n",
    "    # Logging\n",
    "    enable_structured_logging=True,  # Salva m√©tricas em JSON\n",
    "    \n",
    "    # Sa√≠da\n",
    "    output_prefix=\"my_index\",\n",
    "    \n",
    "    # Metadados customizados\n",
    "    custom_metadata={\n",
    "        \"project\": \"Financial RAG\",\n",
    "        \"version\": \"2.0\",\n",
    "        \"author\": \"Jordan\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Estat√≠sticas Detalhadas:\")\n",
    "print(f\"   Chunks processados: {result['chunks_processed']}\")\n",
    "print(f\"   Chunks falharam: {result['chunks_failed']}\")\n",
    "print(f\"   Velocidade: {result['chunks_per_second']:.1f} chunks/s\")\n",
    "print(f\"\\n   Embeddings gerados: {result['embeddings_stats']['embeddings_generated']}\")\n",
    "print(f\"   Normaliza√ß√µes aplicadas: {result['embeddings_stats']['normalizations_applied']}\")\n",
    "if result['embeddings_stats']['normalizations_applied'] == 0:\n",
    "    print(f\"   ‚úÖ Modelo j√° retorna embeddings normalizados!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1230f2",
   "metadata": {},
   "source": [
    "## 5. Usando Diferentes Modelos de IA\n",
    "\n",
    "Voc√™ pode trocar o modelo facilmente. Exemplos de modelos Ollama para embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c95f9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando modelo Qwen (recomendado para portugu√™s)\n",
    "result_qwen = create_embeddings(\n",
    "    documents=[\"./docs\"],\n",
    "    model_name=\"qwen3-embedding:4b\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150,\n",
    "    output_prefix=\"embeddings_qwen\"\n",
    ")\n",
    "\n",
    "# Usando modelo Llama2\n",
    "result_llama = create_embeddings(\n",
    "    documents=[\"./docs\"],\n",
    "    model_name=\"llama2\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150,\n",
    "    output_prefix=\"embeddings_llama\"\n",
    ")\n",
    "\n",
    "# Usando Nomic Embed (√≥timo para embeddings)\n",
    "result_nomic = create_embeddings(\n",
    "    documents=[\"./docs\"],\n",
    "    model_name=\"nomic-embed-text\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150,\n",
    "    output_prefix=\"embeddings_nomic\"\n",
    ")\n",
    "\n",
    "print(f\"Qwen: {result_qwen['total_chunks']} chunks\")\n",
    "print(f\"Llama: {result_llama['total_chunks']} chunks\")\n",
    "print(f\"Nomic: {result_nomic['total_chunks']} chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce927459",
   "metadata": {},
   "source": [
    "## 6. Ajustando Chunks para Diferentes Tipos de Documento\n",
    "\n",
    "Diferentes tipos de documentos podem precisar de configura√ß√µes diferentes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7034b0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÑ CONFIGURA√á√ïES RECOMENDADAS POR TIPO DE DOCUMENTO\n",
    "\n",
    "# Para documentos PEQUENOS (< 100 arquivos)\n",
    "pequeno = create_embeddings(\n",
    "    documents=[\"./docs_pequenos\"],\n",
    "    model_name=\"qwen3-embedding:4b\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150,\n",
    "    batch_size=512,\n",
    "    num_workers=4,\n",
    "    use_ivf_index=False,  # Flat index (busca exata)\n",
    "    output_prefix=\"index_pequeno\"\n",
    ")\n",
    "print(f\"Pequeno: {pequeno['total_chunks']} chunks | √çndice: {pequeno['index_type']}\")\n",
    "\n",
    "# Para documentos M√âDIOS (100-1000 arquivos)\n",
    "medio = create_embeddings(\n",
    "    documents=[\"./docs_medios\"],\n",
    "    model_name=\"qwen3-embedding:4b\",\n",
    "    chunk_size=800,\n",
    "    chunk_overlap=100,\n",
    "    batch_size=256,\n",
    "    num_workers=8,\n",
    "    use_ivf_index=None,  # Autom√°tico - deixa sistema decidir\n",
    "    output_prefix=\"index_medio\"\n",
    ")\n",
    "print(f\"M√©dio: {medio['total_chunks']} chunks | √çndice: {medio['index_type']}\")\n",
    "\n",
    "# Para documentos GRANDES (> 1000 arquivos)\n",
    "grande = create_embeddings(\n",
    "    documents=[\"./docs_grandes\"],\n",
    "    model_name=\"qwen3-embedding:4b\",\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=80,\n",
    "    batch_size=128,\n",
    "    num_workers=12,\n",
    "    use_ivf_index=True,  # IVF index (escal√°vel)\n",
    "    ivf_nlist=200,\n",
    "    output_prefix=\"index_grande\"\n",
    ")\n",
    "print(f\"Grande: {grande['total_chunks']} chunks | √çndice: {grande['index_type']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953ff708",
   "metadata": {},
   "source": [
    "## 7. Otimizando Performance\n",
    "\n",
    "Ajuste `batch_size` e `num_workers` conforme seus recursos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dffdfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ö° OTIMIZA√á√ÉO DE PERFORMANCE\n",
    "\n",
    "# Configura√ß√£o para M√ÅXIMA VELOCIDADE (usa mais recursos)\n",
    "fast = create_embeddings(\n",
    "    documents=[\"./docs\"],\n",
    "    model_name=\"qwen3-embedding:4b\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150,\n",
    "    batch_size=1024,      # Lotes grandes (usa mais RAM)\n",
    "    num_workers=16,       # Muitas threads (usa mais CPU)\n",
    "    output_prefix=\"fast_index\"\n",
    ")\n",
    "print(f\"‚ö° Velocidade m√°xima: {fast['chunks_per_second']:.1f} chunks/s\")\n",
    "\n",
    "# Configura√ß√£o para M√çNIMO USO DE RECURSOS (mais lento, mas seguro)\n",
    "safe = create_embeddings(\n",
    "    documents=[\"./docs\"],\n",
    "    model_name=\"qwen3-embedding:4b\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150,\n",
    "    batch_size=128,       # Lotes pequenos (menos RAM)\n",
    "    num_workers=2,        # Poucas threads (menos CPU)\n",
    "    output_prefix=\"safe_index\"\n",
    ")\n",
    "print(f\"üêå Modo seguro: {safe['chunks_per_second']:.1f} chunks/s\")\n",
    "\n",
    "# Configura√ß√£o BALANCEADA (RECOMENDADO para maioria dos casos)\n",
    "balanced = create_embeddings(\n",
    "    documents=[\"./docs\"],\n",
    "    model_name=\"qwen3-embedding:4b\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150,\n",
    "    batch_size=512,       # Lotes m√©dios\n",
    "    num_workers=4,        # Threads moderadas\n",
    "    output_prefix=\"balanced_index\"\n",
    ")\n",
    "print(f\"‚öñÔ∏è  Balanceado: {balanced['chunks_per_second']:.1f} chunks/s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049a5dec",
   "metadata": {},
   "source": [
    "## 8. üìã Refer√™ncia Completa de Par√¢metros\n",
    "\n",
    "### Par√¢metros Principais:\n",
    "\n",
    "| Par√¢metro | Tipo | Padr√£o | Descri√ß√£o |\n",
    "|-----------|------|--------|-----------|\n",
    "| `documents` | List[str] | **Obrigat√≥rio** | Arquivos ou diret√≥rios para processar |\n",
    "| `model_name` | str | **Obrigat√≥rio** | Modelo Ollama para embeddings |\n",
    "| `chunk_size` | int | 1000 | Tamanho m√°ximo de cada chunk (caracteres) |\n",
    "| `chunk_overlap` | int | 150 | Sobreposi√ß√£o entre chunks (caracteres) |\n",
    "| `min_chunk_size` | int | 50 | Tamanho m√≠nimo para chunk (ignora menores) |\n",
    "\n",
    "### Par√¢metros de Qualidade (NOVOS v2.0):\n",
    "\n",
    "| Par√¢metro | Tipo | Padr√£o | Descri√ß√£o |\n",
    "|-----------|------|--------|-----------|\n",
    "| `normalize_embeddings` | bool | True | Normaliza vetores (recomendado) |\n",
    "| `deduplicate` | bool | True | Remove chunks duplicados |\n",
    "| `add_document_context` | bool | True | Adiciona metadados do documento |\n",
    "\n",
    "### Par√¢metros de √çndice FAISS (NOVOS v2.0):\n",
    "\n",
    "| Par√¢metro | Tipo | Padr√£o | Descri√ß√£o |\n",
    "|-----------|------|--------|-----------|\n",
    "| `use_ivf_index` | bool/None | None | None=autom√°tico, True=IVF, False=Flat |\n",
    "| `ivf_threshold` | int | 10000 | Threshold para ativar IVF automaticamente |\n",
    "| `ivf_nlist` | int | 100 | N√∫mero de clusters para IVF |\n",
    "\n",
    "### Par√¢metros de Performance:\n",
    "\n",
    "| Par√¢metro | Tipo | Padr√£o | Descri√ß√£o |\n",
    "|-----------|------|--------|-----------|\n",
    "| `batch_size` | int | 512 | Chunks a processar por vez |\n",
    "| `num_workers` | int | 4 | N√∫mero de threads paralelas |\n",
    "\n",
    "### Par√¢metros de Sa√≠da:\n",
    "\n",
    "| Par√¢metro | Tipo | Padr√£o | Descri√ß√£o |\n",
    "|-----------|------|--------|-----------|\n",
    "| `output_prefix` | str | \"vector_index\" | Prefixo dos arquivos de sa√≠da |\n",
    "| `enable_structured_logging` | bool | True | Salva m√©tricas em JSON |\n",
    "| `custom_metadata` | dict | None | Metadados customizados |\n",
    "\n",
    "### Formatos Suportados:\n",
    "\n",
    "- üìÑ **PDF** - Documentos de texto (PyMuPDF)\n",
    "- üìä **CSV** - Planilhas de dados\n",
    "- üì¶ **Parquet** - Dados colunares\n",
    "- üìà **Excel** (.xlsx, .xls) - Planilhas Microsoft Excel\n",
    "- üìù **TXT/MD** - Arquivos de texto simples\n",
    "\n",
    "### Arquivos Gerados:\n",
    "\n",
    "- `{prefix}.faiss` - √çndice FAISS com vetores\n",
    "- `{prefix}.jsonl` - Metadados de cada chunk (inclui `content` para BM25)\n",
    "- `{prefix}_stats.json` - Estat√≠sticas do √≠ndice\n",
    "- `{prefix}_metrics.jsonl` - M√©tricas estruturadas (se logging ativado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56ff73f",
   "metadata": {},
   "source": [
    "## 9. Exemplo Pr√°tico Completo\n",
    "\n",
    "Use este exemplo como template para seus projetos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3a8d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "üéØ EXEMPLO PR√ÅTICO COMPLETO\n",
    "Template otimizado para seus projetos\n",
    "\"\"\"\n",
    "\n",
    "# Configura√ß√µes\n",
    "MODELO = \"qwen3-embedding:4b\"\n",
    "DOCUMENTOS = [\n",
    "    \"./base_conhecimento/pdfs\",\n",
    "    \"./base_conhecimento/dados.csv\",\n",
    "    \"./base_conhecimento/relatorio.xlsx\"\n",
    "]\n",
    "TAMANHO_CHUNK = 800\n",
    "OVERLAP_CHUNK = 100\n",
    "NOME_INDICE = \"base_conhecimento\"\n",
    "\n",
    "# Processamento\n",
    "print(\"üöÄ Iniciando processamento...\")\n",
    "print(f\"üìÅ Documentos: {len(DOCUMENTOS)} fontes\")\n",
    "print(f\"ü§ñ Modelo: {MODELO}\")\n",
    "print(f\"üìè Chunk: {TAMANHO_CHUNK} chars | Overlap: {OVERLAP_CHUNK} chars\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "try:\n",
    "    resultado = create_embeddings(\n",
    "        documents=DOCUMENTOS,\n",
    "        model_name=MODELO,\n",
    "        chunk_size=TAMANHO_CHUNK,\n",
    "        chunk_overlap=OVERLAP_CHUNK,\n",
    "        \n",
    "        # Otimiza√ß√µes recomendadas\n",
    "        normalize_embeddings=True,\n",
    "        deduplicate=True,\n",
    "        add_document_context=True,\n",
    "        \n",
    "        # Performance balanceada\n",
    "        batch_size=512,\n",
    "        num_workers=4,\n",
    "        \n",
    "        # Detec√ß√£o autom√°tica de √≠ndice\n",
    "        use_ivf_index=None,\n",
    "        \n",
    "        # Logging e sa√≠da\n",
    "        enable_structured_logging=True,\n",
    "        output_prefix=NOME_INDICE\n",
    "    )\n",
    "    \n",
    "    # Resultados\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"‚úÖ PROCESSAMENTO CONCLU√çDO COM SUCESSO!\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"üìä Chunks √∫nicos: {resultado['total_chunks']}\")\n",
    "    print(f\"üóëÔ∏è  Duplicados: {resultado['duplicates_removed']}\")\n",
    "    print(f\"‚è±Ô∏è  Tempo: {resultado['time_seconds']:.1f}s\")\n",
    "    print(f\"‚ö° Velocidade: {resultado['chunks_per_second']:.1f} chunks/s\")\n",
    "    print(f\"üîß √çndice: {resultado['index_type']}\")\n",
    "    print(f\"\\nüìÇ Arquivos criados:\")\n",
    "    print(f\"   ‚úì {resultado['faiss_path']}\")\n",
    "    print(f\"   ‚úì {resultado['metadata_path']}\")\n",
    "    print(f\"   ‚úì {resultado['stats_path']}\")\n",
    "    \n",
    "    if resultado.get('enable_structured_logging'):\n",
    "        print(f\"   ‚úì {NOME_INDICE}_metrics.jsonl\")\n",
    "    \n",
    "    print(\"\\nüí° Pr√≥ximos passos:\")\n",
    "    print(\"   1. Use perguntar.py para fazer queries\")\n",
    "    print(\"   2. Analise m√©tricas em *_metrics.jsonl\")\n",
    "    print(\"   3. Integre com seu sistema RAG\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "except ValueError as e:\n",
    "    print(f\"\\n‚ùå Erro de valida√ß√£o: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Erro durante processamento: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb276b9",
   "metadata": {},
   "source": [
    "## 10. Recursos Profissionais de Alta Qualidade\n",
    "\n",
    "O sistema agora inclui **melhores pr√°ticas da ind√∫stria** para RAG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efedab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üèÜ CONFIGURA√á√ÉO PROFISSIONAL COMPLETA\n",
    "# Usa TODAS as melhores pr√°ticas da v2.0\n",
    "\n",
    "result = create_embeddings(\n",
    "    documents=[\"./docs\"],\n",
    "    model_name=\"qwen3-embedding:4b\",\n",
    "    \n",
    "    # Chunking otimizado\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150,\n",
    "    min_chunk_size=50,  # Ignora chunks muito pequenos\n",
    "    \n",
    "    # Qualidade RAG\n",
    "    normalize_embeddings=True,      # ‚úÖ Para similaridade coseno\n",
    "    deduplicate=True,               # ‚úÖ Remove duplicados\n",
    "    add_document_context=True,      # ‚úÖ Contexto do documento\n",
    "    \n",
    "    # Detec√ß√£o autom√°tica de √≠ndice (RECOMENDADO)\n",
    "    use_ivf_index=None,             # None = autom√°tico\n",
    "    ivf_threshold=10000,            # < 10k = Flat, ‚â• 10k = IVF\n",
    "    ivf_nlist=100,                  # Clusters para IVF\n",
    "    \n",
    "    # Performance\n",
    "    batch_size=512,\n",
    "    num_workers=4,\n",
    "    \n",
    "    # Logging e metadados\n",
    "    enable_structured_logging=True,\n",
    "    custom_metadata={\n",
    "        \"project\": \"RAG System\",\n",
    "        \"version\": \"2.0\",\n",
    "        \"environment\": \"production\"\n",
    "    },\n",
    "    \n",
    "    output_prefix=\"rag_profissional\"\n",
    ")\n",
    "\n",
    "# An√°lise detalhada dos resultados\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"üìä ESTAT√çSTICAS PROFISSIONAIS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Processamento\n",
    "print(f\"\\nüîÑ PROCESSAMENTO:\")\n",
    "print(f\"   Chunks √∫nicos: {result['total_chunks']}\")\n",
    "print(f\"   Chunks processados: {result['chunks_processed']}\")\n",
    "print(f\"   Chunks falharam: {result['chunks_failed']}\")\n",
    "print(f\"   Duplicados removidos: {result['duplicates_removed']}\")\n",
    "\n",
    "# Arquivos\n",
    "print(f\"\\nüìÅ ARQUIVOS:\")\n",
    "print(f\"   Processados: {result['files_processed']}\")\n",
    "print(f\"   Falharam: {result['files_failed']}\")\n",
    "\n",
    "# Performance\n",
    "print(f\"\\n‚ö° PERFORMANCE:\")\n",
    "print(f\"   Tempo total: {result['time_seconds']:.2f}s\")\n",
    "print(f\"   Velocidade: {result['chunks_per_second']:.1f} chunks/s\")\n",
    "\n",
    "# Embeddings\n",
    "stats = result['embeddings_stats']\n",
    "print(f\"\\nüß¨ EMBEDDINGS:\")\n",
    "print(f\"   Gerados: {stats['embeddings_generated']}\")\n",
    "print(f\"   Normaliza√ß√µes aplicadas: {stats['normalizations_applied']}\")\n",
    "if stats['normalizations_applied'] == 0:\n",
    "    print(f\"   ‚úÖ Modelo j√° normaliza (otimizado!)\")\n",
    "else:\n",
    "    pct = (stats['normalizations_applied'] / stats['embeddings_generated']) * 100\n",
    "    print(f\"   ‚ö†Ô∏è  {pct:.1f}% precisaram normaliza√ß√£o\")\n",
    "\n",
    "# √çndice FAISS\n",
    "print(f\"\\nüîß √çNDICE FAISS:\")\n",
    "print(f\"   Tipo: {result['index_type']}\")\n",
    "print(f\"   Dimens√£o: {result['embedding_dimension']}\")\n",
    "print(f\"   Sele√ß√£o: {'Autom√°tica ‚úÖ' if result['index_auto_selected'] else 'Manual'}\")\n",
    "\n",
    "if result['index_auto_selected']:\n",
    "    if result['index_type'] == 'IVF':\n",
    "        print(f\"   üí° Volume grande detectado (‚â•{result['config']['ivf_threshold']} chunks)\")\n",
    "        print(f\"      ‚Üí IndexIVFFlat selecionado (busca aproximada, escal√°vel)\")\n",
    "    else:\n",
    "        print(f\"   üí° Volume moderado detectado (<{result['config']['ivf_threshold']} chunks)\")\n",
    "        print(f\"      ‚Üí IndexFlatL2 selecionado (busca exata, r√°pida)\")\n",
    "\n",
    "# Arquivos gerados\n",
    "print(f\"\\nüìÇ ARQUIVOS GERADOS:\")\n",
    "print(f\"   ‚úì {result['faiss_path']}\")\n",
    "print(f\"   ‚úì {result['metadata_path']}\")\n",
    "print(f\"   ‚úì {result['stats_path']}\")\n",
    "print(f\"   ‚úì rag_profissional_metrics.jsonl\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"‚úÖ Sistema pronto para RAG de alta qualidade!\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4129330",
   "metadata": {},
   "source": [
    "## 11. üÜï Detec√ß√£o Autom√°tica de √çndice FAISS\n",
    "\n",
    "**NOVIDADE PROFISSIONAL:** O sistema agora escolhe automaticamente o melhor tipo de √≠ndice baseado no volume de documentos!\n",
    "\n",
    "### Como Funciona:\n",
    "\n",
    "| Volume de Chunks | √çndice Selecionado | Caracter√≠sticas |\n",
    "|------------------|-------------------|-----------------|\n",
    "| **< 10.000** | IndexFlatL2 | Busca exata, muito r√°pida |\n",
    "| **‚â• 10.000** | IndexIVFFlat | Busca aproximada, escal√°vel |\n",
    "\n",
    "### Por que isso √© importante?\n",
    "\n",
    "- ‚úÖ **Voc√™ n√£o precisa decidir** - o sistema otimiza automaticamente\n",
    "- ‚úÖ **Performance ideal** - sempre usa o √≠ndice mais apropriado\n",
    "- ‚úÖ **Escalabilidade** - funciona bem de 100 a 1 milh√£o de chunks\n",
    "- ‚úÖ **Padr√£o da ind√∫stria** - mesmo comportamento do LlamaIndex/LangChain\n",
    "\n",
    "### Voc√™ ainda tem controle (se quiser):\n",
    "\n",
    "```python\n",
    "# Detec√ß√£o autom√°tica (RECOMENDADO - deixe vazio ou omita)\n",
    "result = create_embeddings(documents=[\"./docs\"])\n",
    "\n",
    "# For√ßar Flat (busca exata)\n",
    "result = create_embeddings(documents=[\"./docs\"], use_ivf_index=False)\n",
    "\n",
    "# For√ßar IVF (grande escala)\n",
    "result = create_embeddings(documents=[\"./docs\"], use_ivf_index=True)\n",
    "\n",
    "# Ajustar threshold (padr√£o: 10.000)\n",
    "result = create_embeddings(documents=[\"./docs\"], ivf_threshold=15000)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2119b21",
   "metadata": {},
   "source": [
    "## 12. üêõ Tratamento de Erros\n",
    "\n",
    "A vers√£o 2.0 possui **valida√ß√£o robusta** e mensagens de erro espec√≠ficas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135fc276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üêõ TRATAMENTO ROBUSTO DE ERROS\n",
    "\n",
    "# Erro 1: Modelo n√£o encontrado\n",
    "try:\n",
    "    result = create_embeddings(\n",
    "        documents=[\"./docs\"],\n",
    "        model_name=\"modelo-inexistente\"\n",
    "    )\n",
    "except ValueError as e:\n",
    "    print(f\"‚ùå Erro: {e}\")\n",
    "    print(\"üí° Solu√ß√£o: Execute 'ollama pull qwen3-embedding:4b'\")\n",
    "\n",
    "# Erro 2: Caminho inv√°lido\n",
    "try:\n",
    "    result = create_embeddings(\n",
    "        documents=[\"/caminho/que/nao/existe\"],\n",
    "        model_name=\"qwen3-embedding:4b\"\n",
    "    )\n",
    "except ValueError as e:\n",
    "    print(f\"\\n‚ùå Erro: {e}\")\n",
    "    print(\"üí° Solu√ß√£o: Verifique se o caminho existe\")\n",
    "\n",
    "# Erro 3: Overlap maior que chunk_size\n",
    "try:\n",
    "    result = create_embeddings(\n",
    "        documents=[\"./docs\"],\n",
    "        model_name=\"qwen3-embedding:4b\",\n",
    "        chunk_size=100,\n",
    "        chunk_overlap=150  # Maior que chunk_size!\n",
    "    )\n",
    "except ValueError as e:\n",
    "    print(f\"\\n‚ùå Erro: {e}\")\n",
    "    print(\"üí° Solu√ß√£o: chunk_overlap deve ser < chunk_size\")\n",
    "\n",
    "# ‚úÖ Uso correto com tratamento\n",
    "try:\n",
    "    result = create_embeddings(\n",
    "        documents=[\"./docs\"],\n",
    "        model_name=\"qwen3-embedding:4b\"\n",
    "    )\n",
    "    \n",
    "    if \"error\" in result:\n",
    "        print(f\"‚ö†Ô∏è  Processamento com erro: {result['error']}\")\n",
    "    elif result[\"success\"]:\n",
    "        print(f\"‚úÖ Sucesso: {result['total_chunks']} chunks indexados\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Processamento parcial (interrompido)\")\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n‚ö†Ô∏è  Interrompido pelo usu√°rio (Ctrl+C)\")\n",
    "    print(\"   Progresso parcial foi salvo!\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Erro inesperado: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a8a109",
   "metadata": {},
   "source": [
    "## 13. üìä Monitoramento e An√°lise de M√©tricas\n",
    "\n",
    "Analise as m√©tricas salvas para otimizar seu pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7c08ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä AN√ÅLISE DE M√âTRICAS ESTRUTURADAS\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. L√™ arquivo de estat√≠sticas\n",
    "stats_file = Path(\"my_index_stats.json\")\n",
    "if stats_file.exists():\n",
    "    with open(stats_file, \"r\") as f:\n",
    "        stats = json.load(f)\n",
    "    \n",
    "    print(\"üìä ESTAT√çSTICAS DO √çNDICE:\")\n",
    "    print(f\"   Total chunks: {stats['total_chunks']}\")\n",
    "    print(f\"   Duplicados removidos: {stats['duplicates_removed']}\")\n",
    "    print(f\"   Dimens√£o: {stats['embedding_dimension']}\")\n",
    "    print(f\"   Tipo: {stats['index_type']}\")\n",
    "    print(f\"   Criado em: {stats['created_at']}\")\n",
    "\n",
    "# 2. L√™ m√©tricas estruturadas (JSONL)\n",
    "metrics_file = Path(\"my_index_metrics.jsonl\")\n",
    "if metrics_file.exists():\n",
    "    metrics = []\n",
    "    with open(metrics_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            metrics.append(json.loads(line))\n",
    "    \n",
    "    print(f\"\\nüìà M√âTRICAS DE PROCESSAMENTO:\")\n",
    "    print(f\"   Total de eventos: {len(metrics)}\")\n",
    "    \n",
    "    # Filtra por tipo\n",
    "    indexing = [m for m in metrics if m[\"event_type\"] == \"indexing\"]\n",
    "    \n",
    "    if indexing:\n",
    "        print(f\"\\n   Eventos de indexa√ß√£o: {len(indexing)}\")\n",
    "        for event in indexing[-3:]:  # √öltimos 3\n",
    "            cfg = event['metrics']['config']\n",
    "            print(f\"      ‚Ä¢ {event['timestamp']}\")\n",
    "            print(f\"        Modelo: {cfg['model']}\")\n",
    "            print(f\"        Chunk size: {cfg['chunk_size']}\")\n",
    "\n",
    "# 3. Analisa metadados (JSONL)\n",
    "metadata_file = Path(\"my_index.jsonl\")\n",
    "if metadata_file.exists():\n",
    "    # L√™ primeiras linhas como amostra\n",
    "    with open(metadata_file, \"r\") as f:\n",
    "        sample = [json.loads(next(f)) for _ in range(min(3, 3))]\n",
    "    \n",
    "    print(f\"\\nüìù AMOSTRA DE METADADOS:\")\n",
    "    for i, meta in enumerate(sample, 1):\n",
    "        print(f\"\\n   Chunk {i}:\")\n",
    "        print(f\"      Fonte: {meta.get('source', 'N/A')}\")\n",
    "        print(f\"      P√°gina: {meta.get('page_number', 'N/A')}\")\n",
    "        print(f\"      Tamanho: {meta.get('char_count', 'N/A')} chars\")\n",
    "        print(f\"      Preview: {meta.get('content', '')[:60]}...\")\n",
    "\n",
    "print(\"\\n‚úÖ An√°lise de m√©tricas conclu√≠da!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf71e6a",
   "metadata": {},
   "source": [
    "## 14. üìö Resumo e Pr√≥ximos Passos\n",
    "\n",
    "### üéØ O que voc√™ aprendeu:\n",
    "\n",
    "1. ‚úÖ **Uso b√°sico** - Uma linha para indexar documentos\n",
    "2. ‚úÖ **Configura√ß√£o avan√ßada** - Controle total de par√¢metros\n",
    "3. ‚úÖ **Otimiza√ß√£o** - Ajustes de performance\n",
    "4. ‚úÖ **Detec√ß√£o autom√°tica** - Sistema escolhe melhor √≠ndice\n",
    "5. ‚úÖ **Tratamento de erros** - Valida√ß√£o robusta\n",
    "6. ‚úÖ **Monitoramento** - An√°lise de m√©tricas\n",
    "\n",
    "### üöÄ Pr√≥ximos Passos:\n",
    "\n",
    "1. **Indexar seus documentos** com as configura√ß√µes aprendidas\n",
    "2. **Testar retrieval** usando `perguntar.py`\n",
    "3. **Analisar m√©tricas** para otimizar\n",
    "4. **Integrar com LLM** para RAG completo\n",
    "\n",
    "### üìñ Documenta√ß√£o Completa:\n",
    "\n",
    "- `GUIA_RAPIDO.md` - Refer√™ncia r√°pida de uso\n",
    "- `ANALISE_CODIGO_RAG.md` - An√°lise profissional detalhada\n",
    "- `MELHORIAS_APLICADAS.md` - Todas as corre√ß√µes aplicadas\n",
    "- `SUMARIO_REFATORACAO.md` - Resumo executivo\n",
    "- `test_indexar_refatorado.py` - Suite de testes\n",
    "\n",
    "### üí° Dicas Importantes:\n",
    "\n",
    "**Performance:**\n",
    "- `batch_size` maior = mais RAM, mais r√°pido\n",
    "- `num_workers` = n√∫mero de CPUs dispon√≠veis\n",
    "- IVF index para >10k chunks\n",
    "\n",
    "**Qualidade:**\n",
    "- `chunk_overlap` = 10-20% de `chunk_size`\n",
    "- `deduplicate=True` elimina redund√¢ncia\n",
    "- `normalize_embeddings=True` para similaridade coseno\n",
    "\n",
    "**Debug:**\n",
    "- `enable_structured_logging=True` para m√©tricas\n",
    "- Checar `*_stats.json` para diagn√≥stico\n",
    "- Logs em tempo real mostram progresso\n",
    "\n",
    "### üéâ Conclus√£o:\n",
    "\n",
    "Seu sistema RAG est√° pronto com **c√≥digo de n√≠vel produ√ß√£o**:\n",
    "- ‚úÖ 0 erros de compila√ß√£o\n",
    "- ‚úÖ Valida√ß√£o completa\n",
    "- ‚úÖ Performance otimizada\n",
    "- ‚úÖ Gest√£o de recursos\n",
    "- ‚úÖ Documenta√ß√£o profissional\n",
    "\n",
    "**Boa sorte com seu projeto RAG!** üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8970d135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo 1: Detec√ß√£o autom√°tica com documentos pequenos\n",
    "pequeno = create_embeddings(\n",
    "    documents=[\"./pequeno_dataset\"],  # < 10k chunks\n",
    "    model_name=\"qwen3-embedding:4b\",\n",
    "    output_prefix=\"indice_pequeno\"\n",
    ")\n",
    "print(f\"Dataset pequeno ‚Üí √çndice: {pequeno['index_type']}\")\n",
    "print(f\"Sele√ß√£o autom√°tica: {pequeno['index_auto_selected']}\")\n",
    "\n",
    "# Exemplo 2: Detec√ß√£o autom√°tica com documentos grandes\n",
    "grande = create_embeddings(\n",
    "    documents=[\"./grande_dataset\"],  # ‚â• 10k chunks\n",
    "    model_name=\"qwen3-embedding:4b\",\n",
    "    output_prefix=\"indice_grande\"\n",
    ")\n",
    "print(f\"\\nDataset grande ‚Üí √çndice: {grande['index_type']}\")\n",
    "print(f\"Sele√ß√£o autom√°tica: {grande['index_auto_selected']}\")\n",
    "\n",
    "# Exemplo 3: Ajustando o threshold\n",
    "custom = create_embeddings(\n",
    "    documents=[\"./meus_docs\"],\n",
    "    model_name=\"qwen3-embedding:4b\",\n",
    "    ivf_threshold=15000,  # S√≥ usa IVF se tiver 15k+ chunks\n",
    "    output_prefix=\"indice_custom\"\n",
    ")\n",
    "print(f\"\\nThreshold customizado (15k) ‚Üí √çndice: {custom['index_type']}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
