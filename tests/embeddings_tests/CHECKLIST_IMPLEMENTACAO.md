# ‚úÖ Checklist de Implementa√ß√£o - Sistema RAG Avan√ßado

## üöÄ ETAPA 1: Prepara√ß√£o (5 minutos)

### Verificar Ambiente

- [ ] Python 3.8+ instalado
- [ ] Ollama rodando (`ollama list`)
- [ ] Modelos baixados:
  - [ ] `qwen3-embedding:4b`
  - [ ] `granite4:latest` (ou seu modelo LLM preferido)
- [ ] Bibliotecas instaladas:
  - [ ] `ollama`
  - [ ] `faiss-cpu` (ou `faiss-gpu`)
  - [ ] `numpy`
  - [ ] `pandas`
  - [ ] `pyarrow`
  - [ ] `langchain-text-splitters`
  - [ ] `pymupdf` (fitz)

**Comando de verifica√ß√£o:**

```bash
python -c "import ollama, faiss, numpy, pandas, pyarrow, fitz; print('‚úÖ OK')"
```

---

## üîß ETAPA 2: Re-Indexa√ß√£o (OBRIGAT√ìRIO para BM25)

### Por que re-indexar?

O campo `content` foi adicionado ao metadata. √çndices antigos n√£o t√™m esse campo e o BM25 n√£o funcionar√°.

### Passos:

1. **Backup (opcional mas recomendado):**

```bash
cp vector_index.faiss vector_index_old.faiss
cp vector_index.jsonl vector_index_old.jsonl
```

2. **Verificar se precisa re-indexar:**

```bash
python atualizar_metadata.py
```

3. **Re-indexar documentos:**

```bash
python indexar.py
```

4. **Verificar sucesso:**

```bash
# Deve mostrar campo 'content' nos metadados
python atualizar_metadata.py
```

**Checklist:**

- [ ] Backup feito (opcional)
- [ ] `atualizar_metadata.py` executado
- [ ] `indexar.py` executado sem erros
- [ ] Verifica√ß√£o de compatibilidade OK
- [ ] Arquivos gerados:
  - [ ] `vector_index.faiss`
  - [ ] `vector_index.jsonl`
  - [ ] `vector_index_stats.json`

---

## üß™ ETAPA 3: Testes B√°sicos (10 minutos)

### Teste 1: Sistema Funciona

```bash
python perguntar.py
```

**Verificar:**

- [ ] Carrega √≠ndice sem erros
- [ ] Inicializa BM25 (mensagem "Inicializando BM25 reranker...")
- [ ] Executa query completa
- [ ] Salva m√©tricas em `rag_metrics.jsonl`

### Teste 2: Compara√ß√£o Reranking

```bash
python exemplo_uso_rag_avancado.py
# Escolha op√ß√£o 2
```

**Verificar:**

- [ ] Mostra diferen√ßa de qualidade
- [ ] Tempo de reranking razo√°vel (<500ms)
- [ ] Respostas s√£o diferentes (e idealmente melhores)

### Teste 3: Query Expansion

```bash
python exemplo_uso_rag_avancado.py
# Escolha op√ß√£o 3
```

**Verificar:**

- [ ] Queries s√£o expandidas corretamente
- [ ] Sin√¥nimos fazem sentido
- [ ] Poss√≠vel adicionar termos customizados

---

## üìä ETAPA 4: Valida√ß√£o de Qualidade (30 minutos)

### Criar Dataset de Teste

Crie arquivo `test_queries.txt` com 10-20 perguntas do seu dom√≠nio:

```
O que s√£o op√ß√µes de compra?
Como calcular o valor intr√≠nseco?
Qual a diferen√ßa entre call e put?
...
```

### Testar Qualidade

```python
# test_quality.py
from perguntar import AdvancedRAG

rag = AdvancedRAG(
    index_path="vector_index.faiss",
    metadata_path="vector_index.jsonl",
    embedding_model="qwen3-embedding:4b",
    llm_model="granite4:latest",
    use_reranking=True,
    use_query_expansion=True,
    enable_logging=True
)

with open("test_queries.txt") as f:
    queries = [line.strip() for line in f if line.strip()]

for i, query in enumerate(queries, 1):
    print(f"\n{'='*70}")
    print(f"Query {i}/{len(queries)}: {query}")
    print('='*70)

    result = rag.query(query, k=10, rerank_to=4)
    print(f"\nResposta: {result['answer'][:200]}...")
    print(f"Tempo: {result['metrics']['total_time']:.2f}s")

    # Avalie manualmente: resposta faz sentido?
    feedback = input("\nResposta boa? (s/n): ")

    # Salva feedback
    with open("quality_feedback.txt", "a") as f:
        f.write(f"{query}\t{feedback}\n")
```

**Checklist:**

- [ ] Dataset de teste criado
- [ ] Script de teste executado
- [ ] Respostas avaliadas manualmente
- [ ] Taxa de sucesso calculada (ex: 8/10 = 80%)

---

## üîç ETAPA 5: An√°lise de M√©tricas (15 minutos)

### Verificar Logs

```bash
python exemplo_uso_rag_avancado.py
# Escolha op√ß√£o 4
```

**Analisar:**

- [ ] Tempo m√©dio de retrieval (<500ms ideal)
- [ ] Overhead de reranking (<200ms ideal)
- [ ] Tempo m√©dio de gera√ß√£o (vari√°vel, depende do LLM)
- [ ] Queries mais comuns
- [ ] Scores m√©dios (vetor e BM25)

### Identificar Problemas

**Se retrieval muito lento (>1s):**

- Reduzir `k` (buscar menos docs)
- Verificar tamanho do √≠ndice (`vector_index_stats.json`)

**Se reranking muito lento (>500ms):**

- Corpus muito grande (considerar sample menor)
- Muitos documentos sendo reranked (reduzir `k`)

**Se respostas ruins:**

- Verificar qualidade dos chunks (muito pequenos/grandes?)
- Testar sem reranking (`use_reranking=False`)
- Verificar se docs relevantes est√£o no √≠ndice

---

## üéØ ETAPA 6: Otimiza√ß√£o (Opcional, 1-2 horas)

### Tuning de Hiperpar√¢metros

Teste diferentes configura√ß√µes:

```python
# Teste 1: Mais documentos
result_1 = rag.query(query, k=20, rerank_to=8)

# Teste 2: Menos documentos
result_2 = rag.query(query, k=5, rerank_to=3)

# Teste 3: Sem expansion
rag_no_exp = AdvancedRAG(..., use_query_expansion=False)
result_3 = rag_no_exp.query(query, k=10, rerank_to=4)
```

**Encontrar melhor configura√ß√£o:**

- [ ] `k` ideal (trade-off recall vs lat√™ncia)
- [ ] `rerank_to` ideal (trade-off precision vs lat√™ncia)
- [ ] Query expansion ajuda? (compare)
- [ ] BM25 ajuda? (compare com/sem)

### Customizar Query Expansion

Adicione termos espec√≠ficos do seu dom√≠nio:

```python
from perguntar import QueryExpander

expander = QueryExpander()

# Exemplo: dom√≠nio financeiro
expander.add_custom_expansion("bdi", ["√≠ndice bdi", "baltic dry index"])
expander.add_custom_expansion("call", ["op√ß√£o de compra", "call option"])
expander.add_custom_expansion("put", ["op√ß√£o de venda", "put option"])

# Salvar para uso futuro (modificar perguntar.py)
```

**Checklist:**

- [ ] Hiperpar√¢metros testados
- [ ] Melhor configura√ß√£o identificada
- [ ] Termos customizados adicionados (se aplic√°vel)
- [ ] Configura√ß√£o documentada

---

## üìà ETAPA 7: Benchmark Comparativo (30 minutos)

### Comparar: Antigo vs Novo

```bash
# Sistema ANTIGO (sem melhorias)
python perguntar_manual.py  # Salve respostas

# Sistema NOVO (com melhorias)
python perguntar.py  # Compare respostas
```

**Criar tabela de compara√ß√£o:**

| Query   | Antigo           | Novo              | Ganho? |
| ------- | ---------------- | ----------------- | ------ |
| Query 1 | Resposta parcial | Resposta completa | ‚úÖ     |
| Query 2 | Resposta correta | Resposta correta  | =      |
| Query 3 | Resposta errada  | Resposta correta  | ‚úÖ     |
| ...     | ...              | ...               | ...    |

**M√©tricas finais:**

- [ ] % de respostas melhoradas
- [ ] % de respostas mantidas (j√° eram boas)
- [ ] % de respostas pioradas (debugging necess√°rio)
- [ ] Lat√™ncia m√©dia comparada

---

## üöÄ ETAPA 8: Deploy/Produ√ß√£o (Opcional)

### Checklist de Produ√ß√£o

**Performance:**

- [ ] Tempo de resposta <5s (90% das queries)
- [ ] Taxa de sucesso >80%
- [ ] M√©tricas sendo logadas corretamente

**Robustez:**

- [ ] Testa queries vazias
- [ ] Testa queries muito longas
- [ ] Testa queries com caracteres especiais
- [ ] Error handling adequado

**Monitoramento:**

- [ ] `rag_metrics.jsonl` sendo escrito
- [ ] Script de an√°lise de m√©tricas pronto
- [ ] Alertas para queries lentas (opcional)

**Documenta√ß√£o:**

- [ ] README atualizado
- [ ] Exemplos de uso documentados
- [ ] Configura√ß√µes recomendadas documentadas

---

## üîÆ ETAPA 9: Pr√≥ximos Passos (Futuro)

### Se qualidade √© suficiente (70/100):

- [ ] Sistema em produ√ß√£o
- [ ] Monitoramento cont√≠nuo
- [ ] Feedback dos usu√°rios

### Se precisa melhorar (95/100):

**Fase 1 - Quick Wins (1-2 dias):**

- [ ] Implementar Cross-Encoder Reranking
- [ ] Implementar RRF (Reciprocal Rank Fusion)
- [ ] Hardware: 12GB RAM

**Fase 2 - Chunking (3-5 dias):**

- [ ] Semantic Chunking
- [ ] Parent-Child Chunking
- [ ] Hardware: 16GB RAM

**Fase 3 - Query Intelligence (2-4 dias):**

- [ ] HyDE
- [ ] Multi-Query
- [ ] Hardware: 16GB RAM

**Consulte `ROADMAP_BIG_TECH.md` para detalhes completos.**

---

## üìù Checklist Final

### Sistema est√° pronto se:

- [x] ‚úÖ Re-indexa√ß√£o conclu√≠da com campo `content`
- [x] ‚úÖ Testes b√°sicos passando
- [x] ‚úÖ BM25 reranking funcionando
- [x] ‚úÖ Query expansion funcionando
- [x] ‚úÖ Logging estruturado ativo
- [x] ‚úÖ M√©tricas sendo salvas
- [x] ‚úÖ Qualidade validada (>80% respostas boas)
- [x] ‚úÖ Performance aceit√°vel (<5s por query)
- [x] ‚úÖ Documenta√ß√£o lida e entendida

### Se TODOS os itens acima est√£o marcados:

üéâ **PARAB√âNS! Seu sistema RAG est√° pronto para uso!** üéâ

---

## üÜò Troubleshooting R√°pido

### Erro: "campo 'content' n√£o encontrado"

**Solu√ß√£o:** Re-indexar com `python indexar.py`

### BM25 muito lento

**Solu√ß√£o:** Reduzir `k` inicial ou desativar temporariamente

### Respostas piores com reranking

**Solu√ß√£o:** Testar `use_reranking=False` ou ajustar BM25 params

### Queries expandidas incorretas

**Solu√ß√£o:** Customizar dicion√°rio de expans√£o

### Mem√≥ria insuficiente (8GB)

**Solu√ß√£o:**

1. Reduzir corpus
2. Desativar BM25 temporariamente
3. Considerar upgrade para 12-16GB

---

## üìö Refer√™ncias R√°pidas

- **Uso b√°sico:** `README_MELHORIAS.md`
- **Roadmap completo:** `ROADMAP_BIG_TECH.md`
- **Sum√°rio t√©cnico:** `SUMARIO_IMPLEMENTACOES.md`
- **Exemplos:** `exemplo_uso_rag_avancado.py`
- **Verifica√ß√£o:** `atualizar_metadata.py`

---

**√öltima atualiza√ß√£o:** 2025-10-31
**Vers√£o do sistema:** MVP 1.0 (Score: 70/100)
