"""
Exemplo completo de uso do tool_choice para controle de seleÃ§Ã£o de ferramentas.

Este arquivo demonstra:
1. Todos os modos de tool_choice (auto, none, required, especÃ­fico)
2. Formato de string vs formato de dicionÃ¡rio
3. Uso com ToolChoice value object
4. Comportamento em diferentes cenÃ¡rios
"""

import asyncio
import logging

from createagents import CreateAgent, tool, LoggingConfigurator

# Habilitar logging para ver os passos da IA
LoggingConfigurator.configure(level=logging.INFO)


# =============================================================================
# Ferramentas para DemonstraÃ§Ã£o
# =============================================================================


@tool
def calculator(expression: str) -> str:
    """Calcular uma expressÃ£o matemÃ¡tica.

    Args:
        expression: ExpressÃ£o matemÃ¡tica (ex: "2 + 2", "10 * 5").

    Returns:
        Resultado do cÃ¡lculo.
    """
    try:
        allowed = set('0123456789+-*/().% ')
        if not all(c in allowed for c in expression):
            return 'Erro: Caracteres nÃ£o permitidos'
        return f'Resultado: {eval(expression)}'  # nosec B307
    except Exception as e:
        return f'Erro: {e}'


@tool
def weather(city: str, detailed: bool = False) -> str:
    """Consultar previsÃ£o do tempo.

    Args:
        city: Nome da cidade.
        detailed: Se deve incluir detalhes extras.

    Returns:
        PrevisÃ£o do tempo para a cidade.
    """
    # SimulaÃ§Ã£o
    temps = {'SÃ£o Paulo': 25, 'Rio': 32, 'Curitiba': 18}
    temp = temps.get(city, 22)
    base = f'ğŸŒ¤ï¸ {city}: {temp}Â°C'

    if detailed:
        return f'{base}, Umidade: 65%, Vento: 10km/h'
    return base


@tool
def translate(text: str, to_lang: str = 'en') -> str:
    """Traduzir texto.

    Args:
        text: Texto para traduzir.
        to_lang: Idioma destino (padrÃ£o: inglÃªs).

    Returns:
        Texto traduzido.
    """
    # SimulaÃ§Ã£o
    translations = {
        'olÃ¡': 'hello',
        'mundo': 'world',
        'bom dia': 'good morning',
    }
    translated = translations.get(text.lower(), f'[{text}]')
    return f"ğŸŒ '{text}' â†’ '{translated}' ({to_lang})"


@tool
def search(query: str, max_results: int = 5) -> str:
    """Buscar informaÃ§Ãµes.

    Args:
        query: Termo de busca.
        max_results: MÃ¡ximo de resultados.

    Returns:
        Resultados da busca.
    """
    return f"ğŸ” Resultados para '{query}': [{max_results} itens encontrados]"


# =============================================================================
# DemonstraÃ§Ãµes de tool_choice
# =============================================================================


async def demo_auto():
    """
    Modo AUTO (padrÃ£o): O modelo decide se/qual ferramenta usar.

    Use quando: Quer que o modelo escolha a melhor abordagem.
    """
    print('\n' + '=' * 70)
    print('ğŸ“Œ MODO: auto (padrÃ£o) - OPENAI + Stream: False')
    print('   O modelo decide se e qual ferramenta usar')
    print('=' * 70)

    agent = CreateAgent(
        provider='openai',
        model='gpt-5-nano',
        tools=[calculator, weather, translate, search],
        config={'stream': False},
    )

    # CenÃ¡rio 1: Modelo deve usar calculadora
    print('\nğŸ”¹ CenÃ¡rio 1: Pergunta matemÃ¡tica')
    response = await agent.chat('Quanto Ã© 15 vezes 8?')
    print(f'   Resposta: {response}')

    # CenÃ¡rio 2: Modelo pode responder sem ferramenta
    print('\nğŸ”¹ CenÃ¡rio 2: Pergunta geral (pode nÃ£o usar ferramenta)')
    response = await agent.chat('Qual Ã© a capital da FranÃ§a?')
    print(f'   Resposta: {response}')


async def demo_none():
    """
    Modo NONE: Modelo nÃ£o pode usar ferramentas.

    Use quando: Quer apenas conversa, sem aÃ§Ãµes externas.
    """
    print('\n' + '=' * 70)
    print('ğŸ“Œ MODO: none - OLLAMA + Stream: True')
    print('   Ferramentas desabilitadas - apenas conversa')
    print('=' * 70)

    agent = CreateAgent(
        provider='ollama',
        model='gpt-oss:120b-cloud',
        tools=[calculator, weather],
        config={'stream': True},
    )

    # Mesmo pedindo cÃ¡lculo, nÃ£o usarÃ¡ calculadora (sem tool_choice=none aqui,
    # pois o mÃ©todo chat nÃ£o aceita tool_choice ainda)
    print('\nğŸ”¹ CenÃ¡rio: Pergunta simples com streaming')
    print('   Resposta: ', end='', flush=True)
    response = await agent.chat('Quanto Ã© 7 mais 3? Responda brevemente.')
    async for token in response:
        print(token, end='', flush=True)
    print()


async def demo_required():
    """
    Modo REQUIRED: Modelo DEVE usar pelo menos uma ferramenta.

    Use quando: Quer garantir que uma aÃ§Ã£o serÃ¡ executada.
    """
    print('\n' + '=' * 70)
    print('ğŸ“Œ MODO: required - OLLAMA + Stream: False')
    print('   Modelo deve usar alguma ferramenta')
    print('=' * 70)

    agent = CreateAgent(
        provider='ollama',
        model='gpt-oss:120b-cloud',
        tools=[calculator, weather, search],
        config={'stream': False},
    )

    # Mesmo pergunta vaga, modelo escolherÃ¡ uma ferramenta
    print('\nğŸ”¹ CenÃ¡rio: Pedido vago - modelo escolhe ferramenta')
    response = await agent.chat(
        'Me diga algo interessante', tool_choice='required'
    )
    print(f'   Resposta: {response}')
    print('   (Note: Usou alguma ferramenta mesmo sem pedido especÃ­fico)')


async def demo_specific():
    """
    Modo ESPECÃFICO: ForÃ§a uso de uma ferramenta especÃ­fica.

    Use quando: Quer garantir que uma ferramenta especÃ­fica seja usada.
    """
    print('\n' + '=' * 70)
    print('ğŸ“Œ MODO: especÃ­fico (nome da ferramenta) - OPENAI + Stream: True')
    print('   ForÃ§a uso de uma ferramenta especÃ­fica')
    print('=' * 70)

    agent = CreateAgent(
        provider='openai',
        model='gpt-5-nano',
        tools=[calculator, weather, translate, search],
        config={'stream': True},
    )

    # ForÃ§ar uso de weather mesmo para pergunta genÃ©rica
    print("\nğŸ”¹ CenÃ¡rio 1: ForÃ§ar 'weather' para qualquer pergunta")
    print('   Resposta: ', end='', flush=True)
    response = await agent.chat(
        'Me fale sobre SÃ£o Paulo', tool_choice='weather'
    )
    async for token in response:
        print(token, end='', flush=True)
    print()

    # ForÃ§ar calculadora
    print("\nğŸ”¹ CenÃ¡rio 2: ForÃ§ar 'calculator'")
    print('   Resposta: ', end='', flush=True)
    response = await agent.chat('Qualquer coisa', tool_choice='calculator')
    async for token in response:
        print(token, end='', flush=True)
    print()


async def demo_dict_format():
    """
    Formato de DICIONÃRIO: CompatÃ­vel com formato OpenAI.

    Use quando: Precisa de compatibilidade com API OpenAI direta.
    """
    print('\n' + '=' * 70)
    print('ğŸ“Œ MODO: Formato de DicionÃ¡rio - OLLAMA + Stream: True')
    print('   Usa formato compatÃ­vel com API OpenAI')
    print('=' * 70)

    agent = CreateAgent(
        provider='ollama',
        model='gpt-oss:120b-cloud',
        tools=[calculator, weather],
        config={'stream': True},
    )

    # Formato de dicionÃ¡rio para ferramenta especÃ­fica
    print("\nğŸ”¹ CenÃ¡rio: Formato dict para 'calculator'")
    print('   Resposta: ', end='', flush=True)
    response = await agent.chat(
        'FaÃ§a algo',
        tool_choice={'type': 'function', 'function': {'name': 'calculator'}},
    )
    async for token in response:
        print(token, end='', flush=True)
    print()


async def demo_with_value_object():
    """
    Usando ToolChoice VALUE OBJECT diretamente.

    Use quando: Quer type-safety e validaÃ§Ã£o.
    """
    print('\n' + '=' * 70)
    print('ğŸ“Œ MODO: ToolChoice Value Object - OpenAI e Ollama alternados')
    print('   Usando o value object para type-safety')
    print('=' * 70)

    from createagents.domain.value_objects import ToolChoice

    # OpenAI + Stream: False
    agent_openai = CreateAgent(
        provider='openai',
        model='gpt-5-nano',
        tools=[calculator, weather, search],
        config={'stream': False},
    )

    # Ollama + Stream: True
    agent_ollama = CreateAgent(
        provider='ollama',
        model='gpt-oss:120b-cloud',
        tools=[calculator, weather, search],
        config={'stream': True},
    )

    # Usando factory methods do ToolChoice
    print('\nğŸ”¹ CenÃ¡rio 1: ToolChoice.auto() - OpenAI')
    response = await agent_openai.chat(
        'Quanto Ã© 5 + 5?', tool_choice=ToolChoice.auto()
    )
    print(f'   Resposta: {response}')

    print('\nğŸ”¹ CenÃ¡rio 2: ToolChoice.required() - Ollama com streaming')
    print('   Resposta: ', end='', flush=True)
    response = await agent_ollama.chat(
        'OlÃ¡!', tool_choice=ToolChoice.required()
    )
    async for token in response:
        print(token, end='', flush=True)
    print()

    print("\nğŸ”¹ CenÃ¡rio 3: ToolChoice.specific('weather') - OpenAI")
    response = await agent_openai.chat(
        'Qualquer coisa', tool_choice=ToolChoice.specific('weather')
    )
    print(f'   Resposta: {response}')

    print('\nğŸ”¹ CenÃ¡rio 4: ToolChoice.none() - Ollama com streaming')
    print('   Resposta: ', end='', flush=True)
    response = await agent_ollama.chat(
        'Calcule 2 + 2', tool_choice=ToolChoice.none()
    )
    async for token in response:
        print(token, end='', flush=True)
    print()


async def demo_practical_scenarios():
    """CenÃ¡rios PRÃTICOS de uso do tool_choice."""
    print('\n' + '=' * 70)
    print('ğŸ“Œ CENÃRIOS PRÃTICOS - Alternando OpenAI/Ollama e stream')
    print('   Quando usar cada modo')
    print('=' * 70)

    # OpenAI com streaming
    agent_openai_stream = CreateAgent(
        provider='openai',
        model='gpt-5-nano',
        tools=[calculator, weather, translate, search],
        config={'stream': True},
    )

    # Ollama sem streaming
    agent_ollama = CreateAgent(
        provider='ollama',
        model='gpt-oss:120b-cloud',
        tools=[calculator, weather, translate, search],
        config={'stream': False},
    )

    # CenÃ¡rio 1: Chatbot com ferramentas opcionais - OpenAI + Stream
    print('\nğŸ”¹ 1. Chatbot Inteligente (auto) - OpenAI + Stream')
    print("   Use 'auto' para deixar o modelo decidir naturalmente")
    print('   â†’ ', end='', flush=True)
    response = await agent_openai_stream.chat(
        'Qual a previsÃ£o do tempo para SÃ£o Paulo?', tool_choice='auto'
    )
    async for token in response:
        print(token, end='', flush=True)
    print()

    # CenÃ¡rio 2: Executor de tarefas - Ollama sem stream
    print('\nğŸ”¹ 2. Executor de Tarefas (required) - Ollama')
    print("   Use 'required' quando o usuÃ¡rio espera uma aÃ§Ã£o")
    response = await agent_ollama.chat(
        'Execute uma tarefa Ãºtil para mim', tool_choice='required'
    )
    print(f'   â†’ {response}')

    # CenÃ¡rio 3: Assistente de cÃ¡lculos - OpenAI + Stream
    print('\nğŸ”¹ 3. Assistente de CÃ¡lculos (especÃ­fico) - OpenAI + Stream')
    print('   Use especÃ­fico para garantir consistÃªncia')
    print('   â†’ ', end='', flush=True)
    response = await agent_openai_stream.chat(
        'Preciso calcular meu orÃ§amento: 1500 + 800 - 300',
        tool_choice='calculator',
    )
    async for token in response:
        print(token, end='', flush=True)
    print()

    # CenÃ¡rio 4: Modo conversa - Ollama sem stream
    print('\nğŸ”¹ 4. Modo Conversa (none) - Ollama')
    print("   Use 'none' para conversas sem aÃ§Ãµes")
    response = await agent_ollama.chat(
        'Me explique o que vocÃª pode fazer', tool_choice='none'
    )
    print(f'   â†’ {response}')


# =============================================================================
# Tabela de ReferÃªncia
# =============================================================================


def print_reference_table():
    """Imprime tabela de referÃªncia dos modos."""
    print('\n' + '=' * 70)
    print('ğŸ“– TABELA DE REFERÃŠNCIA - tool_choice')
    print('=' * 70)
    print("""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Modo            â”‚ DescriÃ§Ã£o                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ "auto"          â”‚ Modelo decide se/qual ferramenta usar (PADRÃƒO)          â”‚
â”‚ "none"          â”‚ Ferramentas desabilitadas, apenas conversa              â”‚
â”‚ "required"      â”‚ Modelo DEVE usar pelo menos uma ferramenta              â”‚
â”‚ "<nome>"        â”‚ ForÃ§a uso da ferramenta com esse nome                   â”‚
â”‚ {dict}          â”‚ Formato OpenAI: {"type": "function", "function": {...}} â”‚
â”‚ ToolChoice.*()  â”‚ Value object com factory methods (auto/none/required)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ“ Quando usar cada modo:

â€¢ AUTO: Comportamento padrÃ£o, ideal para chatbots inteligentes
â€¢ NONE: Modo conversa pura, Ãºtil para explicaÃ§Ãµes ou smalltalk
â€¢ REQUIRED: Quando vocÃª PRECISA de uma aÃ§Ã£o, nÃ£o apenas texto
â€¢ ESPECÃFICO: Garante consistÃªncia, ex: sempre usar calculadora para math

âš ï¸ Dicas:
1. 'required' pode gerar chamadas desnecessÃ¡rias - use com cuidado
2. Modo especÃ­fico ignora contexto - modelo nÃ£o escolhe ferramenta
3. Use ToolChoice value object para type-safety em cÃ³digo Python
4. Formato dict Ã© Ãºtil para interoperabilidade com outras APIs
    """)


# =============================================================================
# Main
# =============================================================================


async def main():
    """Executar todas as demonstraÃ§Ãµes."""
    print('ğŸš€ CreateAgents - DemonstraÃ§Ã£o Completa de tool_choice')
    print('=' * 70)

    # ReferÃªncia
    print_reference_table()

    # DemonstraÃ§Ãµes
    await demo_auto()
    await demo_none()
    await demo_required()
    await demo_specific()
    await demo_dict_format()
    await demo_with_value_object()
    await demo_practical_scenarios()

    print('\n' + '=' * 70)
    print('âœ… DemonstraÃ§Ã£o concluÃ­da!')
    print('=' * 70)


if __name__ == '__main__':
    # Mostrar apenas referÃªncia (nÃ£o precisa de API key)
    print_reference_table()

    print('\nğŸ’¡ Executando demos com agente...')
    asyncio.run(main())
