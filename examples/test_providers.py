"""
Testes diversificados entre provedores OpenAI e Ollama.

Este arquivo testa:
1. OpenAI com streaming
2. OpenAI sem streaming
3. Ollama com streaming
4. Ollama sem streaming
5. Ferramentas built-in e customizadas em ambos
"""

import asyncio
import logging
from typing import Optional

from createagents import CreateAgent, tool
from createagents.logging import configure_logging

# Habilitar logging para ver os passos da IA
configure_logging(level=logging.INFO)


# =============================================================================
# Ferramentas Customizadas
# =============================================================================


@tool
def calculator(expression: str) -> str:
    """Calcular uma expressÃ£o matemÃ¡tica.

    Args:
        expression: ExpressÃ£o matemÃ¡tica (ex: "2 + 2", "10 * 5").

    Returns:
        Resultado do cÃ¡lculo.
    """
    try:
        allowed = set('0123456789+-*/().% ')
        if not all(c in allowed for c in expression):
            return 'Erro: Caracteres nÃ£o permitidos'
        return f'Resultado: {eval(expression)}'  # nosec B307
    except Exception as e:
        return f'Erro: {e}'


@tool
def weather(city: str) -> str:
    """Consultar previsÃ£o do tempo (simulado).

    Args:
        city: Nome da cidade.

    Returns:
        PrevisÃ£o do tempo para a cidade.
    """
    temps = {'SÃ£o Paulo': 25, 'Rio': 32, 'Curitiba': 18, 'BrasÃ­lia': 28}
    temp = temps.get(city, 22)
    return f'ğŸŒ¤ï¸ {city}: {temp}Â°C, parcialmente nublado'


@tool
async def fetch_data(url: str, timeout: Optional[int] = 30) -> str:
    """Buscar dados de uma URL (assÃ­ncrono).

    Args:
        url: URL para buscar dados.
        timeout: Timeout em segundos (padrÃ£o: 30).

    Returns:
        ConteÃºdo da resposta ou erro.
    """
    # SimulaÃ§Ã£o - em produÃ§Ã£o usaria httpx ou aiohttp
    await asyncio.sleep(0.1)  # Simular latÃªncia
    return f'Dados obtidos de {url} (timeout={timeout}s): [ConteÃºdo simulado]'


# =============================================================================
# Testes OpenAI
# =============================================================================


async def test_openai_stream():
    """Teste OpenAI com streaming habilitado."""
    print('\n' + '=' * 70)
    print('ğŸ”µ OPENAI - Stream: True')
    print('=' * 70)

    agent = CreateAgent(
        provider='openai',
        model='gpt-5-nano',
        instructions='VocÃª Ã© um assistente tÃ©cnico conciso.',
        tools=['currentdate', calculator],
        config={'stream': True},
    )

    print('\nğŸ“ Pergunta: Que dia Ã© hoje e quanto Ã© 25 * 4?')
    print('ğŸ¤– Resposta: ', end='', flush=True)

    response = await agent.chat('Que dia Ã© hoje e quanto Ã© 25 * 4?')
    async for token in response:
        print(token, end='', flush=True)

    print('\n')
    print(
        f'ğŸ“Š MÃ©tricas: {agent.get_metrics()[-1] if agent.get_metrics() else "N/A"}'
    )


async def test_openai_no_stream():
    """Teste OpenAI sem streaming."""
    print('\n' + '=' * 70)
    print('ğŸ”µ OPENAI - Stream: False')
    print('=' * 70)

    agent = CreateAgent(
        provider='openai',
        model='gpt-5-nano',
        instructions='VocÃª Ã© um assistente tÃ©cnico conciso.',
        tools=[calculator, weather],
        config={'stream': False},
    )

    print('\nğŸ“ Pergunta: Quanto Ã© 100 / 4 e qual o tempo em SÃ£o Paulo?')
    response = await agent.chat(
        'Quanto Ã© 100 / 4 e qual o tempo em SÃ£o Paulo?'
    )
    print(f'ğŸ¤– Resposta: {response}')
    print(
        f'ğŸ“Š MÃ©tricas: {agent.get_metrics()[-1] if agent.get_metrics() else "N/A"}'
    )


# =============================================================================
# Testes Ollama
# =============================================================================


async def test_ollama_stream():
    """Teste Ollama com streaming habilitado."""
    print('\n' + '=' * 70)
    print('ğŸŸ¢ OLLAMA - Stream: True')
    print('=' * 70)

    agent = CreateAgent(
        provider='ollama',
        model='gpt-oss:120b-cloud',
        instructions='VocÃª Ã© um assistente tÃ©cnico conciso.',
        tools=['currentdate', calculator],
        config={'stream': True},
    )

    print('\nğŸ“ Pergunta: Que horas sÃ£o agora e quanto Ã© 15 + 27?')
    print('ğŸ¤– Resposta: ', end='', flush=True)

    response = await agent.chat('Que horas sÃ£o agora e quanto Ã© 15 + 27?')
    async for token in response:
        print(token, end='', flush=True)

    print('\n')
    print(
        f'ğŸ“Š MÃ©tricas: {agent.get_metrics()[-1] if agent.get_metrics() else "N/A"}'
    )


async def test_ollama_no_stream():
    """Teste Ollama sem streaming."""
    print('\n' + '=' * 70)
    print('ğŸŸ¢ OLLAMA - Stream: False')
    print('=' * 70)

    agent = CreateAgent(
        provider='ollama',
        model='gpt-oss:120b-cloud',
        instructions='VocÃª Ã© um assistente tÃ©cnico conciso.',
        tools=[calculator, weather],
        config={'stream': False},
    )

    print('\nğŸ“ Pergunta: Quanto Ã© 50 * 3 e qual o clima em Curitiba?')
    response = await agent.chat('Quanto Ã© 50 * 3 e qual o clima em Curitiba?')
    print(f'ğŸ¤– Resposta: {response}')
    print(
        f'ğŸ“Š MÃ©tricas: {agent.get_metrics()[-1] if agent.get_metrics() else "N/A"}'
    )


# =============================================================================
# Testes Mistos
# =============================================================================


async def test_openai_builtin_only():
    """Teste OpenAI apenas com ferramentas built-in."""
    print('\n' + '=' * 70)
    print('ğŸ”µ OPENAI - Apenas Built-in Tools - Stream: True')
    print('=' * 70)

    agent = CreateAgent(
        provider='openai',
        model='gpt-5-nano',
        tools=['currentdate', 'readlocalfile'],
        config={'stream': True},
    )

    print('\nğŸ“ Pergunta: Qual Ã© a data de hoje?')
    print('ğŸ¤– Resposta: ', end='', flush=True)

    response = await agent.chat('Qual Ã© a data de hoje?')
    async for token in response:
        print(token, end='', flush=True)

    print('\n')


async def test_ollama_custom_only():
    """Teste Ollama apenas com ferramentas customizadas."""
    print('\n' + '=' * 70)
    print('ğŸŸ¢ OLLAMA - Apenas Custom Tools - Stream: False')
    print('=' * 70)

    agent = CreateAgent(
        provider='ollama',
        model='gpt-oss:120b-cloud',
        tools=[calculator, weather],
        config={'stream': False},
    )

    print('\nğŸ“ Pergunta: Qual a temperatura em BrasÃ­lia?')
    response = await agent.chat('Qual a temperatura em BrasÃ­lia?')
    print(f'ğŸ¤– Resposta: {response}')


async def test_no_tools():
    """Teste sem ferramentas (apenas conversa)."""
    print('\n' + '=' * 70)
    print('ğŸ”µ OPENAI - Sem ferramentas - Stream: False')
    print('=' * 70)

    agent = CreateAgent(
        provider='openai',
        model='gpt-5-nano',
        instructions='Responda de forma breve.',
        config={'stream': False},
    )

    print('\nğŸ“ Pergunta: O que Ã© Clean Architecture em uma frase?')
    response = await agent.chat('O que Ã© Clean Architecture em uma frase?')
    print(f'ğŸ¤– Resposta: {response}')


async def test_async_tool():
    """Teste com ferramenta assÃ­ncrona (async def)."""
    print('\n' + '=' * 70)
    print('âš¡ ASYNC TOOL - OpenAI - Stream: True')
    print('=' * 70)

    agent = CreateAgent(
        provider='openai',
        model='gpt-5-nano',
        instructions='VocÃª Ã© um assistente que busca dados.',
        tools=[fetch_data],
        config={'stream': True},
    )

    print('\nğŸ“ Pergunta: Busque dados do site example.com')
    print('ğŸ¤– Resposta: ', end='', flush=True)

    response = await agent.chat('Busque dados do site example.com')
    async for token in response:
        print(token, end='', flush=True)

    print('\n')


# =============================================================================
# Main
# =============================================================================


async def run_all_tests():
    """Executa todos os testes."""
    print('ğŸš€ CreateAgents - Testes Diversificados de Provedores')
    print('=' * 70)
    print('Provedores: OpenAI (gpt-5-nano) e Ollama (gpt-oss:120b-cloud)')
    print('Modos: Streaming e NÃ£o-Streaming')
    print('=' * 70)

    tests = [
        ('OpenAI + Stream', test_openai_stream),
        ('OpenAI sem Stream', test_openai_no_stream),
        ('Ollama + Stream', test_ollama_stream),
        ('Ollama sem Stream', test_ollama_no_stream),
        ('OpenAI Built-in', test_openai_builtin_only),
        ('Ollama Custom', test_ollama_custom_only),
        ('Async Tool', test_async_tool),
        ('Sem ferramentas', test_no_tools),
    ]

    results = []
    for name, test_fn in tests:
        try:
            await test_fn()
            results.append((name, 'âœ… OK'))
        except Exception as e:
            print(f'\nâŒ Erro: {e}')
            results.append((name, f'âŒ {type(e).__name__}'))

    # Resumo
    print('\n' + '=' * 70)
    print('ğŸ“‹ RESUMO DOS TESTES')
    print('=' * 70)
    for name, status in results:
        print(f'   {name}: {status}')
    print('=' * 70)


if __name__ == '__main__':
    asyncio.run(run_all_tests())
