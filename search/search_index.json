{"config":{"lang":["pt"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"\ud83e\udd16 Create Agents AI","text":"<p>Framework Python enterprise para criar agentes de IA inteligentes com arquitetura limpa, m\u00faltiplos provedores e ferramentas extens\u00edveis.</p> <p> </p>"},{"location":"#o-que-este-sistema-oferece","title":"\ud83c\udfaf O que este sistema oferece?","text":"<p>Create Agents AI \u00e9 um framework Python que permite criar agentes conversacionais inteligentes de forma profissional:</p> <p>\u2705 M\u00faltiplos provedores: OpenAI e Ollama (local) com f\u00e1cil integra\u00e7\u00e3o \u2705 Ferramentas extens\u00edveis: CurrentDateTool e ReadLocalFileTool (PDF, Excel, CSV e Parquet) \u2705 Hist\u00f3rico autom\u00e1tico: Conversas contextualizadas sem esfor\u00e7o \u2705 M\u00e9tricas integradas: Monitore performance em JSON ou Prometheus \u2705 Arquitetura limpa: C\u00f3digo test\u00e1vel, manuten\u00edvel e escal\u00e1vel seguindo SOLID</p>"},{"location":"#quick-start","title":"\ud83d\ude80 Quick Start","text":""},{"location":"#instalacao","title":"Instala\u00e7\u00e3o","text":"<pre><code># Instala\u00e7\u00e3o b\u00e1sica via PyPI\npip install createagents\n\n# OU com suporte a leitura de arquivos (PDF, Excel, CSV, Parquet)\npip install createagents[file-tools]\n</code></pre>"},{"location":"#configuracao","title":"Configura\u00e7\u00e3o","text":"<pre><code># Configure sua chave de API da OpenAI\nexport OPENAI_API_KEY=\"sk-proj-sua-chave\"\n\n# Ou crie um arquivo .env no seu projeto\necho \"OPENAI_API_KEY=sk-proj-sua-chave\" &gt; .env\n</code></pre>"},{"location":"#primeiro-agente-em-3-linhas","title":"Primeiro Agente em 3 Linhas","text":"<pre><code>import asyncio\nfrom createagents import CreateAgent\n\nasync def main():\n    agent = CreateAgent(\n        provider=\"openai\",\n        model=\"gpt-4\",\n        instructions=\"Voc\u00ea \u00e9 um assistente \u00fatil\"\n    )\n\n    response = await agent.chat(\"Ol\u00e1!\")\n    print(response)\n\nasyncio.run(main())\n</code></pre>"},{"location":"#funcionalidades-principais","title":"\u2728 Funcionalidades Principais","text":""},{"location":"#multiplos-provedores","title":"\ud83e\udd1d M\u00faltiplos Provedores","text":"<pre><code># OpenAI (GPT-4, GPT-3.5-turbo, GPT-4o)\nagent_openai = CreateAgent(provider=\"openai\", model=\"gpt-4\")\n\n# Ollama (llama2, mistral, codellama - 100% local e privado)\nagent_local = CreateAgent(provider=\"ollama\", model=\"llama2\")\n</code></pre>"},{"location":"#ferramentas-integradas","title":"\ud83d\udd27 Ferramentas Integradas","text":"<p>Adicione capacidades aos seus agentes com ferramentas prontas:</p> <pre><code>import asyncio\n\nasync def main():\n    agent = CreateAgent(\n        provider=\"openai\",\n        model=\"gpt-4\",\n        tools=[\"currentdate\", \"readlocalfile\"]  # Ferramentas dispon\u00edveis\n    )\n\n    # O agente usa automaticamente as ferramentas quando necess\u00e1rio\n    response1 = await agent.chat(\"Que dia \u00e9 hoje?\")  # Usa CurrentDateTool\n    print(response1)\n\n    response2 = await agent.chat(\"Leia o arquivo report.pdf\")  # Usa ReadLocalFileTool\n    print(response2)\n\n    # Verificar ferramentas dispon\u00edveis\n    all_tools = agent.get_all_available_tools()\n    print(f\"Total de ferramentas: {len(all_tools)}\")\n\n    # Ver apenas ferramentas do sistema\n    system_tools = agent.get_system_available_tools()\n    for name in system_tools.keys():\n        print(f\"  \u2022 {name}\")\n\nasyncio.run(main())\n</code></pre> <p>Ferramentas Dispon\u00edveis:</p> <ul> <li><code>currentdate</code> - Data/hora em qualquer timezone (sempre dispon\u00edvel)</li> <li><code>readlocalfile</code> - L\u00ea PDF, Excel, CSV, Parquet, JSON, YAML, TXT (requer <code>pip install createagents[file-tools]</code>)</li> </ul> <p>Criar ferramentas customizadas:</p> <pre><code>from createagents import BaseTool\n\nclass CalculatorTool(BaseTool):\n    name = \"calculator\"\n    description = \"Performs mathematical calculations\"\n    parameters = {\n        \"type\": \"object\",\n        \"properties\": {\n            \"expression\": {\n                \"type\": \"string\",\n                \"description\": \"Mathematical expression to evaluate\",\n            }\n        },\n        \"required\": [\"expression\"]\n    }\n\n    def execute(self, expression: str) -&gt; str:\n        return str(eval(expression))\n\n\n# Usar ferramenta customizada\nagent = CreateAgent(\n    provider=\"openai\",\n    model=\"gpt-4\",\n    tools=[\"currentdate\", CalculatorTool()]  # Sistema + customizada\n)\n\n# Ver todas (sistema + customizadas)\nprint(agent.get_all_available_tools().keys())\n# Sa\u00edda: dict_keys(['currentdate', 'readlocalfile', 'my_tool'])\n</code></pre>"},{"location":"#historico-contextual","title":"\ud83d\udcac Hist\u00f3rico Contextual","text":"<pre><code>import asyncio\n\nasync def main():\n    agent = CreateAgent(provider=\"openai\", model=\"gpt-4\")\n\n    await agent.chat(\"Ol\u00e1!\")\n    await agent.chat(\"Qual \u00e9 a capital do Brasil?\")  # Mant\u00e9m contexto\n    await agent.chat(\"E a popula\u00e7\u00e3o?\")              # Usa contexto anterior\n\n    # Ver hist\u00f3rico\n    config = agent.get_configs()\n    print(f\"Hist\u00f3rico: {len(config['history'])} mensagens\")\n\n    # Limpar quando necess\u00e1rio\n    agent.clear_history()\n\nasyncio.run(main())\n</code></pre>"},{"location":"#metricas-e-monitoramento","title":"\ud83d\udcca M\u00e9tricas e Monitoramento","text":"<pre><code># Coletar m\u00e9tricas\nmetrics = agent.get_metrics()\n\n# Exportar em diferentes formatos\nagent.export_metrics_json(\"metrics.json\")\nagent.export_metrics_prometheus(\"metrics.prom\")\n</code></pre>"},{"location":"#configuracoes-personalizadas","title":"\u2699\ufe0f Configura\u00e7\u00f5es Personalizadas","text":"<pre><code>agent = CreateAgent(\n    provider=\"openai\",\n    model=\"gpt-4\",\n    instructions=\"Seja conciso e t\u00e9cnico\",\n    config={\n        \"temperature\": 0.7,      # Criatividade (0-1)\n        \"max_tokens\": 2000,      # Limite de resposta\n    },\n    history_max_size=20         # Tamanho do hist\u00f3rico\n)\n</code></pre>"},{"location":"#documentacao","title":"\ud83d\udcda Documenta\u00e7\u00e3o","text":""},{"location":"#para-usuarios","title":"Para Usu\u00e1rios","text":"<ul> <li>Instala\u00e7\u00e3o - Configure seu ambiente passo a passo</li> <li>Uso B\u00e1sico - Aprenda os fundamentos</li> <li>Exemplos Pr\u00e1ticos - Casos de uso reais</li> <li>FAQ - Perguntas frequentes</li> </ul>"},{"location":"#para-desenvolvedores","title":"Para Desenvolvedores","text":"<ul> <li>Arquitetura - Clean Architecture e padr\u00f5es de design</li> <li>Exemplos T\u00e9cnicos - Exemplos avan\u00e7ados</li> <li>Como Contribuir - Guia de contribui\u00e7\u00e3o</li> </ul>"},{"location":"#referencia","title":"Refer\u00eancia","text":"<ul> <li>API Reference - Documenta\u00e7\u00e3o completa da API</li> <li>Ferramentas - Guia completo das tools dispon\u00edveis</li> <li>Comandos - Refer\u00eancia de comandos</li> </ul>"},{"location":"#por-que-usar-este-framework","title":"\ud83c\udfd7\ufe0f Por Que Usar Este Framework?","text":""},{"location":"#para-empresas","title":"Para Empresas","text":"<ul> <li>\u2705 Privacidade: Op\u00e7\u00e3o de modelos 100% locais com Ollama</li> <li>\u2705 Seguran\u00e7a: Sanitiza\u00e7\u00e3o autom\u00e1tica de dados sens\u00edveis nos logs</li> <li>\u2705 Monitoramento: M\u00e9tricas em tempo real para produ\u00e7\u00e3o</li> <li>\u2705 Escalabilidade: Arquitetura preparada para crescimento</li> </ul>"},{"location":"#para-desenvolvedores_1","title":"Para Desenvolvedores","text":"<ul> <li>\u2705 Clean Architecture: C\u00f3digo limpo, test\u00e1vel e manuten\u00edvel</li> <li>\u2705 SOLID: F\u00e1cil de estender com novos provedores e ferramentas</li> <li>\u2705 Type hints: Suporte completo para IDEs</li> <li>\u2705 CI/CD: Quality checks autom\u00e1ticos com GitHub Actions</li> </ul>"},{"location":"#arquitetura","title":"\ud83d\udcca Arquitetura","text":"<p>O projeto segue Clean Architecture e SOLID principles:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502        application                 \u2502  \u2190 CreateAgent (interface simples)\n\u2502     (Controllers/UI)                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n               \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502        APPLICATION                  \u2502  \u2190 Use Cases &amp; DTOs\n\u2502    (Business Logic)                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n               \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502          DOMAIN                     \u2502  \u2190 Entities &amp; Rules\n\u2502    (Core Business)                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b2\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n               \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      INFRASTRUCTURE                 \u2502  \u2190 Adapters (OpenAI, Ollama)\n\u2502  (External Services)                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Benef\u00edcios: Test\u00e1vel, Flex\u00edvel, Escal\u00e1vel e Manuten\u00edvel</p> <p>Saiba mais sobre a arquitetura \u2192</p>"},{"location":"#contribuindo","title":"\ud83e\udd1d Contribuindo","text":"<p>Quer adicionar um novo provedor ou criar uma ferramenta?</p> <ol> <li>Fork o reposit\u00f3rio</li> <li>Crie uma branch: <code>git checkout -b feature/nova-feature</code></li> <li>Implemente seguindo os padr\u00f5es existentes</li> <li>Teste: <code>poetry run pytest --cov=src</code></li> <li>Envie um Pull Request</li> </ol> <p>Guia completo de contribui\u00e7\u00e3o \u2192</p>"},{"location":"#suporte","title":"\ud83d\udcde Suporte","text":"<ul> <li>\ud83d\udce7 Email: estraliotojordan@gmail.com</li> <li>\ud83d\udc1b Bugs: GitHub Issues</li> <li>\ud83d\udcac Discuss\u00f5es: GitHub Discussions</li> </ul>"},{"location":"#licenca","title":"\ud83d\udcc4 Licen\u00e7a","text":"<p>MIT - Use livremente em seus projetos.</p>"},{"location":"#autor","title":"\ud83d\udc68\u200d\ud83d\udcbb Autor","text":"<p>Jordan Estralioto</p> <ul> <li>GitHub: @jor0105</li> <li>Email: estraliotojordan@gmail.com</li> </ul> <p>Vers\u00e3o: 0.2.0 \u00daltima atualiza\u00e7\u00e3o: 02/12/2025 Status: \ud83d\ude80 Projeto publicado! Aberto para contribui\u00e7\u00f5es e sugest\u00f5es.</p>"},{"location":"dev-guide/architecture-developer/","title":"\ud83c\udfd7\ufe0f Guia de Arquitetura para Desenvolvedores","text":"<p>Documenta\u00e7\u00e3o completa da arquitetura do Create Agents AI, baseada em Clean Architecture e princ\u00edpios SOLID.</p>"},{"location":"dev-guide/architecture-developer/#estrutura-de-camadas","title":"\ud83d\udcd0 Estrutura de Camadas","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502       PRESENTATION                  \u2502  CLI, UI (ChatCLIApplication)\n\u2502     (Interface do Usu\u00e1rio)          \u2502  Command Handlers, Terminal UI\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n               \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502        APPLICATION                  \u2502  Facade (CreateAgent)\n\u2502    (L\u00f3gica da Aplica\u00e7\u00e3o)            \u2502  Use Cases, DTOs, Services\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n               \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502          DOMAIN                     \u2502  Entities, Rules, Interfaces\n\u2502    (Regras de Neg\u00f3cio)              \u2502  Agent, ToolExecutor, LoggerInterface\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b2\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n               \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      INFRASTRUCTURE                 \u2502  Adapters, Handlers, Config\n\u2502    (Detalhes T\u00e9cnicos)              \u2502  OpenAI, Ollama, Tools, Metrics\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"dev-guide/architecture-developer/#camadas","title":"\ud83c\udfaf Camadas","text":""},{"location":"dev-guide/architecture-developer/#1-presentation-apresentacao","title":"1. Presentation (Apresenta\u00e7\u00e3o)","text":"<p>Localiza\u00e7\u00e3o: <code>src/createagents/presentation/</code></p> <p>Responsabilidade: Interface de usu\u00e1rio e intera\u00e7\u00e3o externa.</p> <p>Componentes:</p> <ul> <li>CLI Application: <code>ChatCLIApplication</code> \u2014 aplica\u00e7\u00e3o CLI interativa para chat com agentes</li> <li>Command Handlers: Sistema baseado no Command Pattern</li> <li><code>ChatCommandHandler</code> \u2014 processamento de mensagens de chat</li> <li><code>HelpCommandHandler</code> \u2014 exibe ajuda e comandos dispon\u00edveis</li> <li><code>MetricsCommandHandler</code> \u2014 mostra m\u00e9tricas de performance</li> <li><code>ConfigsCommandHandler</code> \u2014 exibe configura\u00e7\u00f5es do agente</li> <li><code>ToolsCommandHandler</code> \u2014 lista ferramentas dispon\u00edveis</li> <li><code>ClearCommandHandler</code> \u2014 limpa hist\u00f3rico de conversa\u00e7\u00e3o</li> <li>UI Components: <code>TerminalRenderer</code>, <code>TerminalFormatter</code>, <code>ColorScheme</code> \u2014 renderiza\u00e7\u00e3o colorida no terminal</li> <li>I/O: <code>InputReader</code> \u2014 leitura de entrada do usu\u00e1rio</li> <li>Registry: <code>CommandRegistry</code> \u2014 registro e resolu\u00e7\u00e3o de comandos</li> </ul>"},{"location":"dev-guide/architecture-developer/#2-application-aplicacao","title":"2. Application (Aplica\u00e7\u00e3o)","text":"<p>Localiza\u00e7\u00e3o: <code>src/createagents/application/</code></p> <p>Responsabilidade: Orquestrar casos de uso do sistema.</p> <p>Componentes:</p> <ul> <li>Facade / Controller: <code>CreateAgent</code> \u2014 fachada simples que cria agentes e exp\u00f5e m\u00e9todos como <code>chat</code> (async), <code>get_configs</code>, <code>get_all_available_tools</code>, <code>clear_history</code>, <code>export_metrics_*</code>.</li> <li>Services: <code>AgentService</code> \u2014 servi\u00e7o que encapsula <code>Agent</code> com logging integrado</li> <li>Use Cases (application/use_cases):</li> <li><code>CreateAgentUseCase</code> \u2014 cria\u00e7\u00e3o e valida\u00e7\u00e3o de agentes (invocado por <code>AgentComposer</code>).</li> <li><code>ChatWithAgentUseCase</code> \u2014 orquestra mensagens ass\u00edncronas entre <code>Agent</code> e <code>ChatRepository</code> (adapters).</li> <li><code>GetAgentConfigUseCase</code> \u2014 retorna as configura\u00e7\u00f5es do agente.</li> <li><code>GetAllAvailableToolsUseCase</code> / <code>GetSystemAvailableToolsUseCase</code> \u2014 listagem de tools dispon\u00edveis.</li> <li>DTOs (application/dtos): Objetos de transfer\u00eancia:</li> <li><code>CreateAgentInputDTO</code>, <code>ChatInputDTO</code>, <code>AgentConfigOutputDTO</code> \u2014 comunica\u00e7\u00e3o entre controller/use-cases</li> <li><code>StreamingResponseDTO</code> \u2014 wrapper para AsyncGenerator que permite itera\u00e7\u00e3o e await de respostas em streaming</li> <li>Interfaces (application/interfaces): <code>ChatRepository</code> \u2014 contrato que os adapters implementam com suporte ass\u00edncrono</li> </ul>"},{"location":"dev-guide/architecture-developer/#3-domain-dominio","title":"3. Domain (Dom\u00ednio)","text":"<p>Localiza\u00e7\u00e3o: <code>src/createagents/domain/</code></p> <p>Responsabilidade: Regras de neg\u00f3cio puras, independentes de tecnologia.</p> <p>Componentes:</p> <ul> <li>Entities: <code>Agent</code> (entidade principal)</li> <li>Value Objects: <code>Message</code>, <code>MessageRole</code>, <code>History</code>, <code>SupportedConfigs</code>, <code>SupportedProviders</code>, <code>BaseTool</code> (ferramentas), <code>ChatResponse</code></li> <li>Domain Services: <code>ToolExecutor</code> (execu\u00e7\u00e3o ass\u00edncrona de ferramentas), <code>ToolExecutionResult</code></li> <li>Interfaces (domain/interfaces): <code>LoggerInterface</code> \u2014 abstra\u00e7\u00e3o de logging no dom\u00ednio (DIP - Dependency Inversion Principle)</li> <li>Exceptions: <code>domain.exceptions</code> (ex.: <code>AgentException</code>, <code>InvalidAgentConfigException</code>, <code>UnsupportedConfigException</code>)</li> </ul>"},{"location":"dev-guide/architecture-developer/#4-infrastructure-infraestrutura","title":"4. Infrastructure (Infraestrutura)","text":"<p>Localiza\u00e7\u00e3o: <code>src/createagents/infra/</code></p> <p>Responsabilidade: Implementar detalhes t\u00e9cnicos e integra\u00e7\u00f5es externas.</p> <p>Componentes:</p> <ul> <li>Adapters (Chat):</li> <li><code>OpenAIChatAdapter</code> \u2014 integra\u00e7\u00e3o com OpenAI</li> <li><code>OllamaChatAdapter</code> \u2014 integra\u00e7\u00e3o com Ollama</li> <li>Handlers (Async Streaming):</li> <li><code>OpenAIHandler</code> / <code>OpenAIStreamHandler</code> \u2014 processamento de chamadas n\u00e3o-streaming e streaming OpenAI</li> <li><code>OllamaHandler</code> / <code>OllamaStreamHandler</code> \u2014 processamento de chamadas n\u00e3o-streaming e streaming Ollama</li> <li>Clients:</li> <li><code>OpenAIClient</code> \u2014 cliente HTTP para OpenAI</li> <li><code>OllamaClient</code> \u2014 cliente HTTP para Ollama</li> <li>Common Adapters:</li> <li><code>MetricsRecorder</code> \u2014 grava\u00e7\u00e3o centralizada de m\u00e9tricas (OpenAI e Ollama)</li> <li>Tools:</li> <li><code>CurrentDateTool</code> \u2014 ferramenta de data/hora</li> <li><code>ReadLocalFileTool</code> \u2014 leitura de arquivos (PDF, Excel, CSV, Parquet, JSON, YAML, TXT)</li> <li>Factory: <code>ChatAdapterFactory</code> \u2014 cria\u00e7\u00e3o de adapters baseada em provider</li> <li>Config: <code>EnvironmentConfig</code>, <code>LoggingConfig</code>, <code>StandardLogger</code> (implementa\u00e7\u00e3o de <code>LoggerInterface</code>), <code>ChatMetrics</code></li> </ul>"},{"location":"dev-guide/architecture-developer/#principios-solid","title":"\ud83c\udfa8 Princ\u00edpios SOLID","text":""},{"location":"dev-guide/architecture-developer/#single-responsibility-srp","title":"Single Responsibility (SRP)","text":"<p>Cada classe tem uma \u00fanica responsabilidade:</p> <pre><code>Agent          # Representa um agente\nHistory        # Gerencia hist\u00f3rico\nChatWithAgentUseCase  # Orquestra conversa\n</code></pre>"},{"location":"dev-guide/architecture-developer/#openclosed-ocp","title":"Open/Closed (OCP)","text":"<p>Aberto para extens\u00e3o, fechado para modifica\u00e7\u00e3o:</p> <pre><code># Adicionar novo provider sem modificar c\u00f3digo existente\nclass ClaudeAdapter(ChatRepository):\n    def chat(self, ...): pass\n</code></pre>"},{"location":"dev-guide/architecture-developer/#liskov-substitution-lsp","title":"Liskov Substitution (LSP)","text":"<p>Adapters s\u00e3o intercambi\u00e1veis:</p> <pre><code># Qualquer adapter pode substituir outro\nadapter: ChatRepository = OpenAIChatAdapter()\n# ou\nadapter: ChatRepository = OllamaChatAdapter()\n</code></pre>"},{"location":"dev-guide/architecture-developer/#interface-segregation-isp","title":"Interface Segregation (ISP)","text":"<p>Interfaces espec\u00edficas e focadas:</p> <pre><code>class ChatRepository(ABC):\n    @abstractmethod\n    def chat(self, ...) -&gt; str:\n        pass\n</code></pre>"},{"location":"dev-guide/architecture-developer/#dependency-inversion-dip","title":"Dependency Inversion (DIP)","text":"<p>Depende de abstra\u00e7\u00f5es, n\u00e3o de implementa\u00e7\u00f5es:</p> <pre><code>class ChatWithAgentUseCase:\n    def __init__(self, chat_repository: ChatRepository):  # Interface\n        self.__chat_repository = chat_repository\n\n# Exemplo com LoggerInterface (DIP no dom\u00ednio)\nclass ToolExecutor:\n    def __init__(self, logger: LoggerInterface):  # Abstra\u00e7\u00e3o\n        self._logger = logger  # N\u00e3o depende de StandardLogger diretamente\n</code></pre>"},{"location":"dev-guide/architecture-developer/#padroes-de-design","title":"\ud83d\udd27 Padr\u00f5es de Design","text":""},{"location":"dev-guide/architecture-developer/#repository-pattern","title":"Repository Pattern","text":"<pre><code>class ChatRepository(ABC):\n    @abstractmethod\n    def chat(self, ...) -&gt; str:\n        pass\n\nclass OpenAIChatAdapter(ChatRepository):\n    def chat(self, ...): # Implementa\u00e7\u00e3o\n</code></pre>"},{"location":"dev-guide/architecture-developer/#factory-pattern","title":"Factory Pattern","text":"<pre><code>class ChatAdapterFactory:\n    @classmethod\n    def create(\n        cls,\n        provider: str,\n        model: str,\n    ) -&gt; ChatRepository:\n\n        provider_lower = provider.lower()\n        adapter: ChatRepository\n\n        if provider_lower == \"openai\":\n            adapter = OpenAIChatAdapter()\n        elif provider_lower == \"ollama\":\n            adapter = OllamaChatAdapter()\n        else:\n            raise ValueError(f\"Invalid provider: {provider}.\")\n        return adapter\n</code></pre>"},{"location":"dev-guide/architecture-developer/#facade-pattern","title":"Facade Pattern","text":"<pre><code># CreateAgent \u00e9 uma fachada simplificada\nclass CreateAgent:\n    def __init__(self, provider, model, ...):\n        # Esconde complexidade da cria\u00e7\u00e3o\n        self.__agent = AgentComposer.create_agent(...)\n        self.__chat_use_case = AgentComposer.create_chat_use_case(...)\n</code></pre>"},{"location":"dev-guide/architecture-developer/#value-object-pattern","title":"Value Object Pattern","text":"<pre><code>@dataclass(frozen=True)  # Imut\u00e1vel\nclass Message:\n    role: MessageRole\n    content: str\n</code></pre>"},{"location":"dev-guide/architecture-developer/#fluxo-de-dados","title":"\ud83d\udd04 Fluxo de Dados","text":""},{"location":"dev-guide/architecture-developer/#fluxo-sincrono-await-response","title":"Fluxo S\u00edncrono (await response)","text":"<pre><code>User \u2192 CreateAgent.chat()\n    \u2192 ChatWithAgentUseCase.execute() [async]\n        \u2192 ChatRepository.chat() [async]\n            \u2192 OpenAIHandler / OllamaHandler\n                \u2192 StreamHandler (processa streaming)\n                    \u2192 API Externa (OpenAI / Ollama)\n                    \u2190 Tokens em streaming\n                \u2190 Response completo\n            \u2190 AsyncGenerator\n        \u2190 StreamingResponseDTO\n    \u2190 await response (string completa)\n</code></pre>"},{"location":"dev-guide/architecture-developer/#fluxo-assincrono-async-for","title":"Fluxo Ass\u00edncrono (async for)","text":"<pre><code>User \u2192 CreateAgent.chat()\n    \u2192 ChatWithAgentUseCase.execute() [async]\n        \u2192 ChatRepository.chat() [async]\n            \u2192 StreamHandler.handle_streaming()\n                \u2192 async for token in api_stream:\n                    \u2192 yield token  # Streaming em tempo real\n            \u2190 AsyncGenerator[str]\n        \u2190 StreamingResponseDTO\n    \u2192 async for token in response:\n        \u2192 print(token, end='')  # Exibe token por token\n</code></pre>"},{"location":"dev-guide/architecture-developer/#fluxo-cli","title":"Fluxo CLI","text":"<pre><code>Terminal \u2192 ChatCLIApplication.run()\n    \u2192 CommandRegistry.find_handler(user_input)\n        \u2192 CommandHandler.execute()\n            \u2192 CreateAgent.chat() [se ChatCommandHandler]\n                \u2192 async for token in response:\n                    \u2192 TerminalRenderer.render_token()\n</code></pre>"},{"location":"dev-guide/architecture-developer/#beneficios-da-arquitetura","title":"\ud83d\udca1 Benef\u00edcios da Arquitetura","text":""},{"location":"dev-guide/architecture-developer/#testabilidade","title":"\ud83e\uddea Testabilidade","text":"<pre><code># Mock f\u00e1cil de depend\u00eancias\nmock_repo = Mock(spec=ChatRepository)\nuse_case = ChatWithAgentUseCase(mock_repo)\n</code></pre>"},{"location":"dev-guide/architecture-developer/#flexibilidade","title":"\ud83d\udd04 Flexibilidade","text":"<pre><code># Trocar provider sem mudar c\u00f3digo\nagent = CreateAgent(provider=\"ollama\", model=\"llama2\")\n</code></pre>"},{"location":"dev-guide/architecture-developer/#escalabilidade","title":"\ud83d\udcc8 Escalabilidade","text":"<ul> <li>Adicionar novos providers facilmente</li> <li>Extens\u00edvel via interfaces</li> <li>Preparado para crescimento</li> </ul>"},{"location":"dev-guide/architecture-developer/#manutenibilidade","title":"\ud83d\udee1\ufe0f Manutenibilidade","text":"<ul> <li>C\u00f3digo organizado em camadas</li> <li>Responsabilidades claras</li> <li>F\u00e1cil localizar e corrigir bugs</li> </ul>"},{"location":"dev-guide/architecture-developer/#padroes-assincronos","title":"\ud83d\udd04 Padr\u00f5es Ass\u00edncronos","text":""},{"location":"dev-guide/architecture-developer/#streaming-com-asyncgenerator","title":"Streaming com AsyncGenerator","text":"<pre><code># Handler retorna AsyncGenerator\nasync def handle_streaming(self, ...) -&gt; AsyncGenerator[str, None]:\n    async for chunk in api_response:\n        yield chunk  # Stream em tempo real\n\n# DTO encapsula AsyncGenerator\nclass StreamingResponseDTO:\n    def __init__(self, generator: AsyncGenerator[str, None]):\n        self._generator = generator\n\n    async def __anext__(self):  # Permite async for\n        return await self._generator.__anext__()\n\n    def __await__(self):  # Permite await\n        async def _consume():\n            return ''.join([token async for token in self])\n        return _consume().__await__()\n</code></pre> <p>Vers\u00e3o: 0.1.3 | Atualiza\u00e7\u00e3o: 01/12/2025</p>"},{"location":"dev-guide/async-guide/","title":"Guia de Programa\u00e7\u00e3o Ass\u00edncrona","text":"<p>Este guia explica como a arquitetura ass\u00edncrona funciona no CreateAgents AI.</p>"},{"location":"dev-guide/async-guide/#por-que-async","title":"\ud83d\udd04 Por Que Async?","text":"<p>O CreateAgents AI usa programa\u00e7\u00e3o ass\u00edncrona para:</p> <ul> <li>Streaming: Tokens em tempo real das APIs (OpenAI/Ollama)</li> <li>Tools: Execu\u00e7\u00e3o n\u00e3o-bloqueante de ferramentas</li> <li>Performance: M\u00faltiplas chamadas concorrentes</li> </ul>"},{"location":"dev-guide/async-guide/#componentes-assincronos","title":"\ud83c\udfaf Componentes Ass\u00edncronos","text":""},{"location":"dev-guide/async-guide/#chatrepository-interface","title":"ChatRepository (Interface)","text":"<pre><code>class ChatRepository(ABC):\n    @abstractmethod\n    async def chat(self, agent: Agent, message: str) -&gt; AsyncGenerator[str, None]:\n        \"\"\"Chat ass\u00edncrono que retorna AsyncGenerator.\"\"\"\n        pass\n</code></pre>"},{"location":"dev-guide/async-guide/#chatadapter-implementacao","title":"ChatAdapter (Implementa\u00e7\u00e3o)","text":"<pre><code>class OpenAIChatAdapter(ChatRepository):\n    async def chat(self, agent: Agent, message: str) -&gt; AsyncGenerator[str, None]:\n        handler = OpenAIStreamHandler(...)\n        async for token in handler.handle_streaming(...):\n            yield token\n</code></pre>"},{"location":"dev-guide/async-guide/#stream-handlers","title":"Stream Handlers","text":""},{"location":"dev-guide/async-guide/#openaistreamhandler","title":"OpenAIStreamHandler","text":"<pre><code>class OpenAIStreamHandler:\n    async def handle_streaming(\n        self,\n        client,\n        model: str,\n        messages,\n        ...\n    ) -&gt; AsyncGenerator[str, None]:\n        # Inicia streaming\n        stream = client.chat.completions.create(\n            model=model,\n            messages=messages,\n            stream=True,\n            ...\n        )\n\n        async for chunk in stream:\n            if chunk.choices[0].delta.content:\n                yield chunk.choices[0].delta.content\n</code></pre>"},{"location":"dev-guide/async-guide/#ollamastreamhandler","title":"OllamaStreamHandler","text":"<pre><code>class OllamaStreamHandler:\n    async def handle_streaming(\n        self,\n        client,\n        model: str,\n        messages,\n        ...\n    ) -&gt; AsyncGenerator[str, None]:\n        async for response in client.chat(\n            model=model,\n            messages=messages,\n            stream=True,\n            ...\n        ):\n            if response.get('message', {}).get('content'):\n                yield response['message']['content']\n</code></pre>"},{"location":"dev-guide/async-guide/#execucao-assincrona-de-ferramentas","title":"\ud83d\udee0\ufe0f Execu\u00e7\u00e3o Ass\u00edncrona de Ferramentas","text":""},{"location":"dev-guide/async-guide/#toolexecutor","title":"ToolExecutor","text":"<pre><code>class ToolExecutor:\n    async def execute(\n        self,\n        tool: BaseTool,\n        arguments: Dict[str, Any]\n    ) -&gt; ToolExecutionResult:\n        self._logger.info(\"Executing tool: %s\", tool.name)\n\n        try:\n            # Executa tool (pode ser async ou sync)\n            if asyncio.iscoroutinefunction(tool.execute):\n                result = await tool.execute(**arguments)\n            else:\n                result = tool.execute(**arguments)\n\n            return ToolExecutionResult(success=True, result=result)\n        except Exception as e:\n            return ToolExecutionResult(success=False, error=str(e))\n</code></pre>"},{"location":"dev-guide/async-guide/#fluxo-assincrono-completo","title":"\ud83d\udd04 Fluxo Ass\u00edncrono Completo","text":""},{"location":"dev-guide/async-guide/#sem-ferramentas","title":"Sem Ferramentas","text":"<pre><code>User: await agent.chat(\"mensagem\")\n  \u2192 ChatWithAgentUseCase.execute() [async]\n      \u2192 ChatRepository.chat() [async]\n          \u2192 OpenAIStreamHandler.handle_streaming() [async]\n              \u2192 async for chunk in openai_stream:\n                  \u2192 yield chunk\n          \u2190 AsyncGenerator[str, None]\n      \u2190 StreamingResponseDTO\n  \u2190 await response (string completa)\n</code></pre>"},{"location":"dev-guide/async-guide/#com-ferramentas","title":"Com Ferramentas","text":"<pre><code>User: await agent.chat(\"Que dia \u00e9 hoje?\")\n  \u2192 ChatWithAgentUseCase.execute() [async]\n      \u2192 ChatRepository.chat() [async]\n          \u2192 OpenAIStreamHandler.handle_streaming() [async]\n              \u2192 async for chunk in openai_stream:\n                  \u2192 Detecta tool_calls\n              \u2192 Para cada tool_call:\n                  \u2192 ToolExecutor.execute(tool, args) [async]\n                      \u2190 ToolExecutionResult\n              \u2192 Segunda chamada API com tool results\n              \u2192 async for token in second_stream:\n                  \u2192 yield token\n          \u2190 AsyncGenerator[str, None]\n      \u2190 StreamingResponseDTO\n  \u2190 await response\n</code></pre>"},{"location":"dev-guide/async-guide/#padroes-de-uso","title":"\ud83d\udca1 Padr\u00f5es de Uso","text":""},{"location":"dev-guide/async-guide/#padrao-1-consumo-simples-await","title":"Padr\u00e3o 1: Consumo Simples (Await)","text":"<pre><code>import asyncio\n\nasync def simple_chat():\n    from createagents import CreateAgent\n\n    agent = CreateAgent(provider=\"openai\", model=\"gpt-4\")\n    response = await agent.chat(\"Ol\u00e1\")  # Aguarda string completa\n    print(response)\n\nasyncio.run(simple_chat())\n</code></pre>"},{"location":"dev-guide/async-guide/#padrao-2-streaming-manual-async-for","title":"Padr\u00e3o 2: Streaming Manual (Async For)","text":"<pre><code>import asyncio\n\nasync def streaming_chat():\n    from createagents import CreateAgent\n\n    agent = CreateAgent(provider=\"openai\", model=\"gpt-4\")\n    response = await agent.chat(\"Conte uma hist\u00f3ria\")\n\n    async for token in response:\n        print(token, end='', flush=True)\n    print()\n\nasyncio.run(streaming_chat())\n</code></pre>"},{"location":"dev-guide/async-guide/#padrao-3-multiplas-chamadas-concorrentes","title":"Padr\u00e3o 3: M\u00faltiplas Chamadas Concorrentes","text":"<pre><code>import asyncio\n\nasync def concurrent_chats():\n    from createagents import CreateAgent\n\n    agent1 = CreateAgent(provider=\"openai\", model=\"gpt-4\")\n    agent2 = CreateAgent(provider=\"openai\", model=\"gpt-4\")\n\n    # Executar simultaneamente\n    results = await asyncio.gather(\n        agent1.chat(\"Pergunta 1\"),\n        agent2.chat(\"Pergunta 2\"),\n    )\n\n    print(results[0])\n    print(results[1])\n\nasyncio.run(concurrent_chats())\n</code></pre>"},{"location":"dev-guide/async-guide/#padrao-4-ferramentas-assincronas","title":"Padr\u00e3o 4: Ferramentas Ass\u00edncronas","text":"<pre><code>from createagents import BaseTool\nimport asyncio\nimport aiohttp\n\nclass AsyncWebTool(BaseTool):\n    name = \"async_web_fetch\"\n    description = \"Busca dados da web assincronamente\"\n    parameters = {\n        \"type\": \"object\",\n        \"properties\": {\n            \"url\": {\"type\": \"string\", \"description\": \"URL to fetch\"}\n        },\n        \"required\": [\"url\"]\n    }\n\n    async def execute(self, url: str) -&gt; str:\n        async with aiohttp.ClientSession() as session:\n            async with session.get(url) as response:\n                return await response.text()\n\n# Uso\nasync def main():\n    agent = CreateAgent(\n        provider=\"openai\",\n        model=\"gpt-4\",\n        tools=[AsyncWebTool()]\n    )\n\n    response = await agent.chat(\"Busque dados de https://api.example.com\")\n    print(await response)\n\nasyncio.run(main())\n</code></pre>"},{"location":"dev-guide/async-guide/#implementacao-de-handlers","title":"\ud83d\udd27 Implementa\u00e7\u00e3o de Handlers","text":""},{"location":"dev-guide/async-guide/#handler-nao-streaming","title":"Handler N\u00e3o-Streaming","text":"<pre><code>class OpenAIHandler:\n    async def handle_non_streaming(\n        self,\n        client,\n        model: str,\n        messages: List[dict],\n        ...\n    ) -&gt; str:\n        response = await client.chat.completions.create(\n            model=model,\n            messages=messages,\n            stream=False,\n            ...\n        )\n        return response.choices[0].message.content\n</code></pre>"},{"location":"dev-guide/async-guide/#handler-com-metricas","title":"Handler com M\u00e9tricas","text":"<pre><code>class OpenAIStreamHandler:\n    def __init__(self, ...):\n        self._logger = LoggingConfig.get_logger(__name__)\n        self._metrics = MetricsRecorder(metrics_list)\n\n    async def handle_streaming(self, ...) -&gt; AsyncGenerator[str, None]:\n        start_time = time.time()\n\n        try:\n            # Streaming\n            async for token in stream:\n                yield token\n\n            # Gravar m\u00e9tricas de sucesso\n            self._metrics.record_success_metrics(\n                model=model,\n                start_time=start_time,\n                response_api=full_response,\n                provider_type='openai'\n            )\n        except Exception as e:\n            # Gravar m\u00e9tricas de erro\n            self._metrics.record_error_metrics(\n                model=model,\n                start_time=start_time,\n                error=e\n            )\n            raise\n</code></pre>"},{"location":"dev-guide/async-guide/#armadilhas-comuns","title":"\ud83d\udc1b Armadilhas Comuns","text":""},{"location":"dev-guide/async-guide/#1-esquecer-await","title":"1. Esquecer await","text":"<pre><code># \u274c ERRADO\nresponse = agent.chat(\"mensagem\")  # Retorna coroutine\nprint(response)  # &lt;coroutine object...&gt;\n\n# \u2705 CORRETO\nresponse = await agent.chat(\"mensagem\")\nprint(await response)  # String\n</code></pre>"},{"location":"dev-guide/async-guide/#2-bloquear-loop-de-eventos","title":"2. Bloquear Loop de Eventos","text":"<pre><code># \u274c ERRADO (blocking I/O)\nasync def bad_function():\n    time.sleep(10)  # Bloqueia todo o loop!\n\n# \u2705 CORRETO (non-blocking)\nasync def good_function():\n    await asyncio.sleep(10)  # Permite outras tasks\n</code></pre>"},{"location":"dev-guide/async-guide/#3-nao-usar-asynciorun","title":"3. N\u00e3o Usar asyncio.run()","text":"<pre><code># \u274c ERRADO\nasync def main():\n    response = await agent.chat(\"mensagem\")\n    print(await response)\n\nmain()  # Erro! Coroutine n\u00e3o executada\n\n# \u2705 CORRETO\nasyncio.run(main())\n</code></pre>"},{"location":"dev-guide/async-guide/#4-consumir-stream-duas-vezes","title":"4. Consumir Stream Duas Vezes","text":"<pre><code># \u274c ERRADO\nresponse = await agent.chat(\"mensagem\")\ntext1 = await response  # Consome stream\ntext2 = await response  # J\u00e1 consumido! text2 = \"\"\n\n# \u2705 CORRETO\nresponse = await agent.chat(\"mensagem\")\ntext = await response  # Consumir apenas uma vez\n</code></pre>"},{"location":"dev-guide/async-guide/#performance","title":"\ud83d\udcca Performance","text":""},{"location":"dev-guide/async-guide/#concorrencia-vs-sequencial","title":"Concorr\u00eancia vs Sequencial","text":"<p>Sequencial:</p> <pre><code>async def sequential():\n    r1 = await agent.chat(\"Q1\")  # 2s\n    r2 = await agent.chat(\"Q2\")  # 2s\n    r3 = await agent.chat(\"Q3\")  # 2s\n    # Total: 6s\n</code></pre> <p>Concorrente:</p> <pre><code>async def concurrent():\n    results = await asyncio.gather(\n        agent.chat(\"Q1\"),  # 2s\n        agent.chat(\"Q2\"),  # 2s\n        agent.chat(\"Q3\"),  # 2s\n    )\n    # Total: ~2s (paralelizado)\n</code></pre>"},{"location":"dev-guide/async-guide/#testando-codigo-assincrono","title":"\ud83e\uddea Testando C\u00f3digo Ass\u00edncrono","text":"<pre><code>import pytest\n\n@pytest.mark.asyncio\nasync def test_chat():\n    agent = CreateAgent(provider=\"openai\", model=\"gpt-4\")\n    response = await agent.chat(\"Test message\")\n    text = await response\n    assert isinstance(text, str)\n    assert len(text) &gt; 0\n\n@pytest.mark.asyncio\nasync def test_streaming():\n    agent = CreateAgent(provider=\"openai\", model=\"gpt-4\")\n    response = await agent.chat(\"Test\")\n\n    tokens = []\n    async for token in response:\n        tokens.append(token)\n\n    assert len(tokens) &gt; 0\n</code></pre>"},{"location":"dev-guide/async-guide/#best-practices","title":"\ud83d\udca1 Best Practices","text":"<ol> <li>Sempre use await: Para executar coroutines</li> <li>Use asyncio.gather: Para chamadas concorrentes</li> <li>N\u00e3o bloqueie: Use bibliotecas async (aiohttp, aiofiles)</li> <li>Trate exce\u00e7\u00f5es: try/except em c\u00f3digo async</li> <li>Logging apropriado: Use logger em fun\u00e7\u00f5es async</li> <li>Teste com pytest-asyncio: Marque tests com <code>@pytest.mark.asyncio</code></li> </ol>"},{"location":"dev-guide/async-guide/#referencias","title":"\ud83d\udcda Refer\u00eancias","text":"<ul> <li>Python asyncio</li> <li>Async Generators</li> <li>API de Streaming</li> </ul> <p>Vers\u00e3o: 0.1.3 | Atualiza\u00e7\u00e3o: 01/12/2025</p>"},{"location":"dev-guide/cli-architecture/","title":"Arquitetura da CLI","text":"<p>Documenta\u00e7\u00e3o t\u00e9cnica da camada Presentation (CLI) do CreateAgents AI.</p>"},{"location":"dev-guide/cli-architecture/#visao-geral","title":"\ud83d\udcd0 Vis\u00e3o Geral","text":"<p>A CLI segue o Command Pattern para processar entrada do usu\u00e1rio e executar a\u00e7\u00f5es. \u00c9 totalmente desacoplada da camada de aplica\u00e7\u00e3o atrav\u00e9s de interfaces.</p> <pre><code>ChatCLIApplication (orquestrador)\n    \u251c\u2500\u2500 CommandRegistry (registro de comandos)\n    \u251c\u2500\u2500 TerminalRenderer (UI/renderiza\u00e7\u00e3o)\n    \u251c\u2500\u2500 InputReader (leitura de entrada)\n    \u2514\u2500\u2500 CommandHandlers (processadores espec\u00edficos)\n        \u251c\u2500\u2500 ChatCommandHandler\n        \u251c\u2500\u2500 HelpCommandHandler\n        \u251c\u2500\u2500 MetricsCommandHandler\n        \u251c\u2500\u2500 ConfigsCommandHandler\n        \u251c\u2500\u2500 ToolsCommandHandler\n        \u2514\u2500\u2500 ClearCommandHandler\n</code></pre>"},{"location":"dev-guide/cli-architecture/#componentes-principais","title":"\ud83c\udfaf Componentes Principais","text":""},{"location":"dev-guide/cli-architecture/#1-chatcliapplication","title":"1. ChatCLIApplication","text":"<p>Responsabilidade: Orquestrador principal do ciclo de vida da CLI.</p> <p>Localiza\u00e7\u00e3o: <code>src/createagents/presentation/cli/application/chat_cli_app.py</code></p> <pre><code>class ChatCLIApplication:\n    \"\"\"Main CLI application orchestrator.\n\n    Responsibility: Orchestrate the CLI application lifecycle.\n    This follows:\n    - SRP: Only handles application orchestration\n    - DIP: Depends on abstractions (CommandHandler interface)\n    - OCP: New commands can be added by registering new handlers\n    \"\"\"\n\n    def __init__(self, agent: 'CreateAgent'):\n        self._agent = agent\n        self._renderer = TerminalRenderer()\n        self._input_reader = InputReader()\n        self._registry = CommandRegistry()\n        self._setup_commands()\n\n    def run(self) -&gt; None:\n        \"\"\"Start the CLI application main loop.\"\"\"\n        # Loop principal\n</code></pre> <p>M\u00e9todos:</p> <ul> <li><code>__init__(agent)</code> - Inicializa componentes</li> <li><code>_setup_commands()</code> - Registra handlers de comandos</li> <li><code>run()</code> - Loop principal da aplica\u00e7\u00e3o</li> <li><code>_is_exit_command(input)</code> - Verifica comandos de sa\u00edda</li> </ul>"},{"location":"dev-guide/cli-architecture/#2-commandhandler-interface","title":"2. CommandHandler (Interface)","text":"<p>Responsabilidade: Interface abstrata para handlers de comandos.</p> <p>Localiza\u00e7\u00e3o: <code>src/createagents/presentation/cli/commands/base_command.py</code></p> <pre><code>class CommandHandler(ABC):\n    \"\"\"Abstract base class for command handlers.\n\n    This implements the Command Pattern, allowing dynamic\n    command registration and execution.\n    \"\"\"\n\n    def __init__(self, renderer: TerminalRenderer):\n        self._renderer = renderer\n\n    @abstractmethod\n    def can_handle(self, user_input: str) -&gt; bool:\n        \"\"\"Check if this handler can process the input.\"\"\"\n        pass\n\n    @abstractmethod\n    def execute(self, agent: 'CreateAgent', user_input: str) -&gt; None:\n        \"\"\"Execute the command.\"\"\"\n        pass\n\n    @abstractmethod\n    def get_aliases(self) -&gt; List[str]:\n        \"\"\"Get command aliases.\"\"\"\n        pass\n</code></pre>"},{"location":"dev-guide/cli-architecture/#3-commandregistry","title":"3. CommandRegistry","text":"<p>Responsabilidade: Registro e resolu\u00e7\u00e3o de comandos.</p> <p>Localiza\u00e7\u00e3o: <code>src/createagents/presentation/cli/application/command_registry.py</code></p> <pre><code>class CommandRegistry:\n    \"\"\"Registry for command handlers.\n\n    Responsibility: Maintain and resolve command handlers.\n    This follows OCP: new handlers can be added without modification.\n    \"\"\"\n\n    def __init__(self):\n        self._handlers: List[CommandHandler] = []\n\n    def register(self, handler: CommandHandler) -&gt; None:\n        \"\"\"Register a command handler.\"\"\"\n        self._handlers.append(handler)\n\n    def find_handler(self, user_input: str) -&gt; Optional[CommandHandler]:\n        \"\"\"Find the first handler that can process the input.\"\"\"\n        for handler in self._handlers:\n            if handler.can_handle(user_input):\n                return handler\n        return None\n</code></pre> <p>Padr\u00e3o de Registro: Os handlers s\u00e3o registrados em ordem, do mais espec\u00edfico ao mais gen\u00e9rico. O <code>ChatCommandHandler</code> deve ser sempre o \u00faltimo (handler padr\u00e3o).</p>"},{"location":"dev-guide/cli-architecture/#4-command-handlers","title":"4. Command Handlers","text":""},{"location":"dev-guide/cli-architecture/#chatcommandhandler","title":"ChatCommandHandler","text":"<p>Responsabilidade: Processar mensagens de chat (handler padr\u00e3o).</p> <pre><code>class ChatCommandHandler(CommandHandler):\n    \"\"\"Handles regular chat messages (default handler).\"\"\"\n\n    def can_handle(self, user_input: str) -&gt; bool:\n        # Aceita qualquer entrada (fallback)\n        return True\n\n    def execute(self, agent: 'CreateAgent', user_input: str) -&gt; None:\n        # Processa streaming ass\u00edncrono\n        asyncio.run(self._async_execute(agent, user_input))\n</code></pre>"},{"location":"dev-guide/cli-architecture/#helpcommandhandler","title":"HelpCommandHandler","text":"<p>Responsabilidade: Exibir ajuda e lista de comandos.</p> <pre><code>class HelpCommandHandler(CommandHandler):\n    def can_handle(self, user_input: str) -&gt; bool:\n        normalized = self._normalize_input(user_input)\n        return normalized in self.get_aliases()\n\n    def get_aliases(self) -&gt; List[str]:\n        return ['/help', 'help']\n</code></pre>"},{"location":"dev-guide/cli-architecture/#metricscommandhandler","title":"MetricsCommandHandler","text":"<p>Responsabilidade: Exibir m\u00e9tricas de performance.</p> <pre><code>class MetricsCommandHandler(CommandHandler):\n    def execute(self, agent: 'CreateAgent', user_input: str) -&gt; None:\n        metrics = agent.get_metrics()\n        # Formata e renderiza m\u00e9tricas\n</code></pre> <p>(Outros handlers seguem estrutura similar)</p>"},{"location":"dev-guide/cli-architecture/#5-terminalrenderer","title":"5. TerminalRenderer","text":"<p>Responsabilidade: Renderiza\u00e7\u00e3o de UI no terminal.</p> <p>Localiza\u00e7\u00e3o: <code>src/createagents/presentation/cli/ui/terminal_renderer.py</code></p> <pre><code>class TerminalRenderer:\n    \"\"\"Handles terminal rendering with colors and formatting.\n\n    Responsibility: Encapsulate all terminal output logic.\n    This follows SRP by handling only rendering concerns.\n    \"\"\"\n\n    def __init__(self):\n        self._formatter = TerminalFormatter()\n        self._colors = ColorScheme()\n\n    def render_welcome_screen(self) -&gt; None:\n        \"\"\"Display welcome message.\"\"\"\n\n    def render_prompt(self) -&gt; None:\n        \"\"\"Display user input prompt.\"\"\"\n\n    def render_assistant_token(self, token: str) -&gt; None:\n        \"\"\"Render a single token from assistant.\"\"\"\n\n    def render_system_message(self, message: str) -&gt; None:\n        \"\"\"Render a system message.\"\"\"\n\n    def render_error(self, message: str) -&gt; None:\n        \"\"\"Render an error message.\"\"\"\n</code></pre> <p>M\u00e9todos de Renderiza\u00e7\u00e3o:</p> <ul> <li><code>render_welcome_screen()</code> - Tela de boas-vindas</li> <li><code>render_prompt()</code> - Prompt de entrada</li> <li><code>render_input_indicator()</code> - Indicador \u270e</li> <li><code>render_assistant_token(token)</code> - Token individual do agente</li> <li><code>render_thinking_indicator()</code> - Indicador \u201cpensando\u2026\u201d</li> <li><code>render_system_message(msg)</code> - Mensagem do sistema</li> <li><code>render_error(msg)</code> - Mensagem de erro</li> <li><code>render_metrics(metrics)</code> - Exibir m\u00e9tricas</li> <li><code>render_configs(configs)</code> - Exibir configura\u00e7\u00f5es</li> <li><code>render_tools(tools)</code> - Exibir ferramentas</li> </ul>"},{"location":"dev-guide/cli-architecture/#6-terminalformatter","title":"6. TerminalFormatter","text":"<p>Responsabilidade: Formata\u00e7\u00e3o de markdown para terminal.</p> <p>Localiza\u00e7\u00e3o: <code>src/createagents/presentation/cli/ui/terminal_formatter.py</code></p> <pre><code>class TerminalFormatter:\n    \"\"\"Formats markdown text for terminal display.\n\n    Converts markdown elements to terminal-compatible formatting.\n    \"\"\"\n\n    @staticmethod\n    def format_markdown(text: str) -&gt; str:\n        \"\"\"Convert markdown to terminal formatting.\"\"\"\n        # Converte **bold**, *italic*, `code`, etc.\n</code></pre>"},{"location":"dev-guide/cli-architecture/#7-colorscheme","title":"7. ColorScheme","text":"<p>Responsabilidade: Define esquema de cores do terminal.</p> <p>Localiza\u00e7\u00e3o: <code>src/createagents/presentation/cli/ui/color_scheme.py</code></p> <pre><code>class ColorScheme:\n    \"\"\"Defines color scheme for terminal output.\"\"\"\n\n    PRIMARY = \"\\033[36m\"      # Cyan\n    SUCCESS = \"\\033[32m\"      # Green\n    WARNING = \"\\033[33m\"      # Yellow\n    ERROR = \"\\033[31m\"        # Red\n    INFO = \"\\033[34m\"         # Blue\n    COMMAND = \"\\033[35m\"      # Magenta\n    RESET = \"\\033[0m\"\n</code></pre>"},{"location":"dev-guide/cli-architecture/#fluxo-de-execucao","title":"\ud83d\udd04 Fluxo de Execu\u00e7\u00e3o","text":""},{"location":"dev-guide/cli-architecture/#1-inicializacao","title":"1. Inicializa\u00e7\u00e3o","text":"<pre><code>main()\n  \u2192 ChatCLIApplication(agent)\n      \u2192 __init__\n          \u2192 TerminalRenderer()\n          \u2192 InputReader()\n          \u2192 CommandRegistry()\n          \u2192 _setup_commands()\n              \u2192 registry.register(HelpCommandHandler)\n              \u2192 registry.register(MetricsCommandHandler)\n              \u2192 ... (outros comandos)\n              \u2192 registry.register(ChatCommandHandler) \u2190 \u00daLTIMO\n</code></pre>"},{"location":"dev-guide/cli-architecture/#2-loop-principal","title":"2. Loop Principal","text":"<pre><code>app.run()\n  \u2192 renderer.render_welcome_screen()\n  \u2192 while True:\n      \u2192 renderer.render_prompt()\n      \u2192 user_input = input_reader.read_user_input()\n      \u2192 if _is_exit_command(user_input): break\n      \u2192 handler = registry.find_handler(user_input)\n      \u2192 handler.execute(agent, user_input)\n</code></pre>"},{"location":"dev-guide/cli-architecture/#3-processamento-de-comando","title":"3. Processamento de Comando","text":"<pre><code># Exemplo: /metrics\nregistry.find_handler(\"/metrics\")\n  \u2192 itera handlers registrados\n  \u2192 MetricsCommandHandler.can_handle(\"/metrics\") \u2192 True\n  \u2192 retorna MetricsCommandHandler\n\nMetricsCommandHandler.execute(agent, \"/metrics\")\n  \u2192 metrics = agent.get_metrics()\n  \u2192 renderer.render_metrics(metrics)\n</code></pre>"},{"location":"dev-guide/cli-architecture/#4-processamento-de-chat-streaming","title":"4. Processamento de Chat (Streaming)","text":"<pre><code>ChatCommandHandler.execute(agent, \"Ol\u00e1\")\n  \u2192 asyncio.run(_async_execute(agent, \"Ol\u00e1\"))\n      \u2192 renderer.render_thinking_indicator()\n      \u2192 response = await agent.chat(\"Ol\u00e1\")\n      \u2192 async for token in response:\n          \u2192 renderer.render_assistant_token(token)\n      \u2192 renderer.clear_thinking_indicator()\n</code></pre>"},{"location":"dev-guide/cli-architecture/#principios-arquiteturais","title":"\ud83c\udfa8 Princ\u00edpios Arquiteturais","text":""},{"location":"dev-guide/cli-architecture/#single-responsibility-srp","title":"Single Responsibility (SRP)","text":"<p>Cada classe tem uma responsabilidade \u00fanica:</p> <ul> <li><code>ChatCLIApplication</code>: Orquestra\u00e7\u00e3o</li> <li><code>CommandRegistry</code>: Registro e resolu\u00e7\u00e3o</li> <li><code>TerminalRenderer</code>: Renderiza\u00e7\u00e3o</li> <li><code>CommandHandler</code>: Processamento de comando espec\u00edfico</li> </ul>"},{"location":"dev-guide/cli-architecture/#openclosed-ocp","title":"Open/Closed (OCP)","text":"<p>Aberto para extens\u00e3o via novos handlers:</p> <pre><code># Adicionar novo comando sem modificar c\u00f3digo existente\nclass CustomCommandHandler(CommandHandler):\n    def can_handle(self, user_input: str) -&gt; bool:\n        return user_input.startswith('/custom')\n\n    def execute(self, agent, user_input):\n        # Implementa\u00e7\u00e3o customizada\n        pass\n\n    def get_aliases(self):\n        return ['/custom']\n\n# Registrar\nregistry.register(CustomCommandHandler(renderer))\n</code></pre>"},{"location":"dev-guide/cli-architecture/#dependency-inversion-dip","title":"Dependency Inversion (DIP)","text":"<p>Handlers dependem de abstra\u00e7\u00f5es (<code>CommandHandler</code>), n\u00e3o implementa\u00e7\u00f5es concretas.</p>"},{"location":"dev-guide/cli-architecture/#command-pattern","title":"Command Pattern","text":"<p>Cada handler encapsula uma a\u00e7\u00e3o como objeto, permitindo:</p> <ul> <li>Parametriza\u00e7\u00e3o de clientes com diferentes solicita\u00e7\u00f5es</li> <li>Enfileiramento de solicita\u00e7\u00f5es</li> <li>Suporte a opera\u00e7\u00f5es revers\u00edveis</li> </ul>"},{"location":"dev-guide/cli-architecture/#adicionando-novos-comandos","title":"\ud83d\udee0\ufe0f Adicionando Novos Comandos","text":""},{"location":"dev-guide/cli-architecture/#passo-1-criar-handler","title":"Passo 1: Criar Handler","text":"<pre><code># src/createagents/presentation/cli/commands/my_command.py\nfrom .base_command import CommandHandler\n\nclass MyCommandHandler(CommandHandler):\n    def can_handle(self, user_input: str) -&gt; bool:\n        return self._normalize_input(user_input) in self.get_aliases()\n\n    def execute(self, agent: 'CreateAgent', user_input: str) -&gt; None:\n        # Sua l\u00f3gica aqui\n        result = self._my_logic(agent)\n        self._renderer.render_system_message(result)\n\n    def get_aliases(self) -&gt; List[str]:\n        return ['/mycommand', 'mycommand']\n\n    def _my_logic(self, agent):\n        # Implementa\u00e7\u00e3o\n        return \"Resultado do comando\"\n</code></pre>"},{"location":"dev-guide/cli-architecture/#passo-2-registrar-handler","title":"Passo 2: Registrar Handler","text":"<pre><code># src/createagents/presentation/cli/application/chat_cli_app.py\ndef _setup_commands(self) -&gt; None:\n    # ...outros comandos...\n    self._registry.register(MyCommandHandler(self._renderer))\n    # ChatCommandHandler deve ser sempre \u00faltimo\n    self._registry.register(ChatCommandHandler(self._renderer))\n</code></pre>"},{"location":"dev-guide/cli-architecture/#passo-3-exportar-opcional","title":"Passo 3: Exportar (Opcional)","text":"<pre><code># src/createagents/presentation/cli/commands/__init__.py\nfrom .my_command import MyCommandHandler\n\n__all__ = [\n    # ...outros...\n    'MyCommandHandler',\n]\n</code></pre>"},{"location":"dev-guide/cli-architecture/#testabilidade","title":"\ud83d\udcca Testabilidade","text":"<p>A arquitetura permite f\u00e1cil testabilidade:</p> <pre><code>import pytest\nfrom unittest.mock import Mock\n\ndef test_help_command_handler():\n    # Mock renderer\n    mock_renderer = Mock()\n    handler = HelpCommandHandler(mock_renderer)\n\n    # Mock agent\n    mock_agent = Mock()\n\n    # Test can_handle\n    assert handler.can_handle(\"/help\") == True\n    assert handler.can_handle(\"other\") == False\n\n    # Test execute\n    handler.execute(mock_agent, \"/help\")\n    mock_renderer.render_system_message.assert_called_once()\n</code></pre>"},{"location":"dev-guide/cli-architecture/#best-practices","title":"\ud83d\udca1 Best Practices","text":"<ol> <li>Handler Registration Order: Espec\u00edfico \u2192 Gen\u00e9rico</li> <li>ChatCommandHandler Last: Sempre registre como \u00faltimo (fallback)</li> <li>Use Renderer: Nunca fa\u00e7a <code>print()</code> diretamente, use <code>self._renderer</code></li> <li>Normalize Input: Use <code>_normalize_input()</code> para compara\u00e7\u00f5es</li> <li>Async Awareness: Chat \u00e9 ass\u00edncrono, use <code>asyncio.run()</code> se necess\u00e1rio</li> </ol>"},{"location":"dev-guide/cli-architecture/#proximos-passos","title":"\ud83d\udcda Pr\u00f3ximos Passos","text":"<ul> <li>Guia Async</li> <li>API Reference - Commands</li> <li>Contribuindo</li> </ul> <p>Vers\u00e3o: 0.1.3 | Atualiza\u00e7\u00e3o: 01/12/2025</p>"},{"location":"dev-guide/contribute/","title":"Como Contribuir","text":"<p>Contribua para o desenvolvimento do Create Agents AI seguindo as diretrizes abaixo. Toda colabora\u00e7\u00e3o \u00e9 bem-vinda!</p>"},{"location":"dev-guide/contribute/#requisitos-para-contribuicao","title":"\ud83d\udea6 Requisitos para Contribui\u00e7\u00e3o","text":"<ul> <li>Python 3.12+ e Poetry instalados</li> <li>Conhecimento b\u00e1sico de Clean Architecture e SOLID</li> <li>Familiaridade com Git e GitHub</li> <li>Seguir o padr\u00e3o de c\u00f3digo, testes e documenta\u00e7\u00e3o do projeto</li> </ul>"},{"location":"dev-guide/contribute/#passo-a-passo-para-contribuir","title":"\ud83d\udee0\ufe0f Passo a Passo para Contribuir","text":"<ol> <li>Fork o reposit\u00f3rio no GitHub</li> <li>Clone seu fork localmente: <pre><code>git clone https://github.com/seu-usuario/Create-Agents-AI.git\ncd Create-Agents-AI\n</code></pre></li> <li>Crie uma branch descritiva: <pre><code>git checkout -b feature/nome-da-sua-feature\n</code></pre></li> <li>Implemente sua melhoria ou corre\u00e7\u00e3o seguindo os padr\u00f5es do projeto</li> <li>Adicione ou atualize testes (unit\u00e1rios, integra\u00e7\u00e3o, etc.)</li> <li>Garanta que todos os checks passem: <pre><code>poetry run pre-commit run --all-files\npoetry run pytest --cov=src\n</code></pre></li> <li>Atualize a documenta\u00e7\u00e3o se necess\u00e1rio (ex: novos par\u00e2metros, exemplos, etc.)</li> <li>Fa\u00e7a commit seguindo o padr\u00e3o Conventional Commits (ex: <code>feat:</code>, <code>fix:</code>, <code>docs:</code>)</li> <li>Envie seu Pull Request (PR) para o branch <code>develop</code> com uma descri\u00e7\u00e3o clara</li> <li>Aguarde revis\u00e3o e responda a eventuais coment\u00e1rios dos mantenedores</li> </ol>"},{"location":"dev-guide/contribute/#checklist-de-qualidade-para-pr","title":"\u2705 Checklist de Qualidade para PR","text":"<ul> <li> C\u00f3digo segue Clean Architecture e SOLID</li> <li> Testes automatizados cobrindo a nova funcionalidade/corre\u00e7\u00e3o</li> <li> Documenta\u00e7\u00e3o atualizada (c\u00f3digo e Markdown)</li> <li> Sem warnings/lints (Black, Ruff, isort, yamllint, mdformat)</li> <li> Commits claros e at\u00f4micos</li> <li> PR descreve claramente o que foi feito e por qu\u00ea</li> </ul>"},{"location":"dev-guide/contribute/#padrao-de-commits","title":"\ud83d\udcdd Padr\u00e3o de Commits","text":"<p>Utilize o padr\u00e3o Conventional Commits:</p> <ul> <li><code>feat:</code> Nova funcionalidade</li> <li><code>fix:</code> Corre\u00e7\u00e3o de bug</li> <li><code>docs:</code> Mudan\u00e7a apenas na documenta\u00e7\u00e3o</li> <li><code>test:</code> Adi\u00e7\u00e3o/melhoria de testes</li> <li><code>refactor:</code> Refatora\u00e7\u00e3o sem alterar comportamento</li> <li><code>chore:</code> Tarefas de manuten\u00e7\u00e3o</li> </ul> <p>Exemplo:</p> <pre><code>git commit -m \"feat: adicionar suporte ao provedor XYZ\"\n</code></pre>"},{"location":"dev-guide/contribute/#exemplos-de-contribuicao","title":"\ud83d\udcda Exemplos de Contribui\u00e7\u00e3o","text":"<ul> <li>Adicionar nova ferramenta (Tool) customizada</li> <li>Corrigir bug em adapter de provedor</li> <li>Melhorar cobertura de testes</li> <li>Atualizar exemplos na documenta\u00e7\u00e3o</li> <li>Sugerir melhorias de performance ou seguran\u00e7a</li> </ul>"},{"location":"dev-guide/contribute/#reportar-bugs-e-sugerir-melhorias","title":"\ud83d\udc1e Reportar Bugs e Sugerir Melhorias","text":"<ol> <li>Abra uma issue</li> <li>Descreva o problema/sugest\u00e3o com detalhes, passos para reproduzir e contexto</li> <li>Inclua logs, prints ou exemplos de c\u00f3digo se poss\u00edvel</li> </ol>"},{"location":"dev-guide/contribute/#dicas-para-documentacao","title":"\ud83d\udcd6 Dicas para Documenta\u00e7\u00e3o","text":"<ul> <li>Sempre documente novas fun\u00e7\u00f5es, classes e par\u00e2metros com docstrings</li> <li>Atualize os arquivos Markdown relevantes em <code>docs/</code> (ex: exemplos, API, FAQ)</li> <li>Use portugu\u00eas claro, t\u00e9cnico e acess\u00edvel</li> <li>Inclua exemplos de uso sempre que poss\u00edvel</li> </ul>"},{"location":"dev-guide/contribute/#contato-e-suporte","title":"\ud83e\udd1d Contato e Suporte","text":"<ul> <li>Email: estraliotojordan@gmail.com</li> <li>GitHub: @jor0105</li> <li>Discuss\u00f5es: GitHub Discussions</li> </ul> <p>Obrigado por contribuir! Seu apoio torna o projeto melhor para toda a comunidade.</p>"},{"location":"dev-guide/logging_guide/","title":"\ud83d\udcdd Guia de Logging","text":"<p>Este guia explica como configurar e utilizar o sistema de logging da biblioteca <code>CreateAgentsAI</code>, que agora segue Clean Architecture com interfaces de logging no dom\u00ednio e implementa\u00e7\u00f5es na infraestrutura.</p>"},{"location":"dev-guide/logging_guide/#arquitetura-de-logging","title":"\ud83c\udfd7\ufe0f Arquitetura de Logging","text":""},{"location":"dev-guide/logging_guide/#loggerinterface-dominio","title":"LoggerInterface (Dom\u00ednio)","text":"<p>A biblioteca define uma <code>LoggerInterface</code> abstrata no dom\u00ednio (<code>src/createagents/domain/interfaces/</code>), permitindo que as camadas de dom\u00ednio e aplica\u00e7\u00e3o usem logging sem depender de implementa\u00e7\u00f5es concretas de infraestrutura.</p> <pre><code>from abc import ABC, abstractmethod\n\nclass LoggerInterface(ABC):\n    \"\"\"Interface abstrata para logging.\"\"\"\n\n    @abstractmethod\n    def debug(self, message: str, *args, **kwargs) -&gt; None:\n        pass\n\n    @abstractmethod\n    def info(self, message: str, *args, **kwargs) -&gt; None:\n        pass\n\n    @abstractmethod\n    def warning(self, message: str, *args, **kwargs) -&gt; None:\n        pass\n\n    @abstractmethod\n    def error(self, message: str, *args, **kwargs) -&gt; None:\n        pass\n\n    @abstractmethod\n    def critical(self, message: str, *args, **kwargs) -&gt; None:\n        pass\n</code></pre>"},{"location":"dev-guide/logging_guide/#standardlogger-infraestrutura","title":"StandardLogger (Infraestrutura)","text":"<p>A implementa\u00e7\u00e3o concreta est\u00e1 na camada de infraestrutura (<code>src/createagents/infra/config/</code>):</p> <pre><code>class StandardLogger(LoggerInterface):\n    \"\"\"Implementa\u00e7\u00e3o padr\u00e3o do LoggerInterface usando Python logging.\"\"\"\n\n    def __init__(self, logger: logging.Logger):\n        self._logger = logger\n\n    def debug(self, message: str, *args, **kwargs) -&gt; None:\n        self._logger.debug(message, *args, **kwargs)\n\n    # ...outros m\u00e9todos\n</code></pre>"},{"location":"dev-guide/logging_guide/#comportamento-padrao","title":"\ud83d\udd07 Comportamento Padr\u00e3o","text":"<p>Ao importar e usar a biblioteca, nenhum log ser\u00e1 exibido no console ou salvo em arquivo, a menos que voc\u00ea configure explicitamente o sistema de logging.</p> <p>Isso \u00e9 feito intencionalmente para evitar conflitos com a configura\u00e7\u00e3o de logging da aplica\u00e7\u00e3o que consome a biblioteca.</p>"},{"location":"dev-guide/logging_guide/#como-ativar-logs","title":"\ud83d\udee0\ufe0f Como Ativar Logs","text":""},{"location":"dev-guide/logging_guide/#opcao-1-configuracao-rapida-desenvolvimento","title":"Op\u00e7\u00e3o 1: Configura\u00e7\u00e3o R\u00e1pida (Desenvolvimento)","text":"<p>Para desenvolvimento, testes ou scripts simples, use o helper <code>configure_for_development</code>:</p> <pre><code>import logging\nfrom createagents import LoggingConfig\n\n# Ativa logs no n\u00edvel INFO\nLoggingConfig.configure_for_development(level=logging.INFO)\n\n# Ou para ver tudo (DEBUG)\nLoggingConfig.configure_for_development(level=logging.DEBUG)\n</code></pre> <p>Isso configurar\u00e1 logs coloridos no console e filtragem autom\u00e1tica de dados sens\u00edveis.</p>"},{"location":"dev-guide/logging_guide/#opcao-2-configuracao-padrao-do-python","title":"Op\u00e7\u00e3o 2: Configura\u00e7\u00e3o Padr\u00e3o do Python","text":"<p>Se sua aplica\u00e7\u00e3o j\u00e1 configura o logging, a biblioteca respeitar\u00e1 essa configura\u00e7\u00e3o:</p> <pre><code>import logging\n\n# Configura\u00e7\u00e3o da sua aplica\u00e7\u00e3o\nlogging.basicConfig(level=logging.INFO)\n\n# Agora os logs da biblioteca aparecer\u00e3o\nfrom createagents import CreateAgent\n</code></pre>"},{"location":"dev-guide/logging_guide/#opcao-3-configuracao-avancada","title":"Op\u00e7\u00e3o 3: Configura\u00e7\u00e3o Avan\u00e7ada","text":"<p>Para controlar apenas os logs da biblioteca:</p> <pre><code>import logging\n\n# Configura apenas o logger 'createagents'\nlogger = logging.getLogger(\"createagents\")\nlogger.setLevel(logging.DEBUG)\nlogger.addHandler(logging.StreamHandler())\n</code></pre>"},{"location":"dev-guide/logging_guide/#uso-em-componentes-customizados","title":"\ud83c\udfaf Uso em Componentes Customizados","text":"<p>Se voc\u00ea estiver estendendo a biblioteca (ex.: criando ferramentas customizadas ou handlers), pode usar a <code>LoggerInterface</code>:</p>"},{"location":"dev-guide/logging_guide/#exemplo-ferramenta-customizada-com-logging","title":"Exemplo: Ferramenta Customizada com Logging","text":"<pre><code>from createagents import BaseTool\nfrom createagents.domain.interfaces import LoggerInterface\n\nclass MyCustomTool(BaseTool):\n    name = \"my_tool\"\n    description = \"Minha ferramenta customizada\"\n    parameters = {...}\n\n    def __init__(self, logger: LoggerInterface):\n        self._logger = logger\n\n    def execute(self, **kwargs) -&gt; str:\n        self._logger.info(\"Executando MyCustomTool com: %s\", kwargs)\n        try:\n            result = self._do_something(kwargs)\n            self._logger.debug(\"Resultado: %s\", result)\n            return result\n        except Exception as e:\n            self._logger.error(\"Erro em MyCustomTool: %s\", str(e))\n            raise\n</code></pre>"},{"location":"dev-guide/logging_guide/#injecao-de-dependencia","title":"Inje\u00e7\u00e3o de Depend\u00eancia","text":"<pre><code>from createagents.infra.config import LoggingConfig, StandardLogger\n\n# Criar logger\npython_logger = LoggingConfig.get_logger(__name__)\nlogger_interface = StandardLogger(python_logger)\n\n# Injetar na ferramenta\nmy_tool = MyCustomTool(logger=logger_interface)\n</code></pre>"},{"location":"dev-guide/logging_guide/#seguranca-e-privacidade","title":"\ud83d\udd12 Seguran\u00e7a e Privacidade","text":"<p>A biblioteca inclui recursos autom\u00e1ticos de seguran\u00e7a nos logs:</p> <ul> <li>Sanitiza\u00e7\u00e3o: Chaves de API, senhas e tokens s\u00e3o mascarados automaticamente (ex: <code>[API_KEY_REDACTED]</code>).</li> <li>Filtros: Em produ\u00e7\u00e3o, voc\u00ea pode configurar para logar apenas erros.</li> </ul>"},{"location":"dev-guide/logging_guide/#variaveis-de-ambiente","title":"\u2699\ufe0f Vari\u00e1veis de Ambiente","text":"<p>Voc\u00ea pode controlar o logging atrav\u00e9s de vari\u00e1veis de ambiente:</p> Vari\u00e1vel Descri\u00e7\u00e3o Padr\u00e3o <code>LOG_LEVEL</code> N\u00edvel de log (DEBUG, INFO, WARNING, ERROR) INFO <code>LOG_TO_FILE</code> Salvar logs em arquivo (true/false) false <code>LOG_FILE_PATH</code> Caminho do arquivo de log logs/app.log <code>LOG_JSON_FORMAT</code> Usar formato JSON estruturado false"},{"location":"dev-guide/logging_guide/#logs-em-json-producao","title":"\ud83d\udcca Logs em JSON (Produ\u00e7\u00e3o)","text":"<p>Para ambientes de produ\u00e7\u00e3o com agrega\u00e7\u00e3o de logs (Datadog, CloudWatch, ELK), ative o formato JSON:</p> <pre><code>LoggingConfig.configure(json_format=True)\n</code></pre> <p>Ou via ambiente:</p> <pre><code>export LOG_JSON_FORMAT=true\n</code></pre> <p>Isso gerar\u00e1 logs estruturados f\u00e1ceis de indexar:</p> <pre><code>{\n  \"timestamp\": \"2024-03-20 10:00:00,000\",\n  \"level\": \"INFO\",\n  \"logger\": \"createagents.service\",\n  \"message\": \"Agent initialized\",\n  \"module\": \"service\",\n  \"line\": 42\n}\n</code></pre>"},{"location":"dev-guide/logging_guide/#componentes-que-usam-logging","title":"\ud83d\udd0d Componentes que Usam Logging","text":""},{"location":"dev-guide/logging_guide/#agentservice","title":"AgentService","text":"<p>O <code>AgentService</code> usa <code>LoggerInterface</code> para logar opera\u00e7\u00f5es de agente:</p> <pre><code>class AgentService:\n    def __init__(self, agent: Agent, logger: LoggerInterface):\n        self._agent = agent\n        self._logger = logger\n        self._logger.info(\n            \"AgentService initialized - Name: %s, Provider: %s\",\n            agent.name,\n            agent.provider\n        )\n</code></pre>"},{"location":"dev-guide/logging_guide/#toolexecutor","title":"ToolExecutor","text":"<p>O <code>ToolExecutor</code> no dom\u00ednio usa <code>LoggerInterface</code> para logar execu\u00e7\u00f5es de ferramentas:</p> <pre><code>class ToolExecutor:\n    def __init__(self, logger: LoggerInterface):\n        self._logger = logger\n\n    async def execute(self, tool: BaseTool, arguments: dict):\n        self._logger.info(\"Executing tool: %s\", tool.name)\n        # ...\n</code></pre>"},{"location":"dev-guide/logging_guide/#handlers-openaiollama","title":"Handlers (OpenAI/Ollama)","text":"<p>Os handlers de streaming usam logging para m\u00e9tricas e debugging:</p> <pre><code>class OpenAIStreamHandler:\n    def __init__(self, ...):\n        self._logger = LoggingConfig.get_logger(__name__)\n\n    async def handle_streaming(self, ...):\n        self._logger.debug(\"Starting streaming response\")\n        # ...\n</code></pre>"},{"location":"dev-guide/logging_guide/#best-practices","title":"\ud83d\udca1 Best Practices","text":"<ol> <li>Use n\u00edveis apropriados:</li> </ol> <ul> <li><code>DEBUG</code>: Detalhes de execu\u00e7\u00e3o, valores de vari\u00e1veis</li> <li><code>INFO</code>: Eventos normais (agent criado, ferramenta executada)</li> <li><code>WARNING</code>: Situa\u00e7\u00f5es incomuns mas recuper\u00e1veis</li> <li><code>ERROR</code>: Erros que impedem opera\u00e7\u00e3o</li> <li><code>CRITICAL</code>: Falhas graves do sistema</li> </ul> <ol> <li>Nunca logue dados sens\u00edveis:</li> </ol> <ul> <li>A biblioteca sanitiza automaticamente, mas evite logar explicitamente senhas, tokens, etc.</li> </ul> <ol> <li>Use formata\u00e7\u00e3o lazy:</li> </ol> <pre><code># BOM - formata\u00e7\u00e3o lazy (n\u00e3o executa se log desabilitado)\nlogger.debug(\"Processing %s items\", len(items))\n\n# RUIM - formata\u00e7\u00e3o eager\nlogger.debug(f\"Processing {len(items)} items\")\n</code></pre> <ol> <li>Contextualize com extra: <pre><code>logger.info(\n    \"Tool executed successfully\",\n    extra={\"tool_name\": tool.name, \"duration_ms\": duration}\n)\n</code></pre></li> </ol> <p>Vers\u00e3o: 0.1.3 | Atualiza\u00e7\u00e3o: 01/12/2025</p>"},{"location":"dev-guide/technical-examples/","title":"Exemplos T\u00e9cnicos para Desenvolvedores","text":"<p>Veja exemplos avan\u00e7ados de uso, extens\u00e3o e integra\u00e7\u00e3o do Create Agents AI.</p>"},{"location":"dev-guide/technical-examples/#criar-ferramenta-customizada","title":"Criar Ferramenta Customizada","text":"<pre><code>from createagents import BaseTool\nclass MyTool(BaseTool):\n    name = \"my_tool\"\n    description = \"Minha ferramenta personalizada\"\n    parameters = {\n        \"type\": \"object\",\n        \"properties\": {\n            \"input\": {\n                \"type\": \"string\",\n                \"description\": \"Texto de entrada\"\n            }\n        },\n        \"required\": [\"input\"]\n    }\n    def execute(self, input: str) -&gt; str:\n        return f\"Resultado: {input}\"\n</code></pre>"},{"location":"dev-guide/technical-examples/#novo-adapter-de-provedor","title":"Novo Adapter de Provedor","text":"<pre><code>from createagents.application.interfaces import ChatRepository\nclass ClaudeAdapter(ChatRepository):\n    def chat(self, ...):\n        # Implementa\u00e7\u00e3o para Claude\n        pass\n</code></pre>"},{"location":"dev-guide/technical-examples/#testes-unitarios","title":"Testes Unit\u00e1rios","text":"<pre><code>import pytest\nfrom unittest import TestCase\nfrom unittest.mock import patch\nfrom createagents import CreateAgent\n\n@pytest.mark.unitest\nclass TestAgentChat(TestCase):\n    @patch(\"createagents.application.facade.client.OpenAIChatAdapter\")\n    def test_chat(self, mock_adapter):\n        # Configura o mock para simular resposta da API\n        mock_adapter.return_value.chat.return_value = \"Ol\u00e1, mundo!\"\n        agent = CreateAgent(provider=\"openai\", model=\"gpt-4\")\n        response = agent.chat(\"Teste\")\n        self.assertEqual(response, \"Ol\u00e1, mundo!\")\n</code></pre>"},{"location":"dev-guide/technical-examples/#integracao-com-cicd","title":"Integra\u00e7\u00e3o com CI/CD","text":"<ul> <li>Use <code>pytest</code> e <code>pytest-cov</code> para cobertura.</li> </ul>"},{"location":"dev-guide/technical-examples/#extensao-de-metricas","title":"Extens\u00e3o de M\u00e9tricas","text":"<pre><code>metrics = agent.get_metrics()\nagent.export_metrics_json(\"metrics.json\")\n</code></pre>"},{"location":"dev-guide/technical-examples/#contribuindo","title":"Contribuindo","text":"<p>Veja Como Contribuir.</p>"},{"location":"reference/api/","title":"\ud83d\udcda API Reference","text":"<p>Documenta\u00e7\u00e3o completa da API p\u00fablica do Create Agents AI.</p>"},{"location":"reference/api/#createagent","title":"\ud83e\udd16 CreateAgent","text":"<p>O controller principal para intera\u00e7\u00e3o com agentes de IA.</p>"},{"location":"reference/api/#construtor","title":"Construtor","text":"<pre><code>CreateAgent(\n    provider: str,\n    model: str,\n    name: Optional[str] = None,\n    instructions: Optional[str] = None,\n    config: Optional[Dict[str, Any]] = None,\n    tools: Optional[Sequence[Union[str, BaseTool]]] = None,\n    history_max_size: int = 10\n)\n</code></pre> <p>Par\u00e2metros:</p> Par\u00e2metro Tipo Descri\u00e7\u00e3o Obrigat\u00f3rio <code>provider</code> <code>str</code> Provider de IA: <code>\"openai\"</code> ou <code>\"ollama\"</code> \u2705 Sim <code>model</code> <code>str</code> Nome do modelo (ex: <code>\"gpt-4.1-mini\"</code>, <code>\"llama2\"</code>) \u2705 Sim <code>name</code> <code>str</code> Nome do agente \u274c N\u00e3o <code>instructions</code> <code>str</code> Instru\u00e7\u00f5es/personalidade do agente \u274c N\u00e3o <code>config</code> <code>dict</code> Configura\u00e7\u00f5es do modelo (temperature, max_tokens, etc) \u274c N\u00e3o <code>tools</code> <code>list</code> Lista de ferramentas: <code>[\"currentdate\", \"readlocalfile\"]</code> \u274c N\u00e3o <code>history_max_size</code> <code>int</code> Tamanho m\u00e1ximo do hist\u00f3rico (padr\u00e3o: 10) \u274c N\u00e3o <p>Exemplo:</p> <pre><code>from createagents import CreateAgent\n\nagent = CreateAgent(\n    provider=\"openai\",\n    model=\"gpt-4.1-mini\",\n    instructions=\"Voc\u00ea \u00e9 um assistente t\u00e9cnico\",\n    config={\"temperature\": 0.7, \"max_tokens\": 2000},\n    tools=[\"currentdate\"],\n    history_max_size=20\n)\n</code></pre>"},{"location":"reference/api/#metodos","title":"M\u00e9todos","text":""},{"location":"reference/api/#chat","title":"chat()","text":"<p>Envia mensagem ao agente e retorna resposta.</p> <pre><code>async def chat(message: str) -&gt; Union[str, StreamingResponseDTO]\n</code></pre> <p>Par\u00e2metros:</p> <ul> <li><code>message</code> (str): Mensagem do usu\u00e1rio</li> </ul> <p>Retorna: <code>Union[str, StreamingResponseDTO]</code> - Resposta do agente</p> <p>Exemplo:</p> <pre><code>import asyncio\n\nasync def main():\n    resposta = await agent.chat(\"Como criar uma fun\u00e7\u00e3o em Python?\")\n    print(resposta)\n\nasyncio.run(main())\n</code></pre>"},{"location":"reference/api/#get_configs","title":"get_configs()","text":"<p>Retorna configura\u00e7\u00f5es e hist\u00f3rico do agente.</p> <pre><code>def get_configs() -&gt; Dict[str, Any]\n</code></pre> <p>Retorna: <code>dict</code> com:</p> <ul> <li><code>name</code>: Nome do agente</li> <li><code>model</code>: Modelo usado</li> <li><code>provider</code>: Provider (openai/ollama)</li> <li><code>instructions</code>: Instru\u00e7\u00f5es</li> <li><code>history</code>: Lista de mensagens</li> <li><code>tools</code>: Ferramentas dispon\u00edveis</li> <li><code>config</code>: Configura\u00e7\u00f5es do modelo</li> </ul> <p>Exemplo:</p> <pre><code>config = agent.get_configs()\nprint(f\"Modelo: {config['model']}\")\nprint(f\"Hist\u00f3rico: {len(config['history'])} mensagens\")\n</code></pre>"},{"location":"reference/api/#clear_history","title":"clear_history()","text":"<p>Limpa o hist\u00f3rico de mensagens.</p> <pre><code>def clear_history() -&gt; None\n</code></pre> <p>Exemplo:</p> <pre><code>agent.clear_history()\nprint(\"Hist\u00f3rico limpo!\")\n</code></pre>"},{"location":"reference/api/#get_all_available_tools","title":"get_all_available_tools()","text":"<p>Retorna todas as ferramentas dispon\u00edveis para este agente espec\u00edfico (ferramentas do sistema + ferramentas customizadas).</p> <pre><code>def get_all_available_tools() -&gt; Dict[str, str]\n</code></pre> <p>Retorna: <code>dict</code> mapeando nome da ferramenta para descri\u00e7\u00e3o</p> <p>Comportamento:</p> <ul> <li>Inclui todas as ferramentas do sistema (built-in) dispon\u00edveis</li> <li>Inclui ferramentas customizadas adicionadas quando o agente foi criado</li> <li>Remove duplicatas automaticamente (se uma ferramenta do sistema foi explicitamente adicionada)</li> </ul> <p>Exemplo:</p> <pre><code>from createagents import BaseTool\n\n# Ferramenta customizada\nclass MyTool(BaseTool):\n    name = \"my_tool\"\n    description = \"Minha ferramenta personalizada\"\n\n    parameters = {\n        \"type\": \"object\",\n        \"properties\": {\n            \"input\": {\n                \"type\": \"string\",\n                \"description\": \"Texto de entrada para a ferramenta\"\n            },\n            \"limit\": {\n                \"type\": \"integer\",\n                \"description\": \"(Opcional) Limite de itens a retornar\"\n            }\n        },\n        \"required\": [\"input\"]\n    }\n\n    def execute(self, **kwargs) -&gt; str:\n        # Implementa\u00e7\u00e3o da ferramenta (exemplo)\n        input_val = kwargs.get(\"input\", \"\")\n        limit = kwargs.get(\"limit\", None)\n        return f\"Resultado para: {input_val}\" + (f\" (limit={limit})\" if limit is not None else \"\")\n\n# Criar agente com ferramentas\nagent = CreateAgent(\n    provider=\"openai\",\n    model=\"gpt-4\",\n    tools=[\"currentdate\", MyTool()]\n)\n\n# Listar todas as ferramentas\ntools = agent.get_all_available_tools()\nfor name, description in tools.items():\n    print(f\"- {name}: {description}\")\n\n# Sa\u00edda:\n# - currentdate: Get the current date and/or time...\n# - readlocalfile: Use this tool to read local files...\n# - my_tool: Minha ferramenta personalizada\n</code></pre>"},{"location":"reference/api/#get_system_available_tools","title":"get_system_available_tools()","text":"<p>Retorna apenas as ferramentas do sistema (built-in) dispon\u00edveis globalmente.</p> <pre><code>def get_system_available_tools() -&gt; Dict[str, str]\n</code></pre> <p>Retorna: <code>dict</code> mapeando nome da ferramenta do sistema para descri\u00e7\u00e3o</p> <p>Comportamento:</p> <ul> <li>Retorna apenas ferramentas built-in do framework</li> <li>N\u00e3o inclui ferramentas customizadas do agente</li> <li>\u00datil para verificar quais ferramentas opcionais est\u00e3o instaladas</li> </ul> <p>Exemplo:</p> <pre><code>agent = CreateAgent(provider=\"openai\", model=\"gpt-4\")\n\n# Listar apenas ferramentas do sistema\nsystem_tools = agent.get_system_available_tools()\n\nprint(\"Ferramentas do sistema dispon\u00edveis:\")\nfor name, description in system_tools.items():\n    print(f\"- {name}: {description[:50]}...\")\n\n# Verificar se ferramenta opcional est\u00e1 dispon\u00edvel\nif \"readlocalfile\" in system_tools:\n    print(\"\u2705 ReadLocalFileTool est\u00e1 instalada\")\nelse:\n    print(\"\u274c Execute: pip install createagents[file-tools]\")\n\n# Sa\u00edda:\n# - currentdate: Get the current date and/or time...\n# - readlocalfile: Use this tool to read local files...\n</code></pre> <p>Diferen\u00e7a entre os m\u00e9todos:</p> M\u00e9todo Inclui Ferramentas do Sistema Inclui Ferramentas Customizadas Quando Usar <code>get_all_available_tools()</code> \u2705 Sim \u2705 Sim Ver todas as ferramentas que o agente pode usar <code>get_system_available_tools()</code> \u2705 Sim \u274c N\u00e3o Verificar quais ferramentas opcionais est\u00e3o instaladas"},{"location":"reference/api/#get_metrics","title":"get_metrics()","text":"<p>Retorna m\u00e9tricas de performance.</p> <pre><code>def get_metrics() -&gt; List[ChatMetrics]\n</code></pre> <p>Retorna: <code>List[ChatMetrics]</code> com:</p> <ul> <li><code>response_time</code> (float): Tempo de resposta em segundos</li> <li><code>tokens_used</code> (int): Tokens consumidos</li> <li><code>status</code> (str): Status da requisi\u00e7\u00e3o</li> <li><code>timestamp</code> (datetime): Momento da execu\u00e7\u00e3o</li> </ul> <p>Exemplo:</p> <pre><code>metrics = agent.get_metrics()\nfor m in metrics:\n    print(f\"Tempo: {m.response_time:.2f}s, Tokens: {m.tokens_used}\")\n</code></pre>"},{"location":"reference/api/#export_metrics_json","title":"export_metrics_json()","text":"<p>Exporta m\u00e9tricas em formato JSON.</p> <pre><code>def export_metrics_json(filepath: Optional[str] = None) -&gt; str\n</code></pre> <p>Par\u00e2metros:</p> <ul> <li><code>filepath</code> (str, opcional): Caminho para salvar</li> </ul> <p>Retorna: JSON string</p> <p>Exemplo:</p> <pre><code># Salvar em arquivo\nagent.export_metrics_json(\"metrics.json\")\n\n# Obter como string\njson_data = agent.export_metrics_json()\n</code></pre>"},{"location":"reference/api/#export_metrics_prometheus","title":"export_metrics_prometheus()","text":"<p>Exporta m\u00e9tricas em formato Prometheus.</p> <pre><code>def export_metrics_prometheus(filepath: Optional[str] = None) -&gt; str\n</code></pre> <p>Par\u00e2metros:</p> <ul> <li><code>filepath</code> (str, opcional): Caminho para salvar</li> </ul> <p>Retorna: String formato Prometheus</p> <p>Exemplo:</p> <pre><code>agent.export_metrics_prometheus(\"metrics.prom\")\n</code></pre>"},{"location":"reference/api/#start_cli","title":"start_cli()","text":"<p>Inicia sess\u00e3o interativa de chat no terminal.</p> <pre><code>def start_cli() -&gt; None\n</code></pre> <p>Descri\u00e7\u00e3o:</p> <p>Lan\u00e7a uma interface CLI completa com:</p> <ul> <li>Interface colorida e formatada</li> <li>Comandos: <code>/help</code>, <code>/metrics</code>, <code>/configs</code>, <code>/tools</code>, <code>/clear</code>, <code>/chat</code></li> <li>Streaming em tempo real</li> <li>Indicadores de status</li> </ul> <p>Exemplo:</p> <pre><code>agent = CreateAgent(provider=\"openai\", model=\"gpt-4\")\nagent.start_cli()  # Inicia CLI interativa\n</code></pre> <p>\ud83d\udcda Guia completo da CLI</p>"},{"location":"reference/api/#ferramentas-tools","title":"\ud83d\udee0\ufe0f Ferramentas (Tools)","text":""},{"location":"reference/api/#ferramentas-disponiveis","title":"Ferramentas Dispon\u00edveis","text":""},{"location":"reference/api/#currentdatetool","title":"CurrentDateTool","text":"<p>Obt\u00e9m data/hora em qualquer timezone.</p> <p>Nome: <code>\"currentdate\"</code></p> <p>Uso:</p> <pre><code>import asyncio\n\nasync def main():\n    agent = CreateAgent(\n        provider=\"openai\",\n        model=\"gpt-4\",\n        tools=[\"currentdate\"]\n    )\n\n    resposta = await agent.chat(\"Que dia \u00e9 hoje?\")\n    print(resposta)\n\nasyncio.run(main())\n</code></pre> <p>A\u00e7\u00f5es:</p> <ul> <li><code>date</code>: Data (YYYY-MM-DD)</li> <li><code>time</code>: Hora (HH:MM:SS)</li> <li><code>datetime</code>: Data e hora</li> <li><code>timestamp</code>: Unix timestamp</li> <li><code>date_with_weekday</code>: Data com dia da semana</li> </ul>"},{"location":"reference/api/#readlocalfiletool","title":"ReadLocalFileTool","text":"<p>L\u00ea arquivos locais em m\u00faltiplos formatos.</p> <p>Nome: <code>\"readlocalfile\"</code></p> <p>Requer: <code>pip install createagents[file-tools]</code></p> <p>Formatos:</p> <ul> <li>Texto: TXT, MD, CSV, JSON, YAML</li> <li>Documentos: PDF</li> <li>Planilhas: Excel (XLS, XLSX), Parquet</li> </ul> <p>Uso:</p> <pre><code>import asyncio\n\nasync def main():\n    agent = CreateAgent(\n        provider=\"openai\",\n        model=\"gpt-4\",\n        tools=[\"readlocalfile\"]\n    )\n\n    resposta = await agent.chat(\"Leia o arquivo report.pdf\")\n    print(resposta)\n\nasyncio.run(main())\n</code></pre> <p>Limites:</p> <ul> <li>Tamanho m\u00e1ximo: 100MB</li> <li>Tokens m\u00e1ximos: Depende da AI utilizada</li> </ul>"},{"location":"reference/api/#configuracoes-do-modelo","title":"\ud83d\udcca Configura\u00e7\u00f5es do Modelo","text":"<p>Par\u00e2metros para controlar o comportamento do modelo (OpenAI/Ollama):</p> <pre><code>config = {\n    \"temperature\": 0.7,   # 0.0\u20132.0: Criatividade\n    \"max_tokens\": 2000,   # &gt;0: Limite de tokens\n    \"top_p\": 0.9,         # 0.0\u20131.0: Nucleus sampling\n    \"think\": True,        # Ollama: bool / OpenAI: str [\"low\", \"medium\" or \"high\"]\n    \"top_k\": 40,          # &gt;0: (Ollama)\n}\n\nagent = CreateAgent(provider=\"openai\", model=\"gpt-4.1-mini\", config=config)\n</code></pre> <p>Par\u00e2metros suportados:</p> Nome Faixa/Tipo Descri\u00e7\u00e3o <code>temperature</code> 0.0\u20132.0 Controla aleatoriedade. 0=determin\u00edstico, 2=mais criativo <code>max_tokens</code> &gt;0 (int) Limite de tokens na resposta <code>top_p</code> 0.0\u20131.0 Nucleus sampling <code>think</code> bool ou str Ollama: bool (ativa/desativa), OpenAI: string de op\u00e7\u00f5es avan\u00e7adas (\u201clow\u201d, \u201cmedium\u201d ou \u201chigh\u201d dispon\u00edveis) <code>top_k</code> &gt;0 (int) N\u00famero de tokens considerados no sampling"},{"location":"reference/api/#exemplos-de-uso","title":"\ud83d\udca1 Exemplos de Uso","text":""},{"location":"reference/api/#exemplo-basico","title":"Exemplo B\u00e1sico","text":"<pre><code>import asyncio\nfrom createagents import CreateAgent\n\nasync def main():\n    agent = CreateAgent(provider=\"openai\", model=\"gpt-4\")\n    resposta = await agent.chat(\"Ol\u00e1!\")\n    print(resposta)\n\nasyncio.run(main())\n</code></pre>"},{"location":"reference/api/#com-ferramentas","title":"Com Ferramentas","text":"<pre><code>import asyncio\n\nasync def main():\n    agent = CreateAgent(\n        provider=\"openai\",\n        model=\"gpt-4\",\n        tools=[\"currentdate\", \"readlocalfile\"]\n    )\n\n    resposta = await agent.chat(\"Que dia \u00e9 hoje?\")\n    print(resposta)\n\nasyncio.run(main())\n</code></pre>"},{"location":"reference/api/#local-ollama","title":"Local (Ollama)","text":"<pre><code>import asyncio\n\nasync def main():\n    agent = CreateAgent(provider=\"ollama\", model=\"llama3.2\")\n    resposta = await agent.chat(\"Explique IA\")\n    print(resposta)\n\nasyncio.run(main())\n</code></pre>"},{"location":"reference/api/#cli-interativa","title":"CLI Interativa","text":"<pre><code>agent = CreateAgent(provider=\"openai\", model=\"gpt-4\")\nagent.start_cli()  # Interface completa no terminal\n</code></pre> <p>Vers\u00e3o: 0.2.0 | Atualiza\u00e7\u00e3o: 02/12/2025</p>"},{"location":"reference/commands/","title":"Refer\u00eancia de Comandos CLI","text":"<p>Refer\u00eancia completa de todos os comandos dispon\u00edveis na CLI interativa do CreateAgents AI.</p>"},{"location":"reference/commands/#visao-geral","title":"\ud83d\udccb Vis\u00e3o Geral","text":"<p>A CLI oferece 7 comandos integrados para controle total do agente:</p> Comando Aliases Descri\u00e7\u00e3o <code>/help</code> <code>/help</code>, <code>help</code> Exibe ajuda e lista de comandos <code>/metrics</code> <code>/metrics</code> Mostra m\u00e9tricas de performance <code>/configs</code> <code>/configs</code> Exibe configura\u00e7\u00f5es do agente <code>/tools</code> <code>/tools</code> Lista ferramentas dispon\u00edveis <code>/clear</code> <code>/clear</code>, <code>clear</code> Limpa hist\u00f3rico de conversa\u00e7\u00e3o Chat (qualquer texto) Envia mensagem ao agente (padr\u00e3o) <code>exit/quit</code> <code>exit</code>, <code>quit</code> Encerra a aplica\u00e7\u00e3o"},{"location":"reference/commands/#comandos-detalhados","title":"\ud83d\udd27 Comandos Detalhados","text":""},{"location":"reference/commands/#help-ajuda","title":"<code>/help</code> - Ajuda","text":"<p>Descri\u00e7\u00e3o: Exibe lista de comandos dispon\u00edveis e suas descri\u00e7\u00f5es.</p> <p>Aliases: <code>/help</code>, <code>help</code></p> <p>Uso:</p> <pre><code>Voc\u00ea: /help\n</code></pre> <p>Sa\u00edda:</p> <pre><code>Available Commands:\n\n\u2022 /metrics  \u2192 Show agent performance metrics and statistics\n\u2022 /configs  \u2192 Display current agent configuration settings\n\u2022 /tools    \u2192 List all available tools and their descriptions\n\u2022 /clear    \u2192 Clear conversation history and start fresh\n\u2022 /help     \u2192 Show this help message\n\nType 'exit' or 'quit' to close the application.\n</code></pre>"},{"location":"reference/commands/#metrics-metricas-de-performance","title":"<code>/metrics</code> - M\u00e9tricas de Performance","text":"<p>Descri\u00e7\u00e3o: Mostra estat\u00edsticas detalhadas de todas as chamadas realizadas.</p> <p>Aliases: <code>/metrics</code>, <code>metrics</code></p> <p>Uso:</p> <pre><code>Voc\u00ea: /metrics\n</code></pre> <p>Sa\u00edda OpenAI:</p> <pre><code>\ud83d\udcca M\u00e9tricas de Performance\n\nChamada #1 | \u2705 Sucesso\n  \u2514\u2500 Modelo: gpt-4\n  \u2514\u2500 Lat\u00eancia: 1,234ms\n  \u2514\u2500 Tokens: 250 (prompt: 100, completion: 150)\n\nChamada #2 | \u2705 Sucesso\n  \u2514\u2500 Modelo: gpt-4\n  \u2514\u2500 Lat\u00eancia: 987ms\n  \u2514\u2500 Tokens: 180 (prompt: 80, completion: 100)\n\n\ud83d\udcc8 Estat\u00edsticas Gerais\n  Total de chamadas: 2\n  Taxa de sucesso: 100%\n  Lat\u00eancia m\u00e9dia: 1,110ms\n  Total de tokens: 430\n</code></pre> <p>Sa\u00edda Ollama (m\u00e9tricas adicionais):</p> <pre><code>\ud83d\udcca M\u00e9tricas de Performance\n\nChamada #1 | \u2705 Sucesso\n  \u2514\u2500 Modelo: llama3.2:latest\n  \u2514\u2500 Lat\u00eancia: 2,345ms\n  \u2514\u2500 Tokens: 150 (prompt: 50, completion: 100)\n  \u2514\u2500 Load duration: 145ms\n  \u2514\u2500 Prompt eval duration: 234ms\n  \u2514\u2500 Eval duration: 1,966ms\n\n\ud83d\udcc8 Estat\u00edsticas Gerais\n  Total de chamadas: 1\n  Taxa de sucesso: 100%\n  Lat\u00eancia m\u00e9dia: 2,345ms\n  Total de tokens: 150\n</code></pre> <p>Informa\u00e7\u00f5es Exibidas:</p> <ul> <li>N\u00famero da chamada</li> <li>Status (\u2705 Sucesso / \u274c Erro)</li> <li>Modelo usado</li> <li>Lat\u00eancia em milissegundos</li> <li>Tokens (total, prompt, completion)</li> <li>Ollama: Durations (load, prompt_eval, eval)</li> <li>Estat\u00edsticas agregadas</li> </ul>"},{"location":"reference/commands/#configs-configuracoes-do-agente","title":"<code>/configs</code> - Configura\u00e7\u00f5es do Agente","text":"<p>Descri\u00e7\u00e3o: Exibe todas as configura\u00e7\u00f5es atuais do agente.</p> <p>Aliases: <code>/configs</code>, <code>configs</code></p> <p>Uso:</p> <pre><code>Voc\u00ea: /configs\n</code></pre> <p>Sa\u00edda:</p> <pre><code>\u2699\ufe0f Configura\u00e7\u00f5es do Agente\n\nNome: Code Assistant\nProvider: openai\nModelo: gpt-4\n\n\ud83d\udcdd Instru\u00e7\u00f5es:\nVoc\u00ea \u00e9 um especialista em Python. Sempre forne\u00e7a exemplos de c\u00f3digo.\n\n\ud83d\udd27 Par\u00e2metros:\n  \u2022 temperature: 0.7\n  \u2022 max_tokens: 2000\n  \u2022 top_p: 0.9\n\n\ud83d\udee0\ufe0f Ferramentas: 2 dispon\u00edveis\n  \u2022 currentdate\n  \u2022 readlocalfile\n\n\ud83d\udcac Hist\u00f3rico: 5 mensagens (m\u00e1ximo: 20)\n</code></pre> <p>Informa\u00e7\u00f5es Exibidas:</p> <ul> <li>Nome do agente</li> <li>Provider e modelo</li> <li>Instru\u00e7\u00f5es do sistema</li> <li>Par\u00e2metros de configura\u00e7\u00e3o (temperature, max_tokens, etc.)</li> <li>Ferramentas dispon\u00edveis</li> <li>Tamanho do hist\u00f3rico</li> </ul>"},{"location":"reference/commands/#tools-ferramentas-disponiveis","title":"<code>/tools</code> - Ferramentas Dispon\u00edveis","text":"<p>Descri\u00e7\u00e3o: Lista todas as ferramentas que o agente pode usar.</p> <p>Aliases: <code>/tools</code>, <code>tools</code></p> <p>Uso:</p> <pre><code>Voc\u00ea: /tools\n</code></pre> <p>Sa\u00edda:</p> <pre><code>\ud83d\udee0\ufe0f Ferramentas Dispon\u00edveis\n\n\u2022 currentdate\n  \u2514\u2500 Retorna a data e hora atual em qualquer timezone. Suporta offsets UTC e nomes de timezone.\n\n\u2022 readlocalfile\n  \u2514\u2500 L\u00ea e extrai conte\u00fado de arquivos locais incluindo PDF, Excel (xlsx), CSV, Parquet, JSON, YAML e TXT.\n</code></pre> <p>Informa\u00e7\u00f5es Exibidas:</p> <ul> <li>Nome da ferramenta</li> <li>Descri\u00e7\u00e3o detalhada do que ela faz</li> </ul>"},{"location":"reference/commands/#clear-limpar-historico","title":"<code>/clear</code> - Limpar Hist\u00f3rico","text":"<p>Descri\u00e7\u00e3o: Remove todo o hist\u00f3rico de conversa\u00e7\u00e3o e inicia uma nova sess\u00e3o.</p> <p>Aliases: <code>/clear</code>, <code>clear</code></p> <p>Uso:</p> <pre><code>Voc\u00ea: /clear\n</code></pre> <p>Sa\u00edda:</p> <pre><code>\ud83d\uddd1\ufe0f Hist\u00f3rico limpo! Iniciando nova conversa.\n</code></pre> <p>Efeito:</p> <ul> <li>Remove todas as mensagens do hist\u00f3rico</li> <li>Preserva configura\u00e7\u00f5es do agente</li> <li>Pr\u00f3xima mensagem n\u00e3o ter\u00e1 contexto anterior</li> </ul> <p>Quando Usar:</p> <ul> <li>Mudar completamente de assunto</li> <li>Resetar contexto ap\u00f3s erro</li> <li>Liberar mem\u00f3ria em conversas longas</li> </ul>"},{"location":"reference/commands/#chat-comando-padrao","title":"Chat (Comando Padr\u00e3o)","text":"<p>Descri\u00e7\u00e3o: Envia mensagem ao agente de IA. Este \u00e9 o comando padr\u00e3o - qualquer texto que n\u00e3o seja um comando especial \u00e9 enviado ao agente.</p> <p>Uso:</p> <pre><code>Voc\u00ea: Explique o que \u00e9 Clean Architecture\n</code></pre> <p>Sa\u00edda:</p> <pre><code>\u2728 [Resposta em streaming]\n\nClean Architecture \u00e9 um padr\u00e3o de design de software que separa...\n[texto continua em tempo real]\n</code></pre> <p>Comportamento:</p> <ul> <li>Processa entrada com streaming em tempo real</li> <li>Executa ferramentas automaticamente se necess\u00e1rio</li> <li>Mant\u00e9m contexto com hist\u00f3rico de conversa\u00e7\u00e3o</li> <li>Adiciona mensagem ao hist\u00f3rico</li> </ul>"},{"location":"reference/commands/#exit-quit-sair","title":"<code>exit</code> / <code>quit</code> - Sair","text":"<p>Descri\u00e7\u00e3o: Encerra a aplica\u00e7\u00e3o CLI.</p> <p>Aliases: <code>exit</code>, <code>quit</code></p> <p>Uso:</p> <pre><code>Voc\u00ea: exit\n</code></pre> <p>ou</p> <pre><code>Voc\u00ea: quit\n</code></pre> <p>Sa\u00edda:</p> <pre><code>\ud83d\udc4b At\u00e9 logo! Obrigado por usar CreateAgents AI.\n</code></pre> <p>Efeito:</p> <ul> <li>Encerra o loop da CLI</li> <li>Finaliza programa gracefully</li> <li>N\u00e3o salva hist\u00f3rico (sess\u00e3o \u00e9 tempor\u00e1ria)</li> </ul>"},{"location":"reference/commands/#formatacao-e-interface","title":"\ud83c\udfa8 Formata\u00e7\u00e3o e Interface","text":""},{"location":"reference/commands/#cores","title":"Cores","text":"<p>Comandos usam esquema de cores profissional:</p> <ul> <li>Prompts: Cyan</li> <li>Respostas: Verde</li> <li>Sistema: Amarelo</li> <li>Erros: Vermelho</li> <li>Comandos: Magenta</li> </ul>"},{"location":"reference/commands/#indicadores","title":"Indicadores","text":"<p>Durante processamento:</p> <pre><code>\u23f3 Processando...\n\u2728 [Agente est\u00e1 digitando...]\n</code></pre>"},{"location":"reference/commands/#fluxo-de-comandos","title":"\ud83d\udd04 Fluxo de Comandos","text":"<pre><code>User Input\n  \u2193\nCommandRegistry.find_handler()\n  \u2193\n\u00bf\u00c9 comando especial? \u2192 Sim \u2192 Handler espec\u00edfico\n  \u2193                         (/help, /metrics, etc.)\n  N\u00e3o\n  \u2193\nChatCommandHandler (padr\u00e3o)\n  \u2193\nStreaming Response\n</code></pre>"},{"location":"reference/commands/#exemplos-de-uso","title":"\ud83d\udca1 Exemplos de Uso","text":""},{"location":"reference/commands/#fluxo-tipico-de-sessao","title":"Fluxo T\u00edpico de Sess\u00e3o","text":"<pre><code># Iniciar CLI\nVoc\u00ea: /help\n[V\u00ea comandos dispon\u00edveis]\n\nVoc\u00ea: /tools\n[Verifica ferramentas]\n\nVoc\u00ea: Que dia \u00e9 hoje?\n[Agent usa CurrentDateTool e responde]\n\nVoc\u00ea: /metrics\n[V\u00ea estat\u00edsticas da chamada]\n\nVoc\u00ea: /configs\n[Revisa configura\u00e7\u00f5es]\n\nVoc\u00ea: /clear\n[Limpa hist\u00f3rico para novo t\u00f3pico]\n\nVoc\u00ea: Agora vamos falar sobre Python\n[Nova conversa]\n\nVoc\u00ea: exit\n[Sai da CLI]\n</code></pre>"},{"location":"reference/commands/#debugging","title":"Debugging","text":"<pre><code>Voc\u00ea: [mensagem ao agente]\n[Resposta parece estranha]\n\nVoc\u00ea: /configs\n[Verificar instru\u00e7\u00f5es e par\u00e2metros]\n\nVoc\u00ea: /tools\n[Verificar se tool correto est\u00e1 dispon\u00edvel]\n\nVoc\u00ea: /metrics\n[Ver lat\u00eancia e tokens para identificar problemas]\n\nVoc\u00ea: /clear\n[Resetar contexto e tentar novamente]\n</code></pre>"},{"location":"reference/commands/#troubleshooting","title":"\ud83d\udc1b Troubleshooting","text":""},{"location":"reference/commands/#comando-nao-reconhecido","title":"Comando n\u00e3o reconhecido","text":"<p>Problema: Digitou comando errado</p> <p>Solu\u00e7\u00e3o: Use <code>/help</code> para ver lista correta</p>"},{"location":"reference/commands/#metricas-vazias","title":"M\u00e9tricas vazias","text":"<p>Problema: <code>/metrics</code> n\u00e3o mostra nada</p> <p>Solu\u00e7\u00e3o: Fa\u00e7a pelo menos uma chamada ao agente antes</p>"},{"location":"reference/commands/#clear-nao-funciona","title":"Clear n\u00e3o funciona","text":"<p>Problema: Hist\u00f3rico n\u00e3o limpa</p> <p>Solu\u00e7\u00e3o: Verifique que n\u00e3o h\u00e1 erro de digita\u00e7\u00e3o (<code>/clear</code>, n\u00e3o <code>/clean</code>)</p>"},{"location":"reference/commands/#veja-tambem","title":"\ud83d\udcda Veja Tamb\u00e9m","text":"<ul> <li>Guia de Uso da CLI</li> <li>Arquitetura CLI</li> <li>API Reference</li> </ul> <p>Vers\u00e3o: 0.1.3 | Atualiza\u00e7\u00e3o: 01/12/2025</p>"},{"location":"reference/metrics-api/","title":"API de M\u00e9tricas","text":"<p>Refer\u00eancia completa do sistema de m\u00e9tricas do CreateAgents AI.</p>"},{"location":"reference/metrics-api/#chatmetrics","title":"ChatMetrics","text":"<p>Namespace: <code>createagents.infra.config</code></p> <p>Dataclass que armazena m\u00e9tricas de uma chamada de chat.</p>"},{"location":"reference/metrics-api/#estrutura","title":"Estrutura","text":"<pre><code>@dataclass\nclass ChatMetrics:\n    model: str\n    latency_ms: float\n    success: bool\n    tokens_used: Optional[int] = None\n    prompt_tokens: Optional[int] = None\n    completion_tokens: Optional[int] = None\n    load_duration_ms: Optional[float] = None  # Ollama\n    prompt_eval_duration_ms: Optional[float] = None  # Ollama\n    eval_duration_ms: Optional[float] = None  # Ollama\n    error_message: Optional[str] = None\n</code></pre>"},{"location":"reference/metrics-api/#campos","title":"Campos","text":"Campo Tipo Descri\u00e7\u00e3o Provider <code>model</code> str Nome do modelo usado Todos <code>latency_ms</code> float Lat\u00eancia total em ms Todos <code>success</code> bool Se chamada foi bem-sucedida Todos <code>tokens_used</code> int | None Total de tokens Todos <code>prompt_tokens</code> int | None Tokens do prompt Todos <code>completion_tokens</code> int | None Tokens da resposta Todos <code>load_duration_ms</code> float | None Tempo de carregamento do modelo (ms) Ollama <code>prompt_eval_duration_ms</code> float | None Tempo de avalia\u00e7\u00e3o do prompt (ms) Ollama <code>eval_duration_ms</code> float | None Tempo de gera\u00e7\u00e3o da resposta (ms) Ollama <code>error_message</code> str | None Mensagem de erro (se <code>success=False</code>) Todos"},{"location":"reference/metrics-api/#metricsrecorder","title":"MetricsRecorder","text":"<p>Namespace: <code>createagents.infra.adapters.Common</code></p> <p>Classe base para grava\u00e7\u00e3o de m\u00e9tricas em handlers.</p>"},{"location":"reference/metrics-api/#metodos","title":"M\u00e9todos","text":""},{"location":"reference/metrics-api/#__init__metrics_list-optionallistchatmetrics-none","title":"<code>__init__(metrics_list: Optional[List[ChatMetrics]] = None)</code>","text":"<p>Inicializa o recorder com lista opcional de m\u00e9tricas.</p>"},{"location":"reference/metrics-api/#record_success_metricsmodel-start_time-response_api-provider_type","title":"<code>record_success_metrics(model, start_time, response_api, provider_type)</code>","text":"<p>Grava m\u00e9tricas para opera\u00e7\u00e3o bem-sucedida.</p> <p>Par\u00e2metros:</p> <ul> <li><code>model</code> (str): Nome do modelo</li> <li><code>start_time</code> (float): Timestamp do in\u00edcio</li> <li><code>response_api</code> (Any): Resposta da API</li> <li><code>provider_type</code> (str): \u2018openai\u2019 ou \u2018ollama\u2019</li> </ul>"},{"location":"reference/metrics-api/#record_error_metricsmodel-start_time-error","title":"<code>record_error_metrics(model, start_time, error)</code>","text":"<p>Grava m\u00e9tricas para opera\u00e7\u00e3o com erro.</p> <p>Par\u00e2metros:</p> <ul> <li><code>model</code> (str): Nome do modelo</li> <li><code>start_time</code> (float): Timestamp do in\u00edcio</li> <li><code>error</code> (Any): Erro ocorrido</li> </ul>"},{"location":"reference/metrics-api/#get_metrics-listchatmetrics","title":"<code>get_metrics() -&gt; List[ChatMetrics]</code>","text":"<p>Retorna c\u00f3pia da lista de m\u00e9tricas.</p>"},{"location":"reference/metrics-api/#exportacao-de-metricas","title":"Exporta\u00e7\u00e3o de M\u00e9tricas","text":""},{"location":"reference/metrics-api/#json","title":"JSON","text":"<pre><code>agent = CreateAgent(provider=\"openai\", model=\"gpt-4\")\nagent.chat(\"teste\")\n\n# Exportar para string\njson_string = agent.export_metrics_json()\n\n# Exportar para arquivo\nagent.export_metrics_json(\"metrics.json\")\n</code></pre> <p>Formato:</p> <pre><code>[\n  {\n    \"model\": \"gpt-4\",\n    \"latency_ms\": 1234.56,\n    \"success\": true,\n    \"tokens_used\": 250,\n    \"prompt_tokens\": 100,\n    \"completion_tokens\": 150,\n    \"error_message\": null\n  }\n]\n</code></pre>"},{"location":"reference/metrics-api/#prometheus","title":"Prometheus","text":"<pre><code># Exportar para string (formato Prometheus)\nprom_string = agent.export_metrics_prometheus()\n\n# Exportar para arquivo\nagent.export_metrics_prometheus(\"metrics.prom\")\n</code></pre> <p>Formato:</p> <pre><code># HELP createagents_chat_latency_milliseconds Chat latency in milliseconds\n# TYPE createagents_chat_latency_milliseconds histogram\ncreateagents_chat_latency_milliseconds{model=\"gpt-4\"} 1234.56\n\n# HELP createagents_chat_tokens_total Total tokens used\n# TYPE createagents_chat_tokens_total counter\ncreateagents_chat_tokens_total{model=\"gpt-4\",type=\"total\"} 250\n</code></pre>"},{"location":"reference/metrics-api/#metricas-openai-vs-ollama","title":"M\u00e9tricas OpenAI vs Ollama","text":""},{"location":"reference/metrics-api/#openai","title":"OpenAI","text":"<p>M\u00e9tricas dispon\u00edveis:</p> <ul> <li><code>model</code></li> <li><code>latency_ms</code></li> <li><code>tokens_used</code></li> <li><code>prompt_tokens</code></li> <li><code>completion_tokens</code></li> <li><code>success</code></li> </ul>"},{"location":"reference/metrics-api/#ollama","title":"Ollama","text":"<p>M\u00e9tricas dispon\u00edveis (todas do OpenAI +):</p> <ul> <li><code>load_duration_ms</code> - Tempo para carregar modelo</li> <li><code>prompt_eval_duration_ms</code> - Tempo para processar prompt</li> <li><code>eval_duration_ms</code> - Tempo para gerar resposta</li> </ul>"},{"location":"reference/metrics-api/#exemplo-completo","title":"Exemplo Completo","text":"<pre><code>import asyncio\nfrom createagents import CreateAgent\n\nasync def main():\n    agent = CreateAgent(provider=\"openai\", model=\"gpt-4\")\n\n    # Fazer algumas chamadas\n    await agent.chat(\"Pergunta 1\")\n    await agent.chat(\"Pergunta 2\")\n    await agent.chat(\"Pergunta 3\")\n\n    # Obter m\u00e9tricas\n    metrics = agent.get_metrics()\n\n    for i, metric in enumerate(metrics, 1):\n        print(f\"Chamada #{i}\")\n        print(f\"  Modelo: {metric.model}\")\n        print(f\"  Lat\u00eancia: {metric.latency_ms:.2f}ms\")\n        print(f\"  Sucesso: {metric.success}\")\n        if metric.success:\n            print(f\"  Tokens: {metric.tokens_used}\")\n            print(f\"    Prompt: {metric.prompt_tokens}\")\n            print(f\"    Completion: {metric.completion_tokens}\")\n        else:\n            print(f\"  Erro: {metric.error_message}\")\n        print()\n\n    # Exportar\n    agent.export_metrics_json(\"output.json\")\n    agent.export_metrics_prometheus(\"output.prom\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"reference/metrics-api/#veja-tambem","title":"Veja Tamb\u00e9m","text":"<ul> <li>Guia de Uso CLI - Comando <code>/metrics</code></li> <li>API Reference</li> </ul> <p>Vers\u00e3o: 0.1.3 | Atualiza\u00e7\u00e3o: 01/12/2025</p>"},{"location":"reference/streaming-api/","title":"API de Streaming","text":"<p>Refer\u00eancia t\u00e9cnica completa da API de streaming do CreateAgents AI.</p>"},{"location":"reference/streaming-api/#streamingresponsedto","title":"StreamingResponseDTO","text":"<p>Namespace: <code>createagents.application.dtos</code></p> <p>Classe que encapsula um <code>AsyncGenerator</code> e fornece interface conveniente para consumo de respostas em streaming.</p>"},{"location":"reference/streaming-api/#assinatura","title":"Assinatura","text":"<pre><code>class StreamingResponseDTO:\n    def __init__(self, generator: AsyncGenerator[str, None]): ...\n\n    async def __anext__(self) -&gt; str: ...\n    def __aiter__(self) -&gt; 'StreamingResponseDTO': ...\n    def __await__(self) -&gt; Generator[Any, None, str]: ...\n    def __str__(self) -&gt; str: ...\n    def __repr__(self) -&gt; str: ...\n</code></pre>"},{"location":"reference/streaming-api/#metodos","title":"M\u00e9todos","text":""},{"location":"reference/streaming-api/#__init__generator-asyncgeneratorstr-none","title":"<code>__init__(generator: AsyncGenerator[str, None])</code>","text":"<p>Inicializa o DTO com um gerador ass\u00edncrono.</p> <p>Par\u00e2metros:</p> <ul> <li><code>generator</code>: AsyncGenerator que yield tokens como strings</li> </ul> <p>Exemplo:</p> <pre><code>async def my_generator():\n    yield \"Hello\"\n    yield \" \"\n    yield \"World\"\n\ndto = StreamingResponseDTO(my_generator())\n</code></pre>"},{"location":"reference/streaming-api/#__aiter__-streamingresponsedto","title":"<code>__aiter__() -&gt; StreamingResponseDTO</code>","text":"<p>Retorna iterador para uso em <code>async for</code>.</p> <p>Retorna: Self</p> <p>Exemplo:</p> <pre><code>async for token in dto:\n    print(token, end='')\n</code></pre>"},{"location":"reference/streaming-api/#async-__anext__-str","title":"<code>async __anext__() -&gt; str</code>","text":"<p>Retorna pr\u00f3ximo token do stream.</p> <p>Retorna: String com pr\u00f3ximo token</p> <p>Levanta: <code>StopAsyncIteration</code> quando stream termina</p> <p>Exemplo:</p> <pre><code>token = await dto.__anext__()\n</code></pre>"},{"location":"reference/streaming-api/#__await__-generator","title":"<code>__await__() -&gt; Generator</code>","text":"<p>Permite usar <code>await</code> para consumir todo o stream e retornar string completa.</p> <p>Retorna: String com resposta completa</p> <p>Exemplo:</p> <pre><code>full_response = await dto\nprint(full_response)  # \"Hello World\"\n</code></pre>"},{"location":"reference/streaming-api/#__str__-str","title":"<code>__str__() -&gt; str</code>","text":"<p>Retorna representa\u00e7\u00e3o em string.</p> <p>Retorna: String completa se consumido, placeholder caso contr\u00e1rio</p> <p>Exemplo:</p> <pre><code>print(str(dto))  # \"StreamingResponseDTO(not consumed - use 'await response')\"\n</code></pre>"},{"location":"reference/streaming-api/#__repr__-str","title":"<code>__repr__() -&gt; str</code>","text":"<p>Retorna representa\u00e7\u00e3o para debugging.</p> <p>Retorna: String com status e comprimento</p>"},{"location":"reference/streaming-api/#uso-completo","title":"Uso Completo","text":""},{"location":"reference/streaming-api/#padrao-1-await-para-string-completa","title":"Padr\u00e3o 1: Await para String Completa","text":"<pre><code>import asyncio\nfrom createagents import CreateAgent\n\nasync def main():\n    agent = CreateAgent(provider=\"openai\", model=\"gpt-4\")\n    response = await agent.chat(\"Ol\u00e1\")  # StreamingResponseDTO\n    text = await response  # String completa\n    print(text)\n\nasyncio.run(main())\n</code></pre>"},{"location":"reference/streaming-api/#padrao-2-async-for-para-streaming","title":"Padr\u00e3o 2: Async For para Streaming","text":"<pre><code>import asyncio\nfrom createagents import CreateAgent\n\nasync def main():\n    agent = CreateAgent(provider=\"openai\", model=\"gpt-4\")\n    response = await agent.chat(\"Conte uma hist\u00f3ria\")\n\n    async for token in response:\n        print(token, end='', flush=True)\n    print()\n\nasyncio.run(main())\n</code></pre>"},{"location":"reference/streaming-api/#padrao-3-combinar-acumulacao-e-exibicao","title":"Padr\u00e3o 3: Combinar Acumula\u00e7\u00e3o e Exibi\u00e7\u00e3o","text":"<pre><code>import asyncio\n\nasync def accumulate_and_display():\n    agent = CreateAgent(provider=\"openai\", model=\"gpt-4\")\n    response = await agent.chat(\"Liste 5 dicas\")\n\n    accumulated = \"\"\n    async for token in response:\n        accumulated += token\n        print(token, end='', flush=True)\n\n    print(f\"\\n\\nTotal caracteres: {len(accumulated)}\")\n\nasyncio.run(accumulate_and_display())\n</code></pre>"},{"location":"reference/streaming-api/#propriedades-internas","title":"Propriedades Internas","text":"Propriedade Tipo Descri\u00e7\u00e3o <code>_generator</code> AsyncGenerator[str, None] Gerador de tokens <code>_consumed</code> bool Se stream foi consumido <code>_full_response</code> str Resposta acumulada"},{"location":"reference/streaming-api/#excecoes","title":"Exce\u00e7\u00f5es","text":""},{"location":"reference/streaming-api/#stopasynciteration","title":"StopAsyncIteration","text":"<p>Levantada quando itera\u00e7\u00e3o termina.</p> <pre><code>async for token in response:\n    print(token)\n# StopAsyncIteration \u00e9 levantada automaticamente ao final\n</code></pre>"},{"location":"reference/streaming-api/#veja-tambem","title":"Veja Tamb\u00e9m","text":"<ul> <li>Guia de Streaming</li> <li>Guia Async</li> <li>API Reference</li> </ul> <p>Vers\u00e3o: 0.1.3 | Atualiza\u00e7\u00e3o: 01/12/2025</p>"},{"location":"reference/tools/","title":"\ud83d\udee0\ufe0f Ferramentas (Tools)","text":"<p>Este guia explica as ferramentas dispon\u00edveis para seus agentes de IA e como us\u00e1-las.</p>"},{"location":"reference/tools/#visao-geral","title":"\ud83d\udce6 Vis\u00e3o Geral","text":"<p>Ferramentas s\u00e3o capacidades adicionais que seus agentes podem usar para executar tarefas espec\u00edficas. Para manter o sistema leve, algumas ferramentas com depend\u00eancias pesadas s\u00e3o opcionais.</p>"},{"location":"reference/tools/#ferramentas-disponiveis","title":"\ud83c\udfaf Ferramentas Dispon\u00edveis","text":""},{"location":"reference/tools/#currentdatetool-sempre-disponivel","title":"\u2705 CurrentDateTool (Sempre Dispon\u00edvel)","text":"<p>Obt\u00e9m data e hora atuais em qualquer timezone.</p> <p>Depend\u00eancias: Nenhuma (biblioteca padr\u00e3o Python)</p> <p>Uso:</p> <pre><code>import asyncio\nfrom createagents import CreateAgent\n\nasync def main():\n    agent = CreateAgent(\n        provider=\"openai\",\n        model=\"gpt-4\",\n        tools=[\"currentdate\"]\n    )\n\n    resposta = await agent.chat(\"Que dia \u00e9 hoje?\")\n    print(resposta)\n\nasyncio.run(main())\n</code></pre> <p>A\u00e7\u00f5es suportadas:</p> <ul> <li><code>date</code> - Data (YYYY-MM-DD)</li> <li><code>time</code> - Hora (HH:MM:SS)</li> <li><code>datetime</code> - Data e hora completos</li> <li><code>timestamp</code> - Unix timestamp</li> <li><code>date_with_weekday</code> - Data com dia da semana</li> </ul>"},{"location":"reference/tools/#readlocalfiletool-opcional","title":"\ud83d\udd27 ReadLocalFileTool (Opcional)","text":"<p>L\u00ea arquivos locais em m\u00faltiplos formatos.</p> <p>Formatos: TXT, MD, CSV, Excel (XLS/XLSX), PDF, Parquet, JSON, YAML</p> <p>Depend\u00eancias: <code>tiktoken</code>, <code>unstructured</code>, <code>pandas</code>, <code>openpyxl</code>, <code>pyarrow</code>, <code>chardet</code></p> <p>Instala\u00e7\u00e3o:</p> <pre><code>pip install createagents[file-tools]\n</code></pre> <p>Uso:</p> <pre><code>import asyncio\nfrom createagents import CreateAgent\n\nasync def main():\n    agent = CreateAgent(\n        provider=\"openai\",\n        model=\"gpt-4\",\n        tools=[\"readlocalfile\"]\n    )\n\n    resposta = await agent.chat(\"Leia o arquivo report.pdf e resuma\")\n    print(resposta)\n\nasyncio.run(main())\n</code></pre> <p>Limites:</p> <ul> <li>Tamanho m\u00e1ximo: 100MB</li> <li>Tokens m\u00e1ximos: Depende da AI utilizada</li> </ul> <p>Funcionalidades:</p> <ul> <li>\u2705 Valida\u00e7\u00e3o de tamanho</li> <li>\u2705 Detec\u00e7\u00e3o autom\u00e1tica de encoding</li> <li>\u2705 Suporte a m\u00faltiplos formatos</li> <li>\u2705 Tratamento robusto de erros</li> </ul>"},{"location":"reference/tools/#uso-com-agentes","title":"\ud83d\ude80 Uso com Agentes","text":""},{"location":"reference/tools/#exemplo-1-ferramenta-de-data","title":"Exemplo 1: Ferramenta de Data","text":"<pre><code>import asyncio\n\nasync def main():\n    agent = CreateAgent(\n        provider=\"openai\",\n        model=\"gpt-4\",\n        instructions=\"Voc\u00ea pode verificar data/hora quando necess\u00e1rio\",\n        tools=[\"currentdate\"]\n    )\n\n    # O agente usa a ferramenta automaticamente\n    resposta = await agent.chat(\"Que dia da semana \u00e9 hoje?\")\n    print(resposta)\n\nasyncio.run(main())\n</code></pre>"},{"location":"reference/tools/#exemplo-2-leitura-de-arquivos","title":"Exemplo 2: Leitura de Arquivos","text":"<pre><code>import asyncio\n\nasync def main():\n    # Certifique-se que instalou: pip install createagents[file-tools]\n    agent = CreateAgent(\n        provider=\"openai\",\n        model=\"gpt-4\",\n        instructions=\"Voc\u00ea pode ler arquivos locais\",\n        tools=[\"readlocalfile\"]\n    )\n\n    resposta = await agent.chat(\"Resuma o documento relatorio.pdf\")\n    print(resposta)\n\nasyncio.run(main())\n</code></pre>"},{"location":"reference/tools/#exemplo-3-multiplas-ferramentas","title":"Exemplo 3: M\u00faltiplas Ferramentas","text":"<pre><code>import asyncio\n\nasync def main():\n    agent = CreateAgent(\n        provider=\"openai\",\n        model=\"gpt-4\",\n        tools=[\"currentdate\", \"readlocalfile\"]\n    )\n\n    # O agente escolhe qual ferramenta usar\n    resposta1 = await agent.chat(\"Que dia \u00e9 hoje?\")  # Usa currentdate\n    print(resposta1)\n\n    resposta2 = await agent.chat(\"Leia notas.txt\")   # Usa readlocalfile\n    print(resposta2)\n\nasyncio.run(main())\n</code></pre>"},{"location":"reference/tools/#checklist-de-instalacao","title":"\ud83d\udccb Checklist de Instala\u00e7\u00e3o","text":""},{"location":"reference/tools/#instalacao-basica","title":"Instala\u00e7\u00e3o B\u00e1sica \u2705","text":"<pre><code>pip install createagents\n</code></pre> <p>Inclui:</p> <ul> <li> CurrentDateTool</li> <li> Gerenciamento de hist\u00f3rico</li> <li> M\u00e9tricas de performance</li> <li> OpenAI e Ollama adapters</li> </ul>"},{"location":"reference/tools/#instalacao-com-file-tools","title":"Instala\u00e7\u00e3o com File Tools \ud83d\udcc1","text":"<pre><code>pip install createagents[file-tools]\n</code></pre> <p>Inclui:</p> <ul> <li> Tudo da instala\u00e7\u00e3o b\u00e1sica</li> <li> ReadLocalFileTool</li> <li> Suporte para PDF, Excel, CSV, Parquet</li> </ul>"},{"location":"reference/tools/#verificar-ferramentas-disponiveis","title":"\ud83d\udd0d Verificar Ferramentas Dispon\u00edveis","text":""},{"location":"reference/tools/#verificar-ferramentas-do-agente","title":"Verificar Ferramentas do Agente","text":"<p>Use <code>get_all_available_tools()</code> para ver todas as ferramentas dispon\u00edveis para um agente espec\u00edfico (inclui ferramentas do sistema + ferramentas customizadas adicionadas ao agente):</p> <pre><code>from createagents import CreateAgent, BaseTool\n\nclass CustomTool(BaseTool):\n    name = \"custom_tool\"\n    description = \"Minha ferramenta customizada\"\n    parameters = {\n        \"type\": \"object\",\n        \"properties\": {\n            \"input\": {\"type\": \"string\", \"description\": \"Texto de entrada para a ferramenta\"}\n        },\n        \"required\": [\"input\"]\n    }\n\n    def execute(self, input: str) -&gt; str:\n        return f\"Resultado para: {input}\"\n\nagent = CreateAgent(\n    provider=\"openai\",\n    model=\"gpt-4\",\n    tools=[\"currentdate\", CustomTool()]  # Ferramenta do sistema + customizada\n)\n\n# Obter todas as ferramentas deste agente\ntools = agent.get_all_available_tools()\n\nprint(\"Ferramentas dispon\u00edveis neste agente:\")\nfor name, description in tools.items():\n    print(f\"  - {name}: {description[:50]}...\")\n\n# Exemplo de sa\u00edda:\n# - currentdate: Get the current date and/or time...\n# - readlocalfile: Use this tool to read local files...\n# - custom_tool: Minha ferramenta customizada\n</code></pre>"},{"location":"reference/tools/#verificar-apenas-ferramentas-do-sistema","title":"Verificar Apenas Ferramentas do Sistema","text":"<p>Use <code>get_system_available_tools()</code> para ver apenas as ferramentas built-in dispon\u00edveis globalmente (n\u00e3o inclui ferramentas customizadas):</p> <pre><code>from createagents import CreateAgent\n\nagent = CreateAgent(provider=\"openai\", model=\"gpt-4\")\n\n# Obter apenas ferramentas do sistema\nsystem_tools = agent.get_system_available_tools()\n\nprint(\"Ferramentas do sistema dispon\u00edveis:\")\nfor name, description in system_tools.items():\n    print(f\"  - {name}: {description[:50]}...\")\n\n# Verificar se uma ferramenta espec\u00edfica est\u00e1 dispon\u00edvel\nif \"readlocalfile\" in system_tools:\n    print(\"\u2705 ReadLocalFileTool dispon\u00edvel!\")\nelse:\n    print(\"\u26a0\ufe0f Instale com: pip install createagents[file-tools]\")\n</code></pre>"},{"location":"reference/tools/#diferenca-entre-os-metodos","title":"Diferen\u00e7a Entre os M\u00e9todos","text":"M\u00e9todo Retorna Quando Usar <code>get_all_available_tools()</code> Ferramentas do sistema + customizadas do agente Para ver todas as ferramentas que o agente pode usar <code>get_system_available_tools()</code> Apenas ferramentas do sistema (built-in) Para verificar quais ferramentas opcionais est\u00e3o instaladas"},{"location":"reference/tools/#exemplo-pratico","title":"Exemplo Pr\u00e1tico","text":"<pre><code>from createagents import CreateAgent, BaseTool\n\n# Ferramenta customizada\nclass WeatherTool(BaseTool):\n    name = \"weather\"\n    description = \"Consulta previs\u00e3o do tempo\"\n    parameters = {\n        \"type\": \"object\",\n        \"properties\": {\n            \"city\": {\"type\": \"string\", \"description\": \"Nome da cidade para consulta\"}\n        },\n        \"required\": [\"city\"]\n    }\n\n    def execute(self, city: str) -&gt; str:\n        return f\"Previs\u00e3o para {city}: Ensolarado\"\n\n# Agente sem ferramentas customizadas\nagent1 = CreateAgent(provider=\"openai\", model=\"gpt-4\")\nprint(\"Agente 1:\", agent1.get_all_available_tools().keys())\n# Sa\u00edda: dict_keys(['currentdate', 'readlocalfile'])\n\n# Agente com ferramentas customizadas\nagent2 = CreateAgent(\n    provider=\"openai\",\n    model=\"gpt-4\",\n    tools=[\"currentdate\", WeatherTool()]\n)\nprint(\"Agente 2:\", agent2.get_all_available_tools().keys())\n# Sa\u00edda: dict_keys(['currentdate', 'readlocalfile', 'weather'])\n\n# Ferramentas do sistema (sempre igual para todos os agentes)\nprint(\"Sistema:\", agent1.get_system_available_tools().keys())\n# Sa\u00edda: dict_keys(['currentdate', 'readlocalfile'])\n</code></pre>"},{"location":"reference/tools/#evitando-duplicatas","title":"Evitando Duplicatas","text":"<p>O sistema automaticamente evita duplicatas de ferramentas. Se voc\u00ea adicionar uma ferramenta do sistema \u00e0 lista de tools do agente, ela aparecer\u00e1 apenas uma vez:</p> <pre><code># Ferramenta do sistema adicionada explicitamente\nagent = CreateAgent(\n    provider=\"openai\",\n    model=\"gpt-4\",\n    tools=[\"currentdate\"]  # Adiciona explicitamente uma ferramenta do sistema\n)\n\n# N\u00e3o haver\u00e1 duplicatas\ntools = agent.get_all_available_tools()\n# 'currentdate' aparece apenas UMA vez\nprint(list(tools.keys()))  # ['currentdate', 'readlocalfile']\n</code></pre>"},{"location":"reference/tools/#performance","title":"\u26a1 Performance","text":""},{"location":"reference/tools/#uso-de-memoria","title":"Uso de Mem\u00f3ria","text":"Instala\u00e7\u00e3o Mem\u00f3ria Base Com ReadLocalFileTool B\u00e1sica ~50MB N/A Com file-tools ~50MB ~200MB (quando usada)"},{"location":"reference/tools/#criar-suas-proprias-ferramentas","title":"\ud83c\udfa8 Criar Suas Pr\u00f3prias Ferramentas","text":""},{"location":"reference/tools/#ferramenta-propria","title":"Ferramenta Pr\u00f3pria","text":"<pre><code>from createagents import BaseTool\n\nclass CalculatorTool(BaseTool):\n    name = \"calculator\"\n    description = \"Realiza c\u00e1lculos matem\u00e1ticos\"\n    parameters = {\n        \"type\": \"object\",\n        \"properties\": {\n            \"expression\": {\"type\": \"string\", \"description\": \"Express\u00e3o matem\u00e1tica\"}\n        },\n        \"required\": [\"expression\"]\n    }\n\n    def execute(self, expression: str) -&gt; str:\n        return str(eval(expression))\n</code></pre>"},{"location":"reference/tools/#faq","title":"\ud83e\udd14 FAQ","text":"<p>P: Por que algumas ferramentas s\u00e3o opcionais? R: Para manter o sistema leve. Se voc\u00ea n\u00e3o precisa ler PDFs/Excel, n\u00e3o precisa instalar pandas, unstructured, etc.</p> <p>P: Como sei quais ferramentas est\u00e3o dispon\u00edveis? R: Use <code>agent.get_all_available_tools()</code> para listar.</p> <p>P: O que acontece se eu tentar usar uma ferramenta n\u00e3o instalada? R: Voc\u00ea receber\u00e1 erro claro: <code>pip install createagents[file-tools]</code></p> <p>P: Posso criar minhas pr\u00f3prias ferramentas? R: Sim! Siga o padr\u00e3o de ferramentas pr\u00f3prias e estenda <code>BaseTool</code>.</p> <p>\u00daltima atualiza\u00e7\u00e3o: 02/12/2025</p>"},{"location":"user-guide/basic-usage-user/","title":"Guia de Uso B\u00e1sico do Usu\u00e1rio","text":"<p>Aprenda a criar e interagir com agentes de IA rapidamente.</p>"},{"location":"user-guide/basic-usage-user/#primeiro-agente","title":"Primeiro Agente","text":"<pre><code>from createagents import CreateAgent\nagent = CreateAgent(\n    provider=\"openai\",\n    model=\"gpt-4\",\n    instructions=\"Voc\u00ea \u00e9 um assistente \u00fatil\"\n)\n</code></pre>"},{"location":"user-guide/basic-usage-user/#conversando","title":"Conversando","text":"<pre><code>import asyncio\n\nasync def main():\n    response1 = await agent.chat(\"Ol\u00e1! Como voc\u00ea est\u00e1?\")\n    response2 = await agent.chat(\"Qual \u00e9 a capital do Brasil?\")\n    response3 = await agent.chat(\"E a popula\u00e7\u00e3o?\")\n\n    for response in [response1, response2, response3]:\n        print(response)\n\nasyncio.run(main())\n</code></pre>"},{"location":"user-guide/basic-usage-user/#configuracoes","title":"Configura\u00e7\u00f5es","text":"<pre><code>config = agent.get_configs()\nprint(f\"Modelo: {config['model']}\")\nprint(f\"Hist\u00f3rico: {len(config['history'])} mensagens\")\n</code></pre>"},{"location":"user-guide/basic-usage-user/#limpar-historico","title":"Limpar Hist\u00f3rico","text":"<pre><code>agent.clear_history()\n</code></pre>"},{"location":"user-guide/basic-usage-user/#streaming-respostas-em-tempo-real","title":"Streaming (Respostas em Tempo Real)","text":""},{"location":"user-guide/basic-usage-user/#opcao-1-await-receber-resposta-completa","title":"Op\u00e7\u00e3o 1: Await (Receber resposta completa)","text":"<pre><code>import asyncio\n\nasync def main():\n    agent = CreateAgent(\n        provider=\"openai\",\n        model=\"gpt-4\",\n    )\n    # Recebe a resposta completa\n    response = await agent.chat(\"Escreva um poema\")\n    print(response)\n\nasyncio.run(main())\n</code></pre>"},{"location":"user-guide/basic-usage-user/#opcao-2-async-for-streaming-token-por-token","title":"Op\u00e7\u00e3o 2: Async For (Streaming token por token)","text":"<pre><code>import asyncio\n\nasync def main():\n    agent = CreateAgent(\n        provider=\"openai\",\n        model=\"gpt-4\",\n    )\n    # Recebe tokens em tempo real\n    response = await agent.chat(\"Conte uma hist\u00f3ria\")\n    async for token in response:\n        print(token, end='', flush=True)\n    print()  # Nova linha no final\n\nasyncio.run(main())\n</code></pre> <p>\u2139\ufe0f Nota: Streaming \u00e9 controlado pelo par\u00e2metro <code>stream</code> em <code>config</code> (padr\u00e3o: <code>True</code>). Ambos os providers (OpenAI e Ollama) suportam streaming.</p>"},{"location":"user-guide/basic-usage-user/#personalizando","title":"Personalizando","text":"<pre><code>agent_formal = CreateAgent(\n    provider=\"openai\",\n    model=\"gpt-4\",\n    instructions=\"Use linguagem formal\"\n)\nagent_tecnico = CreateAgent(\n    provider=\"openai\",\n    model=\"gpt-4\",\n    instructions=\"Especialista em Python\"\n)\n</code></pre>"},{"location":"user-guide/basic-usage-user/#configuracoes-avancadas","title":"Configura\u00e7\u00f5es Avan\u00e7adas","text":"<pre><code>agent = CreateAgent(\n    provider=\"openai\",\n    model=\"gpt-4\",\n    config={\"temperature\": 0.7, \"max_tokens\": 2000},\n    history_max_size=50\n)\n</code></pre>"},{"location":"user-guide/basic-usage-user/#ferramentas","title":"Ferramentas","text":"<pre><code>import asyncio\n\nasync def main():\n    agent = CreateAgent(\n        provider=\"openai\",\n        model=\"gpt-4\",\n        tools=[\"currentdate\"]\n    )\n    response = await agent.chat(\"Que dia \u00e9 hoje?\")\n    print(response)\n\nasyncio.run(main())\n</code></pre>"},{"location":"user-guide/basic-usage-user/#verificar-ferramentas-disponiveis","title":"Verificar Ferramentas Dispon\u00edveis","text":"<pre><code>all_tools = agent.get_all_available_tools()\nfor name, description in all_tools.items():\n    print(f\"\u2022 {name}: {description[:50]}...\")\n</code></pre>"},{"location":"user-guide/basic-usage-user/#criar-ferramentas-customizadas","title":"Criar Ferramentas Customizadas","text":"<pre><code>from createagents import BaseTool\n\nclass CalculatorTool(BaseTool):\n    name = \"calculator\"\n    description = \"Realiza c\u00e1lculos matem\u00e1ticos\"\n    parameters = {\n        \"type\": \"object\",\n        \"properties\": {\n            \"expression\": {\n                \"type\": \"string\",\n                \"description\": \"Express\u00e3o matem\u00e1tica\"\n            }\n        },\n        \"required\": [\"expression\"]\n    }\n    def execute(self, expression: str) -&gt; str:\n        return str(eval(expression))\n</code></pre>"},{"location":"user-guide/basic-usage-user/#metricas","title":"M\u00e9tricas","text":"<pre><code>metrics = agent.get_metrics()\nagent.export_metrics_json(\"metrics.json\")\nagent.export_metrics_prometheus(\"metrics.prom\")\n</code></pre>"},{"location":"user-guide/basic-usage-user/#proximos-passos","title":"Pr\u00f3ximos Passos","text":"<ul> <li>Exemplos</li> <li>FAQ</li> </ul>"},{"location":"user-guide/cli-usage/","title":"Guia de Uso da CLI Interativa","text":"<p>A CLI (Command-Line Interface) do CreateAgents AI oferece uma interface interativa profissional para conversar com seus agentes de IA.</p>"},{"location":"user-guide/cli-usage/#inicio-rapido","title":"\ud83d\ude80 In\u00edcio R\u00e1pido","text":"<pre><code>from createagents import CreateAgent\n\n# Criar agente\nagent = CreateAgent(\n    provider=\"openai\",\n    model=\"gpt-4\",\n    name=\"Assistente\",\n    instructions=\"Voc\u00ea \u00e9 um assistente prestativo\",\n)\n\n# Iniciar CLI interativa\nagent.start_cli()\n</code></pre>"},{"location":"user-guide/cli-usage/#recursos","title":"\u2728 Recursos","text":"<ul> <li>\ud83c\udfa8 Interface Colorida: Sintaxe highlight e formata\u00e7\u00e3o markdown</li> <li>\u26a1 Streaming em Tempo Real: Respostas aparecem token por token</li> <li>\ud83c\udfaf Comandos Integrados: 7 comandos para controle total</li> <li>\ud83d\udd27 Indicadores de Status: Mostra quando o agente est\u00e1 pensando</li> <li>\ud83d\udcca M\u00e9tricas em Tempo Real: Visualize performance instantaneamente</li> </ul>"},{"location":"user-guide/cli-usage/#comandos-disponiveis","title":"\ud83d\udccb Comandos Dispon\u00edveis","text":""},{"location":"user-guide/cli-usage/#help-ajuda","title":"<code>/help</code> - Ajuda","text":"<p>Exibe lista de comandos dispon\u00edveis.</p> <pre><code>Voc\u00ea: /help\n</code></pre> <p>Aliases: <code>/help</code>, <code>help</code></p>"},{"location":"user-guide/cli-usage/#metrics-metricas","title":"<code>/metrics</code> - M\u00e9tricas","text":"<p>Mostra estat\u00edsticas de performance do agente:</p> <ul> <li>N\u00famero de chamadas</li> <li>Tokens usados (prompt + completion)</li> <li>Lat\u00eancia m\u00e9dia</li> <li>Taxa de sucesso</li> <li>M\u00e9tricas Ollama: load_duration, prompt_eval_duration, eval_duration</li> </ul> <pre><code>Voc\u00ea: /metrics\n</code></pre> <p>Aliases: <code>/metrics</code>, <code>metrics</code></p> <p>Exemplo de sa\u00edda:</p> <pre><code>\ud83d\udcca M\u00e9tricas de Performance\n\nChamada #1 | \u2705 Sucesso\n  \u2514\u2500 Modelo: gpt-4\n  \u2514\u2500 Lat\u00eancia: 1,245ms\n  \u2514\u2500 Tokens: 150 (prompt: 45, completion: 105)\n\nChamada #2 | \u2705 Sucesso\n  \u2514\u2500 Modelo: gpt-4\n  \u2514\u2500 Lat\u00eancia: 982ms\n  \u2514\u2500 Tokens: 230 (prompt: 110, completion: 120)\n\n\ud83d\udcc8 Estat\u00edsticas Gerais\n  Total de chamadas: 2\n  Taxa de sucesso: 100%\n  Lat\u00eancia m\u00e9dia: 1,113ms\n  Total de tokens: 380\n</code></pre>"},{"location":"user-guide/cli-usage/#configs-configuracoes","title":"<code>/configs</code> - Configura\u00e7\u00f5es","text":"<p>Mostra configura\u00e7\u00f5es atuais do agente:</p> <ul> <li>Nome</li> <li>Provider e modelo</li> <li>Instru\u00e7\u00f5es</li> <li>Par\u00e2metros de configura\u00e7\u00e3o</li> <li>Ferramentas dispon\u00edveis</li> <li>Tamanho do hist\u00f3rico</li> </ul> <pre><code>Voc\u00ea: /configs\n</code></pre> <p>Aliases: <code>/configs</code>, <code>configs</code></p>"},{"location":"user-guide/cli-usage/#tools-ferramentas","title":"<code>/tools</code> - Ferramentas","text":"<p>Lista todas as ferramentas dispon\u00edveis para o agente.</p> <pre><code>Voc\u00ea: /tools\n</code></pre> <p>Aliases: <code>/tools</code>, <code>tools</code></p> <p>Exemplo de sa\u00edda:</p> <pre><code>\ud83d\udee0\ufe0f Ferramentas Dispon\u00edveis\n\n\u2022 currentdate\n  \u2514\u2500 Retorna a data e hora atual em qualquer timezone\n\n\u2022 readlocalfile\n  \u2514\u2500 L\u00ea e extrai conte\u00fado de arquivos locais (PDF, Excel, CSV, etc)\n</code></pre>"},{"location":"user-guide/cli-usage/#clear-limpar-historico","title":"<code>/clear</code> - Limpar Hist\u00f3rico","text":"<p>Limpa todo o hist\u00f3rico de conversa\u00e7\u00e3o e inicia uma nova sess\u00e3o.</p> <pre><code>Voc\u00ea: /clear\n</code></pre> <p>Aliases: <code>/clear</code>, <code>clear</code></p>"},{"location":"user-guide/cli-usage/#chat-normal","title":"Chat Normal","text":"<p>Qualquer texto que n\u00e3o seja um comando \u00e9 enviado como mensagem ao agente.</p> <pre><code>Voc\u00ea: Explique Clean Architecture\n</code></pre> <p>O agente responder\u00e1 com streaming em tempo real.</p>"},{"location":"user-guide/cli-usage/#exit-quit-sair","title":"<code>exit</code> / <code>quit</code> - Sair","text":"<p>Encerra a aplica\u00e7\u00e3o CLI.</p> <pre><code>Voc\u00ea: exit\n</code></pre> <p>ou</p> <pre><code>Voc\u00ea: quit\n</code></pre>"},{"location":"user-guide/cli-usage/#interface-e-formatacao","title":"\ud83c\udfa8 Interface e Formata\u00e7\u00e3o","text":""},{"location":"user-guide/cli-usage/#cores-e-destaque","title":"Cores e Destaque","text":"<p>A CLI usa um esquema de cores profissional:</p> <ul> <li>Prompts: Cor prim\u00e1ria (cyan)</li> <li>Respostas do Agente: Verde</li> <li>Mensagens do Sistema: Amarelo</li> <li>Erros: Vermelho</li> <li>Comandos: Magenta</li> </ul>"},{"location":"user-guide/cli-usage/#formatacao-markdown","title":"Formata\u00e7\u00e3o Markdown","text":"<p>A renderiza\u00e7\u00e3o suporta:</p> <ul> <li>Negrito: <code>**texto**</code></li> <li>It\u00e1lico: <code>*texto*</code></li> <li><code>C\u00f3digo inline</code>: <code>`c\u00f3digo`</code></li> <li>Blocos de c\u00f3digo com syntax highlighting</li> <li>Listas e cabe\u00e7alhos</li> </ul>"},{"location":"user-guide/cli-usage/#indicadores-de-status","title":"Indicadores de Status","text":"<p>Durante o processamento:</p> <pre><code>\u23f3 Processando...\n</code></pre> <p>Durante streaming:</p> <pre><code>\u2728 [Agente est\u00e1 digitando...]\n</code></pre>"},{"location":"user-guide/cli-usage/#exemplos-de-uso","title":"\ud83d\udca1 Exemplos de Uso","text":""},{"location":"user-guide/cli-usage/#exemplo-1-assistente-de-programacao","title":"Exemplo 1: Assistente de Programa\u00e7\u00e3o","text":"<pre><code>from createagents import CreateAgent\n\ncode_assistant = CreateAgent(\n    provider=\"openai\",\n    model=\"gpt-4\",\n    name=\"Code Expert\",\n    instructions=\"Voc\u00ea \u00e9 um especialista em Python. Sempre forne\u00e7a exemplos.\"\n)\n\n# Iniciar CLI interativa\ncode_assistant.start_cli()\n</code></pre> <p>Intera\u00e7\u00e3o:</p> <pre><code>Voc\u00ea: Como criar um decorator em Python?\n[Resposta em streaming...]\n\nVoc\u00ea: /metrics\n[Exibe estat\u00edsticas da chamada]\n\nVoc\u00ea: /clear\n[Limpa hist\u00f3rico para novo t\u00f3pico]\n</code></pre>"},{"location":"user-guide/cli-usage/#exemplo-2-agente-com-ferramentas","title":"Exemplo 2: Agente com Ferramentas","text":"<pre><code>from createagents import CreateAgent\n\nagent_with_tools = CreateAgent(\n    provider=\"openai\",\n    model=\"gpt-4\",\n    tools=[\"currentdate\", \"readlocalfile\"]\n)\n\n# Iniciar CLI\nagent_with_tools.start_cli()\n</code></pre> <p>Intera\u00e7\u00e3o:</p> <pre><code>Voc\u00ea: /tools\n[Lista ferramentas dispon\u00edveis]\n\nVoc\u00ea: Que dia \u00e9 hoje?\n[Agente usa CurrentDateTool automaticamente]\n\nVoc\u00ea: Leia o arquivo report.pdf\n[Agente usa ReadLocalFileTool]\n</code></pre>"},{"location":"user-guide/cli-usage/#exemplo-3-ollama-local","title":"Exemplo 3: Ollama Local","text":"<pre><code>from createagents import CreateAgent\n\nlocal_agent = CreateAgent(\n    provider=\"ollama\",\n    model=\"llama3.2\",\n    name=\"Assistente Local\"\n)\n\n# Iniciar CLI\nlocal_agent.start_cli()\n</code></pre>"},{"location":"user-guide/cli-usage/#personalizacao","title":"\ud83d\udd27 Personaliza\u00e7\u00e3o","text":""},{"location":"user-guide/cli-usage/#usando-a-cli-programaticamente","title":"Usando a CLI Programaticamente","text":"<p>A CLI \u00e9 iniciada atrav\u00e9s do m\u00e9todo <code>start_cli()</code> da facade <code>CreateAgent</code>:</p> <pre><code>from createagents import CreateAgent\n\nagent = CreateAgent(provider=\"openai\", model=\"gpt-4\")\nagent.start_cli()  # Inicia loop interativo\n</code></pre> <p>Internamente, este m\u00e9todo:</p> <ol> <li>Importa <code>ChatCLIApplication</code> da camada de apresenta\u00e7\u00e3o</li> <li>Instancia a aplica\u00e7\u00e3o CLI com o agente</li> <li>Executa o loop principal</li> </ol>"},{"location":"user-guide/cli-usage/#troubleshooting","title":"\ud83d\udc1b Troubleshooting","text":""},{"location":"user-guide/cli-usage/#cli-nao-inicia","title":"CLI n\u00e3o inicia","text":"<p>Problema: Erro ao chamar <code>agent.start_cli()</code></p> <p>Solu\u00e7\u00e3o: Certifique-se de que est\u00e1 na vers\u00e3o mais recente:</p> <pre><code>pip install --upgrade createagents\n</code></pre>"},{"location":"user-guide/cli-usage/#caracteres-especiais-nao-aparecem","title":"Caracteres especiais n\u00e3o aparecem","text":"<p>Problema: Emojis ou caracteres Unicode n\u00e3o renderizam</p> <p>Solu\u00e7\u00e3o: Use um terminal com suporte UTF-8 (Windows Terminal, iTerm2, etc.)</p>"},{"location":"user-guide/cli-usage/#streaming-muito-lento","title":"Streaming muito lento","text":"<p>Problema: Tokens aparecem muito devagar</p> <p>Solu\u00e7\u00e3o:</p> <ol> <li>Verifique sua conex\u00e3o de internet (para OpenAI)</li> <li>Para Ollama, verifique se o modelo est\u00e1 carregado</li> <li>Considere usar um modelo menor/mais r\u00e1pido</li> </ol>"},{"location":"user-guide/cli-usage/#proximos-passos","title":"\ud83d\udcda Pr\u00f3ximos Passos","text":"<ul> <li>Guia de Streaming</li> <li>Arquitetura CLI (Desenvolvedores)</li> <li>API Reference</li> </ul> <p>Vers\u00e3o: 0.1.3 | Atualiza\u00e7\u00e3o: 01/12/2025</p>"},{"location":"user-guide/examples-user/","title":"Exemplos Pr\u00e1ticos de Uso","text":"<p>Veja casos reais de uso do Create Agents AI.</p>"},{"location":"user-guide/examples-user/#assistente-educacional","title":"Assistente Educacional","text":"<pre><code>import asyncio\nfrom createagents import CreateAgent\n\nasync def main():\n    professor = CreateAgent(\n        provider=\"openai\",\n        model=\"gpt-4\",\n        name=\"Professor Virtual\",\n        instructions=\"Voc\u00ea \u00e9 um professor did\u00e1tico.\"\n    )\n\n    resposta = await professor.chat(\"Explique recurs\u00e3o em programa\u00e7\u00e3o\")\n    print(resposta)\n\nasyncio.run(main())\n</code></pre>"},{"location":"user-guide/examples-user/#assistente-corporativo","title":"Assistente Corporativo","text":"<pre><code>import asyncio\nfrom createagents import CreateAgent\n\nasync def main():\n    assistente = CreateAgent(\n        provider=\"openai\",\n        model=\"gpt-4\",\n        name=\"Assistente Executivo\",\n        instructions=\"Use linguagem formal.\",\n        tools=[\"currentdate\"]\n    )\n\n    resposta = await assistente.chat(\"Que dia \u00e9 hoje? Preciso agendar uma reuni\u00e3o\")\n    print(resposta)\n\nasyncio.run(main())\n</code></pre>"},{"location":"user-guide/examples-user/#assistente-de-programacao","title":"Assistente de Programa\u00e7\u00e3o","text":"<pre><code>import asyncio\nfrom createagents import CreateAgent\n\nasync def main():\n    code_expert = CreateAgent(\n        provider=\"openai\",\n        model=\"gpt-4\",\n        name=\"Python Expert\",\n        instructions=\"Especialista em Python.\"\n    )\n\n    codigo = await code_expert.chat(\"Crie uma fun\u00e7\u00e3o que valida CPF brasileiro.\")\n    print(codigo)\n\nasyncio.run(main())\n</code></pre>"},{"location":"user-guide/examples-user/#tradutor-profissional","title":"Tradutor Profissional","text":"<pre><code>import asyncio\nfrom createagents import CreateAgent\n\nasync def main():\n    tradutor = CreateAgent(\n        provider=\"openai\",\n        model=\"gpt-4\",\n        name=\"Tradutor Especializado\",\n        instructions=\"Voc\u00ea \u00e9 um tradutor profissional.\"\n    )\n\n    resposta = await tradutor.chat(\n        \"Traduza para ingl\u00eas: 'A arquitetura clean separa as regras de neg\u00f3cio da infraestrutura.'\"\n    )\n    print(resposta)\n\nasyncio.run(main())\n</code></pre>"},{"location":"user-guide/examples-user/#analista-de-dados","title":"Analista de Dados","text":"<pre><code>import asyncio\nfrom createagents import CreateAgent\n\nasync def main():\n    analista = CreateAgent(\n        provider=\"ollama\",\n        model=\"llama3.2\",\n        name=\"Data Analyst\",\n        instructions=\"Forne\u00e7a insights acion\u00e1veis.\"\n    )\n\n    dados = \"Vendas Q1: Jan=100k, Fev=150k, Mar=120k\"\n    resposta = await analista.chat(f\"Analise estes dados: {dados}\")\n    print(resposta)\n\nasyncio.run(main())\n</code></pre>"},{"location":"user-guide/examples-user/#chatbot-interativo-use-a-cli","title":"Chatbot Interativo (Use a CLI!)","text":"<p>Recomendado: Para chatbots interativos, use a CLI integrada:</p> <pre><code>from createagents import CreateAgent\n\nagent = CreateAgent(\n    provider=\"openai\",\n    model=\"gpt-4\",\n    name=\"Assistente Amig\u00e1vel\",\n)\n\n# Inicia CLI interativa\nagent.start_cli()\n</code></pre> <p>A CLI oferece:</p> <ul> <li>Interface colorida e formatada</li> <li>Comandos <code>/help</code>, <code>/metrics</code>, <code>/configs</code>, <code>/tools</code>, <code>/clear</code></li> <li>Streaming em tempo real</li> <li>Indicadores de status</li> </ul> <p>\ud83d\udcd6 Guia completo da CLI</p>"},{"location":"user-guide/examples-user/#chat-simples-loop-manual","title":"Chat Simples (Loop Manual)","text":"<pre><code>import asyncio\n\nasync def main():\n    chatbot = CreateAgent(\n        provider=\"openai\",\n        model=\"gpt-4\",\n        name=\"Chatbot Simples\",\n    )\n\n    print(\"Digite 'sair' para encerrar.\\n\")\n    while True:\n        user_input = input(\"Voc\u00ea: \")\n        if user_input.lower() in [\"sair\", \"exit\", \"quit\"]:\n            break\n\n        # Streaming\n        response = await chatbot.chat(user_input)\n        print(\"Bot: \", end='', flush=True)\n        async for token in response:\n            print(token, end='', flush=True)\n        print(\"\\n\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"user-guide/examples-user/#agente-local-com-ollama","title":"Agente Local com Ollama","text":"<pre><code>import asyncio\nfrom createagents import CreateAgent\n\nasync def main():\n    agente_local = CreateAgent(\n        provider=\"ollama\",\n        model=\"llama3.2\",\n        name=\"Assistente Privado\",\n        instructions=\"Voc\u00ea \u00e9 um assistente local.\"\n    )\n\n    resposta = await agente_local.chat(\"Explique machine learning em termos simples\")\n    print(resposta)\n\nasyncio.run(main())\n</code></pre>"},{"location":"user-guide/examples-user/#streaming-em-tempo-real","title":"Streaming em Tempo Real","text":"<pre><code>import asyncio\n\nasync def streaming_example():\n    agent = CreateAgent(\n        provider=\"openai\",\n        model=\"gpt-4\",\n    )\n\n    print(\"Escrevendo artigo em tempo real:\\n\")\n    response = await agent.chat(\"Escreva um artigo sobre Clean Architecture\")\n\n    # Exibe token por token\n    async for token in response:\n        print(token, end='', flush=True)\n    print(\"\\n\\n--- Finalizado ---\")\n\nasyncio.run(streaming_example())\n</code></pre>"},{"location":"user-guide/examples-user/#streaming-com-ollama","title":"Streaming com Ollama","text":"<pre><code>import asyncio\n\nasync def ollama_streaming():\n    local_agent = CreateAgent(\n        provider=\"ollama\",\n        model=\"llama3.2\",\n        name=\"Assistente Local\",\n    )\n\n    response = await local_agent.chat(\"Explique o que \u00e9 LLM\")\n    async for chunk in response:\n        print(chunk, end='', flush=True)\n    print()\n\nasyncio.run(ollama_streaming())\n</code></pre>"},{"location":"user-guide/examples-user/#proximos-passos","title":"Pr\u00f3ximos Passos","text":"<ul> <li>Guia de Streaming</li> <li>Uso da CLI</li> <li>FAQ</li> </ul>"},{"location":"user-guide/faq-user/","title":"FAQ do Usu\u00e1rio","text":""},{"location":"user-guide/faq-user/#1-por-que-algumas-ferramentas-sao-opcionais","title":"1. Por que algumas ferramentas s\u00e3o opcionais?","text":"<p>Para manter o sistema leve. Instale apenas se precisar de leitura de arquivos (PDF, Excel, etc).</p>"},{"location":"user-guide/faq-user/#2-como-sei-quais-ferramentas-estao-disponiveis","title":"2. Como sei quais ferramentas est\u00e3o dispon\u00edveis?","text":"<p>Use <code>agent.get_all_available_tools()</code> para listar.</p>"},{"location":"user-guide/faq-user/#3-o-que-acontece-se-eu-tentar-usar-uma-ferramenta-nao-instalada","title":"3. O que acontece se eu tentar usar uma ferramenta n\u00e3o instalada?","text":"<p>Voc\u00ea receber\u00e1 um erro claro indicando como instalar.</p>"},{"location":"user-guide/faq-user/#4-posso-criar-minhas-proprias-ferramentas","title":"4. Posso criar minhas pr\u00f3prias ferramentas?","text":"<p>Sim! Basta estender <code>BaseTool</code> e seguir o padr\u00e3o dos exemplos.</p>"},{"location":"user-guide/faq-user/#5-como-garantir-privacidade-dos-meus-dados","title":"5. Como garantir privacidade dos meus dados?","text":"<p>Use modelos locais (Ollama) para que nada saia da sua m\u00e1quina.</p>"},{"location":"user-guide/faq-user/#6-como-exportar-metricas","title":"6. Como exportar m\u00e9tricas?","text":"<p>Use <code>agent.export_metrics_json()</code> ou <code>agent.export_metrics_prometheus()</code>.</p>"},{"location":"user-guide/faq-user/#7-como-limpar-o-historico","title":"7. Como limpar o hist\u00f3rico?","text":"<p>Chame <code>agent.clear_history()</code>.</p>"},{"location":"user-guide/faq-user/#8-como-reportar-bugs-ou-pedir-suporte","title":"8. Como reportar bugs ou pedir suporte?","text":"<p>Abra uma issue no GitHub ou envie email para estraliotojordan@gmail.com.</p>"},{"location":"user-guide/faq-user/#9-como-atualizar-o-framework","title":"9. Como atualizar o framework?","text":"<p>Atualize via pip:</p> <pre><code>pip install --upgrade createagents\n# OU com file-tools\npip install --upgrade createagents[file-tools]\n</code></pre>"},{"location":"user-guide/faq-user/#10-onde-encontrar-exemplos-avancados","title":"10. Onde encontrar exemplos avan\u00e7ados?","text":"<p>Veja Exemplos e a documenta\u00e7\u00e3o avan\u00e7ada.</p>"},{"location":"user-guide/faq-user/#11-como-usar-a-cli-interativa","title":"11. Como usar a CLI interativa?","text":"<p>Basta chamar o m\u00e9todo <code>start_cli()</code> do agente:</p> <pre><code>from createagents import CreateAgent\n\nagent = CreateAgent(provider=\"openai\", model=\"gpt-4\")\nagent.start_cli()  # Inicia CLI interativa\n</code></pre> <p>\u2139\ufe0f Guia completo da CLI</p>"},{"location":"user-guide/faq-user/#12-como-funciona-o-streaming","title":"12. Como funciona o streaming?","text":"<p>O m\u00e9todo <code>chat()</code> retorna um <code>StreamingResponseDTO</code> que pode ser:</p> <ul> <li>Awaited: <code>response_text = await agent.chat(\"mensagem\")</code></li> <li>Iterado: <code>async for token in await agent.chat(\"mensagem\"): ...</code></li> </ul> <p>O streaming \u00e9 controlado pelo par\u00e2metro <code>stream</code> na configura\u00e7\u00e3o:</p> <pre><code># Habilitar streaming (padr\u00e3o)\nagent = CreateAgent(provider=\"openai\", model=\"gpt-4\", config={\"stream\": True})\n\n# Desabilitar streaming\nagent = CreateAgent(provider=\"openai\", model=\"gpt-4\", config={\"stream\": False})\n</code></pre> <p>\u2139\ufe0f Guia de Streaming</p>"},{"location":"user-guide/faq-user/#13-posso-desabilitar-o-streaming","title":"13. Posso desabilitar o streaming?","text":"<p>Sim! Configure <code>stream: False</code> ao criar o agente:</p> <pre><code>agent = CreateAgent(\n    provider=\"openai\",\n    model=\"gpt-4\",\n    config={\"stream\": False}  # Desabilita streaming\n)\n\n# Resposta completa sem streaming token-por-token\nresponse = await agent.chat(\"mensagem\")\ntext = await response\nprint(text)\n</code></pre>"},{"location":"user-guide/faq-user/#14-quais-comandos-estao-disponiveis-na-cli","title":"14. Quais comandos est\u00e3o dispon\u00edveis na CLI?","text":"<ul> <li><code>/help</code> - Ajuda</li> <li><code>/metrics</code> - M\u00e9tricas de performance</li> <li><code>/configs</code> - Configura\u00e7\u00f5es do agente</li> <li><code>/tools</code> - Listar ferramentas</li> <li><code>/clear</code> - Limpar hist\u00f3rico</li> <li><code>exit</code> ou <code>quit</code> - Sair</li> </ul>"},{"location":"user-guide/faq-user/#15-como-contribuir-com-o-projeto","title":"15. Como contribuir com o projeto?","text":"<p>Veja o guia de contribui\u00e7\u00e3o.</p>"},{"location":"user-guide/installation-user/","title":"Guia de Instala\u00e7\u00e3o do Usu\u00e1rio","text":"<p>Siga este passo a passo para instalar e configurar o Create Agents AI com seguran\u00e7a e confiabilidade no seu ambiente.</p>"},{"location":"user-guide/installation-user/#pre-requisitos","title":"\ud83d\udcdd Pr\u00e9-requisitos","text":"<ul> <li>Python 3.12+ (Download)</li> <li>pip (geralmente inclu\u00eddo com Python)</li> </ul> <p>Dica: Recomenda-se usar ambientes virtuais para isolar as depend\u00eancias do projeto.</p>"},{"location":"user-guide/installation-user/#instalacao-rapida","title":"\u26a1 Instala\u00e7\u00e3o R\u00e1pida","text":""},{"location":"user-guide/installation-user/#1-criar-ambiente-virtual-recomendado","title":"1. Criar Ambiente Virtual (Recomendado)","text":"<pre><code># Criar ambiente virtual\npython3 -m venv .venv\n\n# Ativar ambiente virtual\nsource .venv/bin/activate  # Linux/macOS\n# .venv\\Scripts\\activate  # Windows\n</code></pre>"},{"location":"user-guide/installation-user/#2-instalar-via-pypi","title":"2. Instalar via PyPI","text":"<pre><code># Instala\u00e7\u00e3o b\u00e1sica\npip install createagents\n\n# OU com suporte a arquivos (PDF, Excel, CSV, Parquet)\npip install createagents[file-tools]\n</code></pre> <p>Nota: A op\u00e7\u00e3o <code>[file-tools]</code> adiciona suporte para leitura de arquivos PDF, Excel, CSV e Parquet.</p>"},{"location":"user-guide/installation-user/#3-configurar-variaveis-de-ambiente","title":"3. Configurar Vari\u00e1veis de Ambiente","text":"<pre><code>cp .env.example .env\n# Edite o arquivo .env e adicione sua chave OPENAI_API_KEY\n</code></pre> <p>Exemplo de configura\u00e7\u00e3o:</p> <pre><code>OPENAI_API_KEY=sk-proj-sua-chave\n# Adicione outras vari\u00e1veis se necess\u00e1rio\n</code></pre>"},{"location":"user-guide/installation-user/#4-testar-instalacao","title":"4. Testar Instala\u00e7\u00e3o","text":"<pre><code>import asyncio\nfrom createagents import CreateAgent\n\nasync def main():\n    agent = CreateAgent(\n        provider=\"openai\",\n        model=\"gpt-4\",\n        instructions=\"Voc\u00ea \u00e9 um assistente \u00fatil.\"\n    )\n    response = await agent.chat(\"Ol\u00e1! Teste de instala\u00e7\u00e3o.\")\n    print(response)\n\nasyncio.run(main())\n</code></pre> <p>Se o c\u00f3digo acima rodar sem erros, a instala\u00e7\u00e3o est\u00e1 conclu\u00edda!</p>"},{"location":"user-guide/installation-user/#configuracao-openai","title":"\ud83d\udd11 Configura\u00e7\u00e3o OpenAI","text":"<ol> <li>Crie uma conta em platform.openai.com</li> <li>Gere uma nova API Key em API Keys</li> <li>Adicione ao arquivo <code>.env</code>:</li> </ol> <pre><code>OPENAI_API_KEY=sk-proj-sua-chave\n</code></pre> <p>Aten\u00e7\u00e3o: Nunca compartilhe sua chave em reposit\u00f3rios p\u00fablicos.</p>"},{"location":"user-guide/installation-user/#configuracao-ollama-opcional","title":"\ud83e\udd16 Configura\u00e7\u00e3o Ollama (Opcional)","text":"<p>Permite rodar modelos de IA localmente (privacidade total, sem custos de API).</p>"},{"location":"user-guide/installation-user/#instalar-ollama","title":"Instalar Ollama","text":"<p>Linux:</p> <pre><code>curl -fsSL https://ollama.ai/install.sh | sh\n</code></pre> <p>macOS:</p> <pre><code>brew install ollama\n</code></pre> <p>Windows:</p> <p>Baixe em: ollama.ai/download/windows</p>"},{"location":"user-guide/installation-user/#baixar-modelos","title":"Baixar Modelos","text":"<pre><code>ollama pull llama3.2:latest     # Modelo recomendado\nollama pull granite4:latest     # Alternativo\nollama list             # Ver modelos dispon\u00edveis\n</code></pre>"},{"location":"user-guide/installation-user/#usar-no-codigo","title":"Usar no C\u00f3digo","text":"<pre><code>import asyncio\nfrom createagents import CreateAgent\n\nasync def main():\n    agent = CreateAgent(\n        provider=\"ollama\",\n        model=\"llama3.2\",\n        instructions=\"Voc\u00ea \u00e9 um assistente local.\"\n    )\n    response = await agent.chat(\"Explique machine learning\")\n    print(response)\n\nasyncio.run(main())\n</code></pre> <p>Dica: Rode <code>ollama serve</code> antes de usar para garantir que o servidor est\u00e1 ativo.</p>"},{"location":"user-guide/installation-user/#seguranca-e-boas-praticas","title":"\ud83d\udd12 Seguran\u00e7a e Boas Pr\u00e1ticas","text":"<ul> <li>Nunca fa\u00e7a commit do arquivo <code>.env</code> (j\u00e1 est\u00e1 no <code>.gitignore</code>)</li> <li>Mantenha suas chaves privadas e rotacione periodicamente</li> <li>Use ambientes virtuais para isolar depend\u00eancias</li> <li>Atualize depend\u00eancias regularmente (<code>poetry update</code> ou <code>pip install -U</code>)</li> </ul>"},{"location":"user-guide/installation-user/#solucao-de-problemas","title":"\ud83d\udee0\ufe0f Solu\u00e7\u00e3o de Problemas","text":""},{"location":"user-guide/installation-user/#erros-comuns","title":"Erros Comuns","text":"<ul> <li>\u201cOPENAI_API_KEY not found\u201d: Verifique se o arquivo <code>.env</code> est\u00e1 na raiz e a vari\u00e1vel est\u00e1 correta, sem espa\u00e7os ou aspas.</li> <li>\u201cModuleNotFoundError\u201d: Ative o ambiente virtual e reinstale as depend\u00eancias.</li> <li>Ollama n\u00e3o conecta: Rode <code>ollama serve</code> e verifique se o modelo est\u00e1 baixado.</li> <li>Problemas de permiss\u00e3o: Execute comandos com <code>sudo</code> apenas se necess\u00e1rio e nunca para instalar depend\u00eancias Python no sistema global.</li> </ul>"},{"location":"user-guide/installation-user/#dicas-de-diagnostico","title":"Dicas de Diagn\u00f3stico","text":"<ul> <li>Use <code>poetry run python --version</code> ou <code>python --version</code> para checar a vers\u00e3o ativa.</li> <li>Use <code>poetry show</code> ou <code>pip list</code> para listar depend\u00eancias instaladas.</li> <li>Consulte os logs de erro completos para identificar problemas espec\u00edficos.</li> </ul> <p>Se persistir, consulte a FAQ ou abra uma issue no GitHub.</p>"},{"location":"user-guide/installation-user/#instalacao-para-desenvolvimento-contribuidores","title":"\ud83d\udc68\u200d\ud83d\udcbb Instala\u00e7\u00e3o para Desenvolvimento (Contribuidores)","text":"<p>Se voc\u00ea deseja contribuir com o projeto ou precisa da vers\u00e3o de desenvolvimento:</p>"},{"location":"user-guide/installation-user/#1-clonar-o-repositorio","title":"1. Clonar o Reposit\u00f3rio","text":"<pre><code>git clone https://github.com/jor0105/Create-Agents-AI.git\ncd Create-Agents-AI\n</code></pre>"},{"location":"user-guide/installation-user/#2-instalar-com-poetry","title":"2. Instalar com Poetry","text":"<pre><code># Instale o Poetry se necess\u00e1rio\ncurl -sSL https://install.python-poetry.org | python3 -\n\n# Instala\u00e7\u00e3o b\u00e1sica\npoetry install\n\n# OU com suporte a file-tools\npoetry install -E file-tools\n\n# Ativar ambiente virtual\npoetry shell\n</code></pre>"},{"location":"user-guide/installation-user/#3-configurar-ambiente-de-desenvolvimento","title":"3. Configurar Ambiente de Desenvolvimento","text":"<pre><code># Copiar arquivo de exemplo\ncp .env.example .env\n\n# Editar e adicionar sua chave\n# OPENAI_API_KEY=sk-proj-sua-chave\n</code></pre>"},{"location":"user-guide/installation-user/#4-instalar-pre-commit-hooks","title":"4. Instalar Pre-commit Hooks","text":"<pre><code># Instalar hooks de qualidade de c\u00f3digo\npoetry run pre-commit install\n\n# Executar checks manualmente\npoetry run pre-commit run --all-files\n</code></pre> <p>\ud83d\udcd6 Mais informa\u00e7\u00f5es: Guia de Contribui\u00e7\u00e3o</p>"},{"location":"user-guide/installation-user/#proximos-passos","title":"\ud83d\ude80 Pr\u00f3ximos Passos","text":"<ul> <li>Uso B\u00e1sico</li> <li>Exemplos</li> <li>FAQ</li> <li>Refer\u00eancia de Ferramentas</li> <li>API Reference</li> </ul> <p>Vers\u00e3o: 0.2.0 | Atualiza\u00e7\u00e3o: 02/12/2025</p>"},{"location":"user-guide/streaming-guide/","title":"Guia de Streaming","text":"<p>Este guia explica como receber respostas do agente em tempo real.</p>"},{"location":"user-guide/streaming-guide/#o-que-e-streaming","title":"\ud83d\udca1 O que \u00e9 Streaming?","text":"<p>Streaming permite que voc\u00ea veja a resposta aparecendo palavra por palavra em tempo real, como se o agente estivesse digitando. Isso deixa a experi\u00eancia mais natural e interativa.</p> <p>Sem streaming: Voc\u00ea espera 5 segundos e recebe a resposta completa de uma vez. Com streaming: As palavras aparecem imediatamente, conforme o agente gera a resposta.</p>"},{"location":"user-guide/streaming-guide/#como-usar","title":"\ud83d\ude80 Como Usar","text":"<p>Existem duas formas de receber respostas do agente:</p>"},{"location":"user-guide/streaming-guide/#1-receber-a-resposta-completa-mais-simples","title":"1\ufe0f\u20e3 Receber a Resposta Completa (Mais Simples)","text":"<p>Use <code>await</code> para esperar a resposta completa:</p> <pre><code>import asyncio\nfrom createagents import CreateAgent\n\nasync def main():\n    agent = CreateAgent(provider=\"openai\", model=\"gpt-4\")\n\n    # Espera a resposta completa\n    resposta = await agent.chat(\"Escreva um poema\")\n    print(resposta)\n\nasyncio.run(main())\n</code></pre>"},{"location":"user-guide/streaming-guide/#2-ver-palavra-por-palavra-streaming-em-tempo-real","title":"2\ufe0f\u20e3 Ver Palavra por Palavra (Streaming em Tempo Real)","text":"<p>Use <code>async for</code> para ver cada palavra aparecer:</p> <pre><code>import asyncio\nfrom createagents import CreateAgent\n\nasync def main():\n    agent = CreateAgent(provider=\"openai\", model=\"gpt-4\")\n\n    resposta = await agent.chat(\"Conte uma hist\u00f3ria\")\n\n    # Mostra palavra por palavra\n    async for palavra in resposta:\n        print(palavra, end='', flush=True)\n    print()  # Nova linha no final\n\nasyncio.run(main())\n</code></pre> <p>\ud83d\udca1 Dica: Use a op\u00e7\u00e3o 2 para chatbots ou interfaces onde voc\u00ea quer mostrar o agente \u201cpensando\u201d.</p>"},{"location":"user-guide/streaming-guide/#exemplos-praticos","title":"\ud83d\udcda Exemplos Pr\u00e1ticos","text":""},{"location":"user-guide/streaming-guide/#exemplo-1-chatbot-interativo","title":"Exemplo 1: Chatbot Interativo","text":"<p>Crie um chatbot que mostra as palavras aparecendo:</p> <pre><code>import asyncio\nfrom createagents import CreateAgent\n\nasync def chat_interface():\n    agent = CreateAgent(provider=\"openai\", model=\"gpt-4\")\n\n    while True:\n        user_input = input(\"Voc\u00ea: \")\n        if user_input.lower() in ['sair', 'exit']:\n            break\n\n        print(\"Agente: \", end='', flush=True)\n        resposta = await agent.chat(user_input)\n\n        # Mostra palavra por palavra\n        async for palavra in resposta:\n            print(palavra, end='', flush=True)\n        print(\"\\n\")\n\nasyncio.run(chat_interface())\n</code></pre>"},{"location":"user-guide/streaming-guide/#exemplo-2-perguntas-simples","title":"Exemplo 2: Perguntas Simples","text":"<p>Para perguntas diretas, use <code>await</code> (mais simples):</p> <pre><code>import asyncio\nfrom createagents import CreateAgent\n\nasync def perguntas_simples():\n    agent = CreateAgent(provider=\"openai\", model=\"gpt-4\")\n\n    # Pergunta direta\n    resposta = await agent.chat(\"Qual a capital do Brasil?\")\n    print(f\"Resposta: {resposta}\")\n\nasyncio.run(perguntas_simples())\n</code></pre>"},{"location":"user-guide/streaming-guide/#ativando-e-desativando-streaming","title":"\u2699\ufe0f Ativando e Desativando Streaming","text":""},{"location":"user-guide/streaming-guide/#ativar-streaming-padrao","title":"Ativar Streaming (Padr\u00e3o)","text":"<p>Por padr\u00e3o, o streaming j\u00e1 vem ativado. Voc\u00ea n\u00e3o precisa fazer nada!</p> <pre><code>import asyncio\nfrom createagents import CreateAgent\n\nasync def main():\n    # Streaming j\u00e1 est\u00e1 ativo\n    agent = CreateAgent(provider=\"openai\", model=\"gpt-4\")\n\n    resposta = await agent.chat(\"Conte uma hist\u00f3ria\")\n    async for palavra in resposta:\n        print(palavra, end='', flush=True)\n\nasyncio.run(main())\n</code></pre>"},{"location":"user-guide/streaming-guide/#desativar-streaming","title":"Desativar Streaming","text":"<p>Se preferir esperar a resposta completa, desative o streaming:</p> <pre><code>import asyncio\n\nasync def main():\n    # Desabilita streaming\n    agent = CreateAgent(\n        provider=\"openai\",\n        model=\"gpt-4\",\n        config={\"stream\": False}\n    )\n\n    # Recebe tudo de uma vez\n    resposta = await agent.chat(\"Ol\u00e1\")\n    print(resposta)\n\nasyncio.run(main())\n</code></pre>"},{"location":"user-guide/streaming-guide/#usar-com-ollama-modelos-locais","title":"Usar com Ollama (Modelos Locais)","text":"<pre><code>import asyncio\n\nasync def ollama_streaming():\n    agent = CreateAgent(provider=\"ollama\", model=\"llama3.2\")\n\n    resposta = await agent.chat(\"Explique machine learning\")\n    async for palavra in resposta:\n        print(palavra, end='', flush=True)\n    print()\n\nasyncio.run(ollama_streaming())\n</code></pre> <p>Funciona igual! N\u00e3o importa se usa OpenAI ou Ollama, o streaming funciona da mesma forma.</p>"},{"location":"user-guide/streaming-guide/#usando-ferramentas","title":"\ud83d\udee0\ufe0f Usando Ferramentas","text":"<p>O streaming funciona normalmente mesmo quando o agente usa ferramentas:</p> <pre><code>import asyncio\n\nasync def exemplo_com_ferramentas():\n    agent = CreateAgent(\n        provider=\"openai\",\n        model=\"gpt-4\",\n        tools=[\"currentdate\"]\n    )\n\n    print(\"Perguntando sobre datas...\\n\")\n    resposta = await agent.chat(\"Que dia \u00e9 hoje?\")\n\n    # O agente usa a ferramenta e responde em streaming\n    async for palavra in resposta:\n        print(palavra, end='', flush=True)\n    print()\n\nasyncio.run(exemplo_com_ferramentas())\n</code></pre>"},{"location":"user-guide/streaming-guide/#streaming-e-metricas","title":"\ud83d\udcca Streaming e M\u00e9tricas","text":"<p>M\u00e9tricas s\u00e3o coletadas automaticamente, independentemente do modo de consumo:</p> <pre><code>import asyncio\n\nasync def streaming_with_metrics():\n    from createagents import CreateAgent\n\n    agent = CreateAgent(provider=\"openai\", model=\"gpt-4\")\n\n    # Streaming\n    response = await agent.chat(\"Conte uma piada\")\n    async for token in response:\n        print(token, end='')\n    print(\"\\n\")\n\n    # M\u00e9tricas ainda s\u00e3o gravadas\n    metrics = agent.get_metrics()\n    print(f\"\\nLat\u00eancia: {metrics[-1].latency_ms}ms\")\n    print(f\"Tokens: {metrics[-1].tokens_used}\")\n\nasyncio.run(streaming_with_metrics())\n</code></pre>"},{"location":"user-guide/streaming-guide/#dicas","title":"\ufffd Dicas","text":""},{"location":"user-guide/streaming-guide/#1-para-perguntas-rapidas","title":"1. Para Perguntas R\u00e1pidas","text":"<p>Use <code>await</code> para receber a resposta completa:</p> <pre><code>resposta = await agent.chat(\"Qual a capital da Fran\u00e7a?\")\nprint(resposta)\n</code></pre>"},{"location":"user-guide/streaming-guide/#2-para-chatbots-e-interfaces","title":"2. Para Chatbots e Interfaces","text":"<p>Use <code>async for</code> para mostrar palavra por palavra:</p> <pre><code>resposta = await agent.chat(\"Escreva um artigo\")\nasync for palavra in resposta:\n    print(palavra, end='', flush=True)\n</code></pre>"},{"location":"user-guide/streaming-guide/#3-lembre-se-do-await","title":"3. Lembre-se do <code>await</code>","text":"<p>Sempre use <code>await</code> ao chamar <code>agent.chat()</code>:</p> <pre><code># \u274c Errado\nresposta = agent.chat(\"mensagem\")  # N\u00e3o funciona!\n\n# \u2705 Correto\nresposta = await agent.chat(\"mensagem\")  # Funciona!\n</code></pre>"},{"location":"user-guide/streaming-guide/#4-use-asynciorun","title":"4. Use <code>asyncio.run()</code>","text":"<p>Sempre envolva seu c\u00f3digo em uma fun\u00e7\u00e3o <code>async</code> e execute com <code>asyncio.run()</code>:</p> <pre><code>import asyncio\n\nasync def main():\n    resposta = await agent.chat(\"mensagem\")\n    print(resposta)\n\nasyncio.run(main())\n</code></pre>"},{"location":"user-guide/streaming-guide/#proximos-passos","title":"\ud83d\udcda Pr\u00f3ximos Passos","text":"<ul> <li>Uso da CLI - Interface interativa</li> <li>Exemplos Pr\u00e1ticos - Mais exemplos de uso</li> <li>FAQ - Perguntas frequentes</li> </ul> <p>Vers\u00e3o: 0.1.3 | Atualiza\u00e7\u00e3o: 01/12/2025</p>"}]}